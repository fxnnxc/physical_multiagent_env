{"episode_reward_max": -1.0, "episode_reward_min": -1.0, "episode_reward_mean": -1.0, "episode_len_mean": 375.5, "episodes_this_iter": 4, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": -1.0}, "policy_reward_mean": {"pol": -1.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0], "episode_lengths": [433, 516, 293, 260], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9750720266100172, "mean_raw_obs_processing_ms": 1.0998104359362866, "mean_inference_ms": 1.0497583137763726, "mean_action_processing_ms": 0.046615238551731476}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4000, "timers": {"sample_time_ms": 3312.394, "sample_throughput": 1207.586, "learn_time_ms": 12111.577, "learn_throughput": 330.263, "update_time_ms": 3.665}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 5e-05, "total_loss": 0.07416397862834856, "policy_loss": -0.020474488992476836, "vf_loss": 0.09106922044884413, "vf_explained_var": 0.19824528694152832, "kl": 0.017846225295215845, "entropy": 1.5918004401028156, "entropy_coeff": 0.0}}, "num_steps_sampled": 4000, "num_steps_trained": 4000}, "done": false, "episodes_total": 4, "training_iteration": 1, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-30-12", "timestamp": 1619872212, "time_this_iter_s": 15.439741849899292, "time_total_s": 15.439741849899292, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec67bc80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d730>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 15.439741849899292, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.45909090909091, "ram_util_percent": 57.895454545454555}, "trial_id": "e60dd_00000"}
{"episode_reward_max": -1.0, "episode_reward_min": -1.0, "episode_reward_mean": -1.0, "episode_len_mean": 482.0, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": -1.0}, "policy_reward_mean": {"pol": -1.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0], "episode_lengths": [1011, 379, 433, 516, 293, 260], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.96865028388167, "mean_raw_obs_processing_ms": 1.0759534038854215, "mean_inference_ms": 1.0472381982374006, "mean_action_processing_ms": 0.046068401670168506}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 8000, "timers": {"sample_time_ms": 3256.867, "sample_throughput": 1228.174, "learn_time_ms": 12124.232, "learn_throughput": 329.918, "update_time_ms": 3.617}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 5e-05, "total_loss": -0.018491370195988566, "policy_loss": -0.028393088665325195, "vf_loss": 0.006962168525205925, "vf_explained_var": 0.844042181968689, "kl": 0.014697755221277475, "entropy": 1.5847242064774036, "entropy_coeff": 0.0}}, "num_steps_sampled": 8000, "num_steps_trained": 8000}, "done": false, "episodes_total": 6, "training_iteration": 2, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-30-27", "timestamp": 1619872227, "time_this_iter_s": 15.349010705947876, "time_total_s": 30.788752555847168, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d6a8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 30.788752555847168, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 18.381818181818183, "ram_util_percent": 57.91818181818184}, "trial_id": "e60dd_00000"}
{"episode_reward_max": -1.0, "episode_reward_min": -1.0, "episode_reward_mean": -1.0, "episode_len_mean": 482.0, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": -1.0}, "policy_reward_mean": {"pol": -1.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0], "episode_lengths": [433, 516, 293, 260, 1011, 379], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9686502838816701, "mean_raw_obs_processing_ms": 1.0759534038854213, "mean_inference_ms": 1.0472381982374006, "mean_action_processing_ms": 0.04606840167016851}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 12000, "timers": {"sample_time_ms": 3193.366, "sample_throughput": 1252.597, "learn_time_ms": 12111.503, "learn_throughput": 330.265, "update_time_ms": 3.488}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 5e-05, "total_loss": -0.007773983816150576, "policy_loss": -0.018494331743568182, "vf_loss": 0.008202658616937697, "vf_explained_var": 0.4564138352870941, "kl": 0.012588451645569876, "entropy": 1.589912947267294, "entropy_coeff": 0.0}}, "num_steps_sampled": 12000, "num_steps_trained": 12000}, "done": false, "episodes_total": 6, "training_iteration": 3, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-30-42", "timestamp": 1619872242, "time_this_iter_s": 15.163207292556763, "time_total_s": 45.95195984840393, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 45.95195984840393, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 18.927272727272726, "ram_util_percent": 57.88181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": -1.0, "episode_reward_min": -1.0, "episode_reward_mean": -1.0, "episode_len_mean": 482.0, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": -1.0}, "policy_reward_mean": {"pol": -1.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0], "episode_lengths": [433, 516, 293, 260, 1011, 379], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9686502838816701, "mean_raw_obs_processing_ms": 1.0759534038854213, "mean_inference_ms": 1.0472381982374006, "mean_action_processing_ms": 0.04606840167016851}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 16000, "timers": {"sample_time_ms": 3098.252, "sample_throughput": 1291.051, "learn_time_ms": 12119.665, "learn_throughput": 330.042, "update_time_ms": 3.377}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 5e-05, "total_loss": -0.022753184370230883, "policy_loss": -0.029479568998795003, "vf_loss": 0.002706586295971647, "vf_explained_var": 0.5716655254364014, "kl": 0.02009898266987875, "entropy": 1.5649319104850292, "entropy_coeff": 0.0}}, "num_steps_sampled": 16000, "num_steps_trained": 16000}, "done": false, "episodes_total": 6, "training_iteration": 4, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-30-57", "timestamp": 1619872257, "time_this_iter_s": 14.9667387008667, "time_total_s": 60.91869854927063, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671c80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bb70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 60.91869854927063, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 18.071428571428573, "ram_util_percent": 57.971428571428575}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.7773888888888889, "episode_len_mean": 1228.6666666666667, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.7773888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, 0.0035000000000000014, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], "episode_lengths": [4002, 162, 4002, 433, 516, 293, 260, 1011, 379], "policy_pol_reward": [0.0, -1.0, 0.0035000000000000014, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9651030925607077, "mean_raw_obs_processing_ms": 0.9978912676275209, "mean_inference_ms": 1.0393192690641242, "mean_action_processing_ms": 0.045616207319285125}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 20000, "timers": {"sample_time_ms": 3082.245, "sample_throughput": 1297.755, "learn_time_ms": 12059.998, "learn_throughput": 331.675, "update_time_ms": 3.31}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.021301868197042495, "policy_loss": -0.026315907976822928, "vf_loss": 0.0029835769164492376, "vf_explained_var": 0.7185760736465454, "kl": 0.006768206993001513, "entropy": 1.5647997669875622, "entropy_coeff": 0.0}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 9, "training_iteration": 5, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-31-12", "timestamp": 1619872272, "time_this_iter_s": 14.84987187385559, "time_total_s": 75.76857042312622, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d378>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 75.76857042312622, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 19.10454545454546, "ram_util_percent": 57.86818181818182}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.666375, "episode_len_mean": 1643.0833333333333, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.666375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014], "episode_lengths": [4002, 655, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002], "policy_pol_reward": [0.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014]}, "sampler_perf": {"mean_env_wait_ms": 0.958730760699596, "mean_raw_obs_processing_ms": 0.9705338798452275, "mean_inference_ms": 1.0359829316740041, "mean_action_processing_ms": 0.045196103269220966}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 24000, "timers": {"sample_time_ms": 3099.556, "sample_throughput": 1290.508, "learn_time_ms": 12053.982, "learn_throughput": 331.841, "update_time_ms": 3.413}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.02013642410747707, "policy_loss": -0.026824000233318657, "vf_loss": 0.0033335893549519824, "vf_explained_var": 0.795401930809021, "kl": 0.011179948633071035, "entropy": 1.551018226891756, "entropy_coeff": 0.0}}, "num_steps_sampled": 24000, "num_steps_trained": 24000}, "done": false, "episodes_total": 12, "training_iteration": 6, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-31-27", "timestamp": 1619872287, "time_this_iter_s": 15.22167420387268, "time_total_s": 90.9902446269989, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671f28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6039d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 90.9902446269989, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 17.104761904761904, "ram_util_percent": 57.94761904761905}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.666375, "episode_len_mean": 1643.0833333333333, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.666375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9587307606995963, "mean_raw_obs_processing_ms": 0.9705338798452275, "mean_inference_ms": 1.0359829316740041, "mean_action_processing_ms": 0.04519610326922096}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 28000, "timers": {"sample_time_ms": 3094.193, "sample_throughput": 1292.744, "learn_time_ms": 12086.025, "learn_throughput": 330.961, "update_time_ms": 3.575}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.02633759699529037, "policy_loss": -0.030225649941712618, "vf_loss": 0.00032332501518794743, "vf_explained_var": 0.33139950037002563, "kl": 0.011882433289429173, "entropy": 1.5403205901384354, "entropy_coeff": 0.0}}, "num_steps_sampled": 28000, "num_steps_trained": 28000}, "done": false, "episodes_total": 12, "training_iteration": 7, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-31-43", "timestamp": 1619872303, "time_this_iter_s": 15.35294771194458, "time_total_s": 106.34319233894348, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671730>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671620>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 106.34319233894348, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 18.368181818181817, "ram_util_percent": 57.91818181818183}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.666375, "episode_len_mean": 1643.0833333333333, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.666375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9587307606995963, "mean_raw_obs_processing_ms": 0.9705338798452275, "mean_inference_ms": 1.0359829316740041, "mean_action_processing_ms": 0.04519610326922096}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 32000, "timers": {"sample_time_ms": 3080.347, "sample_throughput": 1298.555, "learn_time_ms": 12028.663, "learn_throughput": 332.539, "update_time_ms": 3.721}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.015121571632334962, "policy_loss": -0.01832750896573998, "vf_loss": 0.0002018301024691027, "vf_explained_var": 0.6937065124511719, "kl": 0.010013685590820387, "entropy": 1.5254202522337437, "entropy_coeff": 0.0}}, "num_steps_sampled": 32000, "num_steps_trained": 32000}, "done": false, "episodes_total": 12, "training_iteration": 8, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-31-58", "timestamp": 1619872318, "time_this_iter_s": 14.622317552566528, "time_total_s": 120.96550989151001, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec603268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec603b70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 120.96550989151001, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 22.79523809523809, "ram_util_percent": 57.838095238095235}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5997666666666668, "episode_len_mean": 1879.6, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5997666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 473, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002], "policy_pol_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9587741767255377, "mean_raw_obs_processing_ms": 0.9436437397549375, "mean_inference_ms": 1.0364458251077453, "mean_action_processing_ms": 0.04515523931505102}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 36000, "timers": {"sample_time_ms": 3080.536, "sample_throughput": 1298.475, "learn_time_ms": 11926.373, "learn_throughput": 335.391, "update_time_ms": 3.818}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.013651765591930598, "policy_loss": -0.01932593059609644, "vf_loss": 0.0017993733199546114, "vf_explained_var": 0.8360333442687988, "kl": 0.012915975792566314, "entropy": 1.5147491991519928, "entropy_coeff": 0.0}}, "num_steps_sampled": 36000, "num_steps_trained": 36000}, "done": false, "episodes_total": 15, "training_iteration": 9, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-32-12", "timestamp": 1619872332, "time_this_iter_s": 14.203191757202148, "time_total_s": 135.16870164871216, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dd08>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 135.16870164871216, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 17.46666666666667, "ram_util_percent": 57.966666666666676}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5553611111111112, "episode_len_mean": 2032.7222222222222, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5553611111111112}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 4002, 391, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473], "policy_pol_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9566834639879429, "mean_raw_obs_processing_ms": 0.9289259158329524, "mean_inference_ms": 1.0361389043199236, "mean_action_processing_ms": 0.045015090741676374}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 40000, "timers": {"sample_time_ms": 3085.097, "sample_throughput": 1296.556, "learn_time_ms": 11943.312, "learn_throughput": 334.915, "update_time_ms": 3.899}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.02023524628020823, "policy_loss": -0.025932655844371766, "vf_loss": 0.001476455137890298, "vf_explained_var": 0.8797528743743896, "kl": 0.014069842407479882, "entropy": 1.5238986760377884, "entropy_coeff": 0.0}}, "num_steps_sampled": 40000, "num_steps_trained": 40000}, "done": false, "episodes_total": 18, "training_iteration": 10, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-32-27", "timestamp": 1619872347, "time_this_iter_s": 15.233206033706665, "time_total_s": 150.40190768241882, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671f28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671730>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 150.40190768241882, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 19.704545454545457, "ram_util_percent": 57.91363636363635}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5553611111111112, "episode_len_mean": 2032.7222222222222, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5553611111111112}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9566834639879429, "mean_raw_obs_processing_ms": 0.9289259158329524, "mean_inference_ms": 1.0361389043199236, "mean_action_processing_ms": 0.045015090741676374}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 44000, "timers": {"sample_time_ms": 3037.047, "sample_throughput": 1317.069, "learn_time_ms": 11891.079, "learn_throughput": 336.387, "update_time_ms": 3.827}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.02629441535100341, "policy_loss": -0.029593423649203032, "vf_loss": 0.00027997741926810704, "vf_explained_var": 0.6774619221687317, "kl": 0.010063430003356189, "entropy": 1.5222938545048237, "entropy_coeff": 0.0}}, "num_steps_sampled": 44000, "num_steps_trained": 44000}, "done": false, "episodes_total": 18, "training_iteration": 11, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-32-42", "timestamp": 1619872362, "time_this_iter_s": 14.43215036392212, "time_total_s": 164.83405804634094, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d1e0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69de18>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 164.83405804634094, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 18.325000000000003, "ram_util_percent": 57.935}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5553611111111112, "episode_len_mean": 2032.7222222222222, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5553611111111112}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9566834639879429, "mean_raw_obs_processing_ms": 0.9289259158329524, "mean_inference_ms": 1.0361389043199236, "mean_action_processing_ms": 0.045015090741676374}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 48000, "timers": {"sample_time_ms": 2997.891, "sample_throughput": 1334.271, "learn_time_ms": 11886.477, "learn_throughput": 336.517, "update_time_ms": 3.871}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.014265339239500463, "policy_loss": -0.019625453685875982, "vf_loss": 0.0004418991366037517, "vf_explained_var": 0.43272334337234497, "kl": 0.016394046688219532, "entropy": 1.505042303353548, "entropy_coeff": 0.0}}, "num_steps_sampled": 48000, "num_steps_trained": 48000}, "done": false, "episodes_total": 18, "training_iteration": 12, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-32-57", "timestamp": 1619872377, "time_this_iter_s": 14.913942813873291, "time_total_s": 179.74800086021423, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671f28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60da60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 179.74800086021423, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 17.204761904761906, "ram_util_percent": 57.94285714285715}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5261315789473685, "episode_len_mean": 2136.3684210526317, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5261315789473685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9566090114404137, "mean_raw_obs_processing_ms": 0.9217747974553901, "mean_inference_ms": 1.0356655186143964, "mean_action_processing_ms": 0.045004813004205314}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 52000, "timers": {"sample_time_ms": 3015.965, "sample_throughput": 1326.275, "learn_time_ms": 11900.532, "learn_throughput": 336.119, "update_time_ms": 3.952}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.020724091795273125, "policy_loss": -0.026078651659190655, "vf_loss": 0.000393752804484393, "vf_explained_var": 0.47409188747406006, "kl": 0.01653602020815015, "entropy": 1.4457082524895668, "entropy_coeff": 0.0}}, "num_steps_sampled": 52000, "num_steps_trained": 52000}, "done": false, "episodes_total": 19, "training_iteration": 13, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-33-12", "timestamp": 1619872392, "time_this_iter_s": 15.485042810440063, "time_total_s": 195.2330436706543, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671c80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 195.2330436706543, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 21.88695652173913, "ram_util_percent": 57.95652173913044}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.4998541666666667, "episode_len_mean": 2197.0416666666665, "episodes_this_iter": 5, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.4998541666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 55, 77, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.954597358039957, "mean_raw_obs_processing_ms": 0.9073659926346576, "mean_inference_ms": 1.0346939539664948, "mean_action_processing_ms": 0.044834686164440606}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 56000, "timers": {"sample_time_ms": 3042.569, "sample_throughput": 1314.679, "learn_time_ms": 11808.484, "learn_throughput": 338.74, "update_time_ms": 4.046}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.028361186385154724, "policy_loss": -0.0365583153325133, "vf_loss": 0.0035451134099275805, "vf_explained_var": 0.8078310489654541, "kl": 0.015506726922467351, "entropy": 1.455966379493475, "entropy_coeff": 0.0}}, "num_steps_sampled": 56000, "num_steps_trained": 56000}, "done": false, "episodes_total": 24, "training_iteration": 14, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-33-26", "timestamp": 1619872406, "time_this_iter_s": 14.313978910446167, "time_total_s": 209.54702258110046, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60db70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 209.54702258110046, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 18.85, "ram_util_percent": 57.89000000000001}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.51986, "episode_len_mean": 2150.6, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.51986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0], "episode_lengths": [1036, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9545745943154302, "mean_raw_obs_processing_ms": 0.9060620202486342, "mean_inference_ms": 1.034606881251234, "mean_action_processing_ms": 0.044818850121052314}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 60000, "timers": {"sample_time_ms": 3056.447, "sample_throughput": 1308.709, "learn_time_ms": 11848.956, "learn_throughput": 337.582, "update_time_ms": 4.194}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.023872109595686197, "policy_loss": -0.03519073064671829, "vf_loss": 0.006296600462519564, "vf_explained_var": 0.46030664443969727, "kl": 0.016740065562771633, "entropy": 1.4436631947755814, "entropy_coeff": 0.0}}, "num_steps_sampled": 60000, "num_steps_trained": 60000}, "done": false, "episodes_total": 25, "training_iteration": 15, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-33-42", "timestamp": 1619872422, "time_this_iter_s": 15.394603729248047, "time_total_s": 224.9416263103485, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec67bc80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d950>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 224.9416263103485, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 18.777272727272724, "ram_util_percent": 57.936363636363645}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5382307692307692, "episode_len_mean": 2122.076923076923, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5382307692307692}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.9975, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0], "episode_lengths": [1409, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036], "policy_pol_reward": [-0.9975, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9535369191482939, "mean_raw_obs_processing_ms": 0.9049323781183364, "mean_inference_ms": 1.033847393640887, "mean_action_processing_ms": 0.044769360668549606}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 64000, "timers": {"sample_time_ms": 3039.044, "sample_throughput": 1316.203, "learn_time_ms": 11829.737, "learn_throughput": 338.131, "update_time_ms": 4.204}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.008257613430032507, "policy_loss": -0.011721772461896762, "vf_loss": 0.0012801208245036833, "vf_explained_var": 0.8473689556121826, "kl": 0.007280121004441753, "entropy": 1.462481513619423, "entropy_coeff": 0.0}}, "num_steps_sampled": 64000, "num_steps_trained": 64000}, "done": false, "episodes_total": 26, "training_iteration": 16, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-33-57", "timestamp": 1619872437, "time_this_iter_s": 14.855164766311646, "time_total_s": 239.79679107666016, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671c80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 239.79679107666016, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 17.914285714285718, "ram_util_percent": 57.90952380952382}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.5182962962962964, "episode_len_mean": 2191.703703703704, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.5182962962962964}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975]}, "sampler_perf": {"mean_env_wait_ms": 0.9535523097132943, "mean_raw_obs_processing_ms": 0.9007125286995427, "mean_inference_ms": 1.0334708205748793, "mean_action_processing_ms": 0.044766300872654465}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 68000, "timers": {"sample_time_ms": 3040.856, "sample_throughput": 1315.419, "learn_time_ms": 11827.446, "learn_throughput": 338.196, "update_time_ms": 4.125}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.020017495815409347, "policy_loss": -0.02541071962332353, "vf_loss": 0.0009926194961735746, "vf_explained_var": 0.8185920715332031, "kl": 0.014668681164039299, "entropy": 1.4282770305871964, "entropy_coeff": 0.0}}, "num_steps_sampled": 68000, "num_steps_trained": 68000}, "done": false, "episodes_total": 27, "training_iteration": 17, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-34-12", "timestamp": 1619872452, "time_this_iter_s": 15.347654342651367, "time_total_s": 255.14444541931152, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d730>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dbf8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 255.14444541931152, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 22.48181818181818, "ram_util_percent": 57.98636363636365}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.49978571428571433, "episode_len_mean": 2256.3571428571427, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.49978571428571433}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9530946990506338, "mean_raw_obs_processing_ms": 0.8982954435505632, "mean_inference_ms": 1.0335643364721872, "mean_action_processing_ms": 0.044731949071606034}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 72000, "timers": {"sample_time_ms": 3073.759, "sample_throughput": 1301.338, "learn_time_ms": 11907.674, "learn_throughput": 335.918, "update_time_ms": 4.084}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.03188528522150591, "policy_loss": -0.03784450324019417, "vf_loss": 0.0007027803430901258, "vf_explained_var": 0.8729291558265686, "kl": 0.017521451867651194, "entropy": 1.4407707378268242, "entropy_coeff": 0.0}}, "num_steps_sampled": 72000, "num_steps_trained": 72000}, "done": false, "episodes_total": 28, "training_iteration": 18, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-34-28", "timestamp": 1619872468, "time_this_iter_s": 15.753577470779419, "time_total_s": 270.89802289009094, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60ba60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 270.89802289009094, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 21.269565217391303, "ram_util_percent": 57.95217391304348}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.0035000000000000014, "episode_reward_min": -1.0, "episode_reward_mean": -0.48255172413793107, "episode_len_mean": 2316.551724137931, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.0035000000000000014}, "policy_reward_mean": {"pol": -0.48255172413793107}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.953309733575252, "mean_raw_obs_processing_ms": 0.8973429296816052, "mean_inference_ms": 1.0337715806862844, "mean_action_processing_ms": 0.04473158385396638}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 76000, "timers": {"sample_time_ms": 3094.451, "sample_throughput": 1292.637, "learn_time_ms": 11989.265, "learn_throughput": 333.632, "update_time_ms": 3.872}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.015942652215017006, "policy_loss": -0.02064024007995613, "vf_loss": 0.0004813275877495471, "vf_explained_var": 0.37699437141418457, "kl": 0.014054208848392591, "entropy": 1.431462686508894, "entropy_coeff": 0.0}}, "num_steps_sampled": 76000, "num_steps_trained": 76000}, "done": false, "episodes_total": 29, "training_iteration": 19, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-34-43", "timestamp": 1619872483, "time_this_iter_s": 15.222387313842773, "time_total_s": 286.1204102039337, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6717b8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 286.1204102039337, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 19.990909090909092, "ram_util_percent": 57.98181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.46625, "episode_len_mean": 2372.733333333333, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.46625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006500000000000004, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002], "policy_pol_reward": [0.006500000000000004, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9524864843712607, "mean_raw_obs_processing_ms": 0.8967740053624579, "mean_inference_ms": 1.0332402070228703, "mean_action_processing_ms": 0.04469417393951058}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 80000, "timers": {"sample_time_ms": 3093.364, "sample_throughput": 1293.091, "learn_time_ms": 11956.497, "learn_throughput": 334.546, "update_time_ms": 3.781}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.03485762397758663, "policy_loss": -0.03952119004679844, "vf_loss": 3.481381753545065e-05, "vf_explained_var": 0.5004992485046387, "kl": 0.015429188206326216, "entropy": 1.411595281213522, "entropy_coeff": 0.0}}, "num_steps_sampled": 80000, "num_steps_trained": 80000}, "done": false, "episodes_total": 30, "training_iteration": 20, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-34-58", "timestamp": 1619872498, "time_this_iter_s": 14.89420461654663, "time_total_s": 301.01461482048035, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60b268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60bb70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 301.01461482048035, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 18.495238095238097, "ram_util_percent": 57.966666666666676}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5637820512820513, "episode_len_mean": 1997.8974358974358, "episodes_this_iter": 9, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5637820512820513}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004], "episode_lengths": [4002, 153, 1736, 58, 29, 311, 159, 186, 102, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.953839248645523, "mean_raw_obs_processing_ms": 0.8923121454609756, "mean_inference_ms": 1.033784685667027, "mean_action_processing_ms": 0.0446937191968027}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 84000, "timers": {"sample_time_ms": 3151.267, "sample_throughput": 1269.331, "learn_time_ms": 11975.222, "learn_throughput": 334.023, "update_time_ms": 3.887}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.01215959302498959, "policy_loss": -0.03427382500376552, "vf_loss": 0.01734151755226776, "vf_explained_var": 0.724888801574707, "kl": 0.015909039444522932, "entropy": 1.4032925218343735, "entropy_coeff": 0.0}}, "num_steps_sampled": 84000, "num_steps_trained": 84000}, "done": false, "episodes_total": 39, "training_iteration": 21, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-35-14", "timestamp": 1619872514, "time_this_iter_s": 15.201726198196411, "time_total_s": 316.21634101867676, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec67bbf8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d2f0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 316.21634101867676, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 17.745454545454546, "ram_util_percent": 58.02272727272727}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5606707317073171, "episode_len_mean": 2001.9512195121952, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5606707317073171}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], "episode_lengths": [4002, 160, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9536555569270091, "mean_raw_obs_processing_ms": 0.8916686872199737, "mean_inference_ms": 1.0338889952199648, "mean_action_processing_ms": 0.04466797065659098}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 88000, "timers": {"sample_time_ms": 3198.898, "sample_throughput": 1250.431, "learn_time_ms": 11915.355, "learn_throughput": 335.701, "update_time_ms": 3.903}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.009173584228847176, "policy_loss": -0.013029048568569124, "vf_loss": 0.0007825722123016021, "vf_explained_var": 0.600166916847229, "kl": 0.01024297229014337, "entropy": 1.3519541695713997, "entropy_coeff": 0.0}}, "num_steps_sampled": 88000, "num_steps_trained": 88000}, "done": false, "episodes_total": 41, "training_iteration": 22, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-35-28", "timestamp": 1619872528, "time_this_iter_s": 14.79049277305603, "time_total_s": 331.0068337917328, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671840>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 331.0068337917328, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 19.652380952380952, "ram_util_percent": 57.95714285714284}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5606707317073171, "episode_len_mean": 2001.9512195121952, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5606707317073171}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9536555569270093, "mean_raw_obs_processing_ms": 0.8916686872199739, "mean_inference_ms": 1.033888995219965, "mean_action_processing_ms": 0.044667970656590984}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 92000, "timers": {"sample_time_ms": 3188.454, "sample_throughput": 1254.527, "learn_time_ms": 11889.056, "learn_throughput": 336.444, "update_time_ms": 3.846}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.028522116073872894, "policy_loss": -0.033173505624290556, "vf_loss": 2.8477044423880216e-05, "vf_explained_var": 0.6670564413070679, "kl": 0.015409704006742686, "entropy": 1.3934371061623096, "entropy_coeff": 0.0}}, "num_steps_sampled": 92000, "num_steps_trained": 92000}, "done": false, "episodes_total": 41, "training_iteration": 23, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-35-44", "timestamp": 1619872544, "time_this_iter_s": 15.11690616607666, "time_total_s": 346.12373995780945, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69df28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d488>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 346.12373995780945, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 16.954545454545453, "ram_util_percent": 58.00909090909091}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5578488372093023, "episode_len_mean": 2075.232558139535, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5578488372093023}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0], "episode_lengths": [4002, 3153, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9531620662640772, "mean_raw_obs_processing_ms": 0.8900767472532242, "mean_inference_ms": 1.0333173860502989, "mean_action_processing_ms": 0.04464820722535878}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 96000, "timers": {"sample_time_ms": 3192.389, "sample_throughput": 1252.98, "learn_time_ms": 11982.781, "learn_throughput": 333.812, "update_time_ms": 3.841}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.03898659412516281, "policy_loss": -0.045656783011509106, "vf_loss": 0.0013258851522550685, "vf_explained_var": 0.8640206456184387, "kl": 0.017814340797485784, "entropy": 1.3569093085825443, "entropy_coeff": 0.0}}, "num_steps_sampled": 96000, "num_steps_trained": 96000}, "done": false, "episodes_total": 43, "training_iteration": 24, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-35-59", "timestamp": 1619872559, "time_this_iter_s": 15.291258096694946, "time_total_s": 361.4149980545044, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671ae8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec616a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 361.4149980545044, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 19.9, "ram_util_percent": 57.94285714285714}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5578488372093023, "episode_len_mean": 2075.232558139535, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5578488372093023}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9531620662640772, "mean_raw_obs_processing_ms": 0.8900767472532244, "mean_inference_ms": 1.0333173860502989, "mean_action_processing_ms": 0.04464820722535879}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 100000, "timers": {"sample_time_ms": 3168.279, "sample_throughput": 1262.515, "learn_time_ms": 11914.444, "learn_throughput": 335.727, "update_time_ms": 3.769}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.017947894491953775, "policy_loss": -0.02099449440720491, "vf_loss": 0.00034793283180079015, "vf_explained_var": 0.7662460803985596, "kl": 0.008995547614176758, "entropy": 1.3840407766401768, "entropy_coeff": 0.0}}, "num_steps_sampled": 100000, "num_steps_trained": 100000}, "done": false, "episodes_total": 43, "training_iteration": 25, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-36-13", "timestamp": 1619872573, "time_this_iter_s": 14.469566106796265, "time_total_s": 375.88456416130066, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671b70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671f28>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 375.88456416130066, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 18.39047619047619, "ram_util_percent": 57.98095238095237}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5330277777777778, "episode_len_mean": 2160.866666666667, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5330277777777778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00125, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153], "policy_pol_reward": [0.00125, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9528903115296855, "mean_raw_obs_processing_ms": 0.8896784791399424, "mean_inference_ms": 1.0332068753695878, "mean_action_processing_ms": 0.04461663885418886}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 104000, "timers": {"sample_time_ms": 3173.655, "sample_throughput": 1260.376, "learn_time_ms": 11941.724, "learn_throughput": 334.96, "update_time_ms": 3.783}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.30000000000000004, "cur_lr": 5e-05, "total_loss": -0.03310042171506211, "policy_loss": -0.03937689965823665, "vf_loss": 0.00015305191300285514, "vf_explained_var": 0.6648611426353455, "kl": 0.020411425561178476, "entropy": 1.4111849591135979, "entropy_coeff": 0.0}}, "num_steps_sampled": 104000, "num_steps_trained": 104000}, "done": false, "episodes_total": 45, "training_iteration": 26, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-36-29", "timestamp": 1619872589, "time_this_iter_s": 15.181427717208862, "time_total_s": 391.0659918785095, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec616268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec616b70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 391.0659918785095, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 17.58636363636364, "ram_util_percent": 57.9409090909091}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5330277777777778, "episode_len_mean": 2160.866666666667, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5330277777777778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9528903115296855, "mean_raw_obs_processing_ms": 0.8896784791399424, "mean_inference_ms": 1.0332068753695878, "mean_action_processing_ms": 0.044616638854188866}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 108000, "timers": {"sample_time_ms": 3181.211, "sample_throughput": 1257.383, "learn_time_ms": 11977.959, "learn_throughput": 333.947, "update_time_ms": 3.83}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5e-05, "total_loss": -0.03258506447309628, "policy_loss": -0.038225219352170825, "vf_loss": 0.00030882010878485744, "vf_explained_var": 0.6953500509262085, "kl": 0.01184740598546341, "entropy": 1.4544887244701385, "entropy_coeff": 0.0}}, "num_steps_sampled": 108000, "num_steps_trained": 108000}, "done": false, "episodes_total": 45, "training_iteration": 27, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-36-45", "timestamp": 1619872605, "time_this_iter_s": 15.786853075027466, "time_total_s": 406.852844953537, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec67bc80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dd90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 406.852844953537, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 21.463636363636365, "ram_util_percent": 58.02272727272726}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5102074468085107, "episode_len_mean": 2239.2127659574467, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5102074468085107}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.004000000000000002, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002], "policy_pol_reward": [0.0025000000000000005, 0.004000000000000002, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9523724336812587, "mean_raw_obs_processing_ms": 0.8883488733890104, "mean_inference_ms": 1.032617596695488, "mean_action_processing_ms": 0.04459646909225932}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 112000, "timers": {"sample_time_ms": 3154.808, "sample_throughput": 1267.906, "learn_time_ms": 11908.4, "learn_throughput": 335.897, "update_time_ms": 3.683}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5e-05, "total_loss": -0.046396750054555014, "policy_loss": -0.05197286044131033, "vf_loss": 0.0001873668677490059, "vf_explained_var": 0.7304664850234985, "kl": 0.011974987661233172, "entropy": 1.3739292360842228, "entropy_coeff": 0.0}}, "num_steps_sampled": 112000, "num_steps_trained": 112000}, "done": false, "episodes_total": 47, "training_iteration": 28, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-36-59", "timestamp": 1619872619, "time_this_iter_s": 14.79204797744751, "time_total_s": 421.6448929309845, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671f28>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 421.6448929309845, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 17.936363636363637, "ram_util_percent": 57.972727272727276}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.5102074468085106, "episode_len_mean": 2239.2127659574467, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.5102074468085106}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002]}, "sampler_perf": {"mean_env_wait_ms": 0.9523724336812587, "mean_raw_obs_processing_ms": 0.8883488733890105, "mean_inference_ms": 1.032617596695488, "mean_action_processing_ms": 0.04459646909225933}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 116000, "timers": {"sample_time_ms": 3144.279, "sample_throughput": 1272.152, "learn_time_ms": 11966.53, "learn_throughput": 334.266, "update_time_ms": 3.89}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5e-05, "total_loss": -0.03863035951508209, "policy_loss": -0.04822983423946425, "vf_loss": 9.233714274614613e-05, "vf_explained_var": 0.6737565994262695, "kl": 0.02112697419943288, "entropy": 1.4030949138104916, "entropy_coeff": 0.0}}, "num_steps_sampled": 116000, "num_steps_trained": 116000}, "done": false, "episodes_total": 47, "training_iteration": 29, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-37-15", "timestamp": 1619872635, "time_this_iter_s": 15.699524402618408, "time_total_s": 437.3444173336029, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d7b8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dc80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 437.3444173336029, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 18.327272727272728, "ram_util_percent": 58.00909090909091}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.48927040816326534, "episode_len_mean": 2311.1632653061224, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.48927040816326534}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0037500000000000016, 0.00175, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0037500000000000016, 0.00175, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002]}, "sampler_perf": {"mean_env_wait_ms": 0.9521805428728762, "mean_raw_obs_processing_ms": 0.8885806698300337, "mean_inference_ms": 1.0325607446471583, "mean_action_processing_ms": 0.044570010211501226}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 120000, "timers": {"sample_time_ms": 3159.104, "sample_throughput": 1266.182, "learn_time_ms": 12021.557, "learn_throughput": 332.736, "update_time_ms": 3.907}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.0242913193651475, "policy_loss": -0.02973995712818578, "vf_loss": 1.8634404398198967e-05, "vf_explained_var": 0.7728932499885559, "kl": 0.008044446600251831, "entropy": 1.3556957505643368, "entropy_coeff": 0.0}}, "num_steps_sampled": 120000, "num_steps_trained": 120000}, "done": false, "episodes_total": 49, "training_iteration": 30, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-37-31", "timestamp": 1619872651, "time_this_iter_s": 15.592434406280518, "time_total_s": 452.9368517398834, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671f28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60ba60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 452.9368517398834, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 21.33636363636364, "ram_util_percent": 57.99090909090907}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4892704081632653, "episode_len_mean": 2311.1632653061224, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4892704081632653}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175]}, "sampler_perf": {"mean_env_wait_ms": 0.9521805428728762, "mean_raw_obs_processing_ms": 0.8885806698300335, "mean_inference_ms": 1.0325607446471583, "mean_action_processing_ms": 0.044570010211501226}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 124000, "timers": {"sample_time_ms": 3134.96, "sample_throughput": 1275.933, "learn_time_ms": 11845.68, "learn_throughput": 337.676, "update_time_ms": 3.761}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.010003024624893442, "policy_loss": -0.014277994050644338, "vf_loss": 2.1953642885819136e-05, "vf_explained_var": 0.38386598229408264, "kl": 0.006300770051893778, "entropy": 1.4025045037269592, "entropy_coeff": 0.0}}, "num_steps_sampled": 124000, "num_steps_trained": 124000}, "done": false, "episodes_total": 49, "training_iteration": 31, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-37-44", "timestamp": 1619872664, "time_this_iter_s": 13.194746494293213, "time_total_s": 466.13159823417664, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671c80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6717b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 466.13159823417664, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 19.65263157894737, "ram_util_percent": 58.01578947368421}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4700833333333333, "episode_len_mean": 2377.470588235294, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4700833333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175]}, "sampler_perf": {"mean_env_wait_ms": 0.9517016661177323, "mean_raw_obs_processing_ms": 0.8878324988574846, "mean_inference_ms": 1.0320075970704299, "mean_action_processing_ms": 0.04455439459001985}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 128000, "timers": {"sample_time_ms": 3112.344, "sample_throughput": 1285.205, "learn_time_ms": 11910.563, "learn_throughput": 335.836, "update_time_ms": 3.751}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.022664864780381322, "policy_loss": -0.028220638108905405, "vf_loss": 0.00016649593885631475, "vf_explained_var": 0.40047362446784973, "kl": 0.007984114126884378, "entropy": 1.310306690633297, "entropy_coeff": 0.0}}, "num_steps_sampled": 128000, "num_steps_trained": 128000}, "done": false, "episodes_total": 51, "training_iteration": 32, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-37-59", "timestamp": 1619872679, "time_this_iter_s": 15.212559700012207, "time_total_s": 481.34415793418884, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60b268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60bb70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 481.34415793418884, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 20.450000000000003, "ram_util_percent": 58.02272727272726}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4700833333333333, "episode_len_mean": 2377.470588235294, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4700833333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9517016661177323, "mean_raw_obs_processing_ms": 0.8878324988574846, "mean_inference_ms": 1.0320075970704297, "mean_action_processing_ms": 0.04455439459001986}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 132000, "timers": {"sample_time_ms": 3107.086, "sample_throughput": 1287.38, "learn_time_ms": 11941.622, "learn_throughput": 334.963, "update_time_ms": 3.734}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.02981698897201568, "policy_loss": -0.03611072336207144, "vf_loss": 8.754758948725794e-05, "vf_explained_var": 0.6556275486946106, "kl": 0.009194352445774712, "entropy": 1.3301241733133793, "entropy_coeff": 0.0}}, "num_steps_sampled": 132000, "num_steps_trained": 132000}, "done": false, "episodes_total": 51, "training_iteration": 33, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-38-15", "timestamp": 1619872695, "time_this_iter_s": 15.376736640930176, "time_total_s": 496.720894575119, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec67bbf8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 496.720894575119, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 18.581818181818182, "ram_util_percent": 58.0090909090909}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.45229245283018865, "episode_len_mean": 2438.7735849056603, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.45229245283018865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0027500000000000007, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0027500000000000007, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.951542140387994, "mean_raw_obs_processing_ms": 0.8881102413253785, "mean_inference_ms": 1.031959479557759, "mean_action_processing_ms": 0.044530926969509874}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 136000, "timers": {"sample_time_ms": 3103.548, "sample_throughput": 1288.847, "learn_time_ms": 11865.252, "learn_throughput": 337.119, "update_time_ms": 3.608}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.02831603732192889, "policy_loss": -0.036176794092170894, "vf_loss": 8.813470415702795e-06, "vf_explained_var": 0.7812178134918213, "kl": 0.011632507666945457, "entropy": 1.2577607817947865, "entropy_coeff": 0.0}}, "num_steps_sampled": 136000, "num_steps_trained": 136000}, "done": false, "episodes_total": 53, "training_iteration": 34, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-38-29", "timestamp": 1619872709, "time_this_iter_s": 14.488570213317871, "time_total_s": 511.2094647884369, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec671268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6717b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 511.2094647884369, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 18.814285714285717, "ram_util_percent": 57.99047619047619}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.46238425925925924, "episode_len_mean": 2462.3518518518517, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.46238425925925924}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99725, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0], "episode_lengths": [3712, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-0.99725, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9511308360332486, "mean_raw_obs_processing_ms": 0.8882027071443456, "mean_inference_ms": 1.0316438871646363, "mean_action_processing_ms": 0.04451353573235956}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 140000, "timers": {"sample_time_ms": 3105.342, "sample_throughput": 1288.103, "learn_time_ms": 11915.631, "learn_throughput": 335.694, "update_time_ms": 3.637}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.018989262694958597, "policy_loss": -0.022966040298342705, "vf_loss": 0.00029885943524732284, "vf_explained_var": -0.08647169172763824, "kl": 0.005448764961329289, "entropy": 1.3386198692023754, "entropy_coeff": 0.0}}, "num_steps_sampled": 140000, "num_steps_trained": 140000}, "done": false, "episodes_total": 54, "training_iteration": 35, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-38-44", "timestamp": 1619872724, "time_this_iter_s": 14.990928888320923, "time_total_s": 526.2003936767578, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d400>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69db70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 526.2003936767578, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 17.985714285714284, "ram_util_percent": 57.96666666666668}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4721090909090909, "episode_len_mean": 2479.5272727272727, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4721090909090909}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99725, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725], "episode_lengths": [3407, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712], "policy_pol_reward": [-0.99725, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725]}, "sampler_perf": {"mean_env_wait_ms": 0.951143872633184, "mean_raw_obs_processing_ms": 0.8875167875867233, "mean_inference_ms": 1.031463339716691, "mean_action_processing_ms": 0.0445171325574065}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 144000, "timers": {"sample_time_ms": 3109.441, "sample_throughput": 1286.405, "learn_time_ms": 11928.094, "learn_throughput": 335.343, "update_time_ms": 3.516}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.675, "cur_lr": 5e-05, "total_loss": -0.0062351226806640625, "policy_loss": -0.008727593929506838, "vf_loss": 0.0007092241171449132, "vf_explained_var": 0.8844409584999084, "kl": 0.0026418474881211296, "entropy": 1.3558823354542255, "entropy_coeff": 0.0}}, "num_steps_sampled": 144000, "num_steps_trained": 144000}, "done": false, "episodes_total": 55, "training_iteration": 36, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-39-00", "timestamp": 1619872740, "time_this_iter_s": 15.346397161483765, "time_total_s": 541.5467908382416, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6717b8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 541.5467908382416, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 20.786363636363635, "ram_util_percent": 57.94090909090908}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4721090909090909, "episode_len_mean": 2479.5272727272727, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4721090909090909}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725]}, "sampler_perf": {"mean_env_wait_ms": 0.9511438726331841, "mean_raw_obs_processing_ms": 0.8875167875867234, "mean_inference_ms": 1.031463339716691, "mean_action_processing_ms": 0.0445171325574065}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 148000, "timers": {"sample_time_ms": 3106.709, "sample_throughput": 1287.536, "learn_time_ms": 11896.329, "learn_throughput": 336.238, "update_time_ms": 3.429}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.019862749584717676, "policy_loss": -0.026575691939797252, "vf_loss": 0.0014467700875684386, "vf_explained_var": 0.8300111293792725, "kl": 0.01560347477789037, "entropy": 1.2960290983319283, "entropy_coeff": 0.0}}, "num_steps_sampled": 148000, "num_steps_trained": 148000}, "done": false, "episodes_total": 55, "training_iteration": 37, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-39-15", "timestamp": 1619872755, "time_this_iter_s": 15.44520616531372, "time_total_s": 556.9919970035553, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6716a8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec671b70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 556.9919970035553, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 23.200000000000003, "ram_util_percent": 58.049999999999976}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4648922413793104, "episode_len_mean": 2540.137931034483, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4648922413793104}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, 0.0022500000000000003, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725], "episode_lengths": [2950, 4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407], "policy_pol_reward": [-1.0, 0.0022500000000000003, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725]}, "sampler_perf": {"mean_env_wait_ms": 0.9506215777112691, "mean_raw_obs_processing_ms": 0.8876303786382475, "mean_inference_ms": 1.0311792059742242, "mean_action_processing_ms": 0.04448216931814711}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 152000, "timers": {"sample_time_ms": 3113.914, "sample_throughput": 1284.557, "learn_time_ms": 11923.159, "learn_throughput": 335.482, "update_time_ms": 3.526}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.024558036267990246, "policy_loss": -0.029963567154482007, "vf_loss": 0.002048796526651131, "vf_explained_var": 0.8556098937988281, "kl": 0.009945874073309824, "entropy": 1.309278815984726, "entropy_coeff": 0.0}}, "num_steps_sampled": 152000, "num_steps_trained": 152000}, "done": false, "episodes_total": 58, "training_iteration": 38, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-39-31", "timestamp": 1619872771, "time_this_iter_s": 15.133982419967651, "time_total_s": 572.125979423523, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600b70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 572.125979423523, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 20.24090909090909, "ram_util_percent": 57.99090909090909}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.46489224137931034, "episode_len_mean": 2540.137931034483, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.46489224137931034}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9506215777112689, "mean_raw_obs_processing_ms": 0.8876303786382477, "mean_inference_ms": 1.0311792059742242, "mean_action_processing_ms": 0.044482169318147115}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 156000, "timers": {"sample_time_ms": 3105.926, "sample_throughput": 1287.861, "learn_time_ms": 11944.142, "learn_throughput": 334.892, "update_time_ms": 3.368}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.026206684240605682, "policy_loss": -0.032111816690303385, "vf_loss": 3.0480380416975095e-05, "vf_explained_var": 0.4371437430381775, "kl": 0.017406386032234877, "entropy": 1.3753367513418198, "entropy_coeff": 0.0}}, "num_steps_sampled": 156000, "num_steps_trained": 156000}, "done": false, "episodes_total": 58, "training_iteration": 39, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-39-46", "timestamp": 1619872786, "time_this_iter_s": 15.8303062915802, "time_total_s": 587.9562857151031, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73f6b62510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600158>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 587.9562857151031, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 21.078260869565216, "ram_util_percent": 58.056521739130424}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4660625, "episode_len_mean": 2569.4333333333334, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4660625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0], "episode_lengths": [4002, 2836, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.950670870884894, "mean_raw_obs_processing_ms": 0.887211138015583, "mean_inference_ms": 1.031010796403844, "mean_action_processing_ms": 0.044482761634484023}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 160000, "timers": {"sample_time_ms": 3067.92, "sample_throughput": 1303.815, "learn_time_ms": 11933.461, "learn_throughput": 335.192, "update_time_ms": 3.342}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.027039247972425073, "policy_loss": -0.031238465249771252, "vf_loss": 0.00019561911926757602, "vf_explained_var": 0.9829708337783813, "kl": 0.011862514278618619, "entropy": 1.2323310859501362, "entropy_coeff": 0.0}}, "num_steps_sampled": 160000, "num_steps_trained": 160000}, "done": false, "episodes_total": 60, "training_iteration": 40, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-40-02", "timestamp": 1619872802, "time_this_iter_s": 15.106663227081299, "time_total_s": 603.0629489421844, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600730>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67b510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 603.0629489421844, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 20.523809523809526, "ram_util_percent": 57.999999999999986}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.47481557377049183, "episode_len_mean": 2552.409836065574, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.47481557377049183}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0], "episode_lengths": [1531, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9506790713405764, "mean_raw_obs_processing_ms": 0.8865009539155501, "mean_inference_ms": 1.0308772382238653, "mean_action_processing_ms": 0.044486338893469105}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 164000, "timers": {"sample_time_ms": 3061.417, "sample_throughput": 1306.585, "learn_time_ms": 12135.42, "learn_throughput": 329.614, "update_time_ms": 3.544}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.03541684875381179, "policy_loss": -0.04005160790984519, "vf_loss": 0.00048557871787124895, "vf_explained_var": 0.9614212512969971, "kl": 0.012293870662688278, "entropy": 1.3119579292833805, "entropy_coeff": 0.0}}, "num_steps_sampled": 164000, "num_steps_trained": 164000}, "done": false, "episodes_total": 61, "training_iteration": 41, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-40-17", "timestamp": 1619872817, "time_this_iter_s": 15.15416669845581, "time_total_s": 618.2171156406403, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600378>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d950>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 618.2171156406403, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 21.13636363636364, "ram_util_percent": 58.0}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.45974206349206354, "episode_len_mean": 2598.4285714285716, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.45974206349206354}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531], "policy_pol_reward": [0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9501692325086897, "mean_raw_obs_processing_ms": 0.8861297431107846, "mean_inference_ms": 1.0306538613163032, "mean_action_processing_ms": 0.04445847617146366}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 168000, "timers": {"sample_time_ms": 3080.552, "sample_throughput": 1298.468, "learn_time_ms": 12129.917, "learn_throughput": 329.763, "update_time_ms": 3.495}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.017497079039458185, "policy_loss": -0.021866340917767957, "vf_loss": 0.0002481681676727021, "vf_explained_var": 0.2909208834171295, "kl": 0.01221064868150279, "entropy": 1.3101197220385075, "entropy_coeff": 0.0}}, "num_steps_sampled": 168000, "num_steps_trained": 168000}, "done": false, "episodes_total": 63, "training_iteration": 42, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-40-32", "timestamp": 1619872832, "time_this_iter_s": 15.354463338851929, "time_total_s": 633.5715789794922, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d8c8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 633.5715789794922, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 20.88181818181818, "ram_util_percent": 58.0181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.45974206349206354, "episode_len_mean": 2598.4285714285716, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.45974206349206354}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9501692325086897, "mean_raw_obs_processing_ms": 0.8861297431107847, "mean_inference_ms": 1.0306538613163034, "mean_action_processing_ms": 0.04445847617146365}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 172000, "timers": {"sample_time_ms": 3083.236, "sample_throughput": 1297.338, "learn_time_ms": 12108.721, "learn_throughput": 330.34, "update_time_ms": 3.575}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.029651048447703943, "policy_loss": -0.03453673914191313, "vf_loss": 9.962725897594282e-06, "vf_explained_var": 0.8311992287635803, "kl": 0.014446607528952882, "entropy": 1.34474628418684, "entropy_coeff": 0.0}}, "num_steps_sampled": 172000, "num_steps_trained": 172000}, "done": false, "episodes_total": 63, "training_iteration": 43, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-40-47", "timestamp": 1619872847, "time_this_iter_s": 15.18999719619751, "time_total_s": 648.7615761756897, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600730>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 648.7615761756897, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 22.004545454545454, "ram_util_percent": 58.0}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.45255859374999996, "episode_len_mean": 2620.359375, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.45255859374999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.950188947206833, "mean_raw_obs_processing_ms": 0.8867592900073924, "mean_inference_ms": 1.0306381992095957, "mean_action_processing_ms": 0.04445617759193788}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 176000, "timers": {"sample_time_ms": 3111.279, "sample_throughput": 1285.645, "learn_time_ms": 12221.623, "learn_throughput": 327.289, "update_time_ms": 3.667}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.01415782026015222, "policy_loss": -0.01694577280431986, "vf_loss": 2.7691288892128796e-05, "vf_explained_var": 0.8145811557769775, "kl": 0.008178553674952127, "entropy": 1.3027133345603943, "entropy_coeff": 0.0}}, "num_steps_sampled": 176000, "num_steps_trained": 176000}, "done": false, "episodes_total": 64, "training_iteration": 44, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-41-03", "timestamp": 1619872863, "time_this_iter_s": 15.901619911193848, "time_total_s": 664.6631960868835, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600c80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bb70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 664.6631960868835, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 31.172727272727276, "ram_util_percent": 55.559090909090905}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.45399621212121216, "episode_len_mean": 2647.6969696969695, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.45399621212121216}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 3043, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9500836244116292, "mean_raw_obs_processing_ms": 0.8861245353559828, "mean_inference_ms": 1.0306102960613452, "mean_action_processing_ms": 0.044448912405536514}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 180000, "timers": {"sample_time_ms": 3147.126, "sample_throughput": 1271.001, "learn_time_ms": 12253.143, "learn_throughput": 326.447, "update_time_ms": 3.599}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.012242479133419693, "policy_loss": -0.015434429980814457, "vf_loss": 0.001116168791668315, "vf_explained_var": 0.876587986946106, "kl": 0.006150467510451563, "entropy": 1.2825879231095314, "entropy_coeff": 0.0}}, "num_steps_sampled": 180000, "num_steps_trained": 180000}, "done": false, "episodes_total": 66, "training_iteration": 45, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-41-19", "timestamp": 1619872879, "time_this_iter_s": 15.665241241455078, "time_total_s": 680.3284373283386, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6002f0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec614a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 680.3284373283386, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 22.59130434782609, "ram_util_percent": 57.58695652173914}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4472201492537313, "episode_len_mean": 2667.910447761194, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4472201492537313}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9497783407715292, "mean_raw_obs_processing_ms": 0.8862599981732449, "mean_inference_ms": 1.0304485139673765, "mean_action_processing_ms": 0.04443894019800155}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 184000, "timers": {"sample_time_ms": 3175.88, "sample_throughput": 1259.493, "learn_time_ms": 12230.952, "learn_throughput": 327.039, "update_time_ms": 3.742}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.007036178547423333, "policy_loss": -0.009716840868350118, "vf_loss": 0.0004952602566845599, "vf_explained_var": 0.6186526417732239, "kl": 0.006475258938735351, "entropy": 1.1721618473529816, "entropy_coeff": 0.0}}, "num_steps_sampled": 184000, "num_steps_trained": 184000}, "done": false, "episodes_total": 67, "training_iteration": 46, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-41-35", "timestamp": 1619872895, "time_this_iter_s": 15.415238618850708, "time_total_s": 695.7436759471893, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 695.7436759471893, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 20.472727272727273, "ram_util_percent": 57.97727272727273}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4472201492537314, "episode_len_mean": 2667.910447761194, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4472201492537314}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9497783407715292, "mean_raw_obs_processing_ms": 0.8862599981732447, "mean_inference_ms": 1.0304485139673765, "mean_action_processing_ms": 0.04443894019800155}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 188000, "timers": {"sample_time_ms": 3183.987, "sample_throughput": 1256.286, "learn_time_ms": 12222.635, "learn_throughput": 327.262, "update_time_ms": 3.71}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.018316820554900914, "policy_loss": -0.02375461143674329, "vf_loss": 0.00046848905867591384, "vf_explained_var": 0.7561244368553162, "kl": 0.014723853120813146, "entropy": 1.2141695357859135, "entropy_coeff": 0.0}}, "num_steps_sampled": 188000, "num_steps_trained": 188000}, "done": false, "episodes_total": 67, "training_iteration": 47, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-41-50", "timestamp": 1619872910, "time_this_iter_s": 15.437986850738525, "time_total_s": 711.1816627979279, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6140d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec614ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 711.1816627979279, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 18.79090909090909, "ram_util_percent": 57.972727272727276}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4487173913043478, "episode_len_mean": 2689.7391304347825, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4487173913043478}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99775, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [2840, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002], "policy_pol_reward": [-0.99775, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9497407372635598, "mean_raw_obs_processing_ms": 0.8868293758338617, "mean_inference_ms": 1.0306242217671235, "mean_action_processing_ms": 0.044431748950593965}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 192000, "timers": {"sample_time_ms": 3200.387, "sample_throughput": 1249.849, "learn_time_ms": 12218.132, "learn_throughput": 327.382, "update_time_ms": 3.734}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.02621895243646577, "policy_loss": -0.03281107998918742, "vf_loss": 0.001533369109438354, "vf_explained_var": 0.8167452812194824, "kl": 0.014988908573286608, "entropy": 1.2403949908912182, "entropy_coeff": 0.0}}, "num_steps_sampled": 192000, "num_steps_trained": 192000}, "done": false, "episodes_total": 69, "training_iteration": 48, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-42-05", "timestamp": 1619872925, "time_this_iter_s": 15.252047061920166, "time_total_s": 726.433709859848, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d8c8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6009d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 726.433709859848, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 21.80454545454546, "ram_util_percent": 57.98636363636364}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4422857142857142, "episode_len_mean": 2708.4857142857145, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4422857142857142}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0015, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002], "policy_pol_reward": [0.0015, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9497871171558454, "mean_raw_obs_processing_ms": 0.8865169060559559, "mean_inference_ms": 1.030583570543518, "mean_action_processing_ms": 0.044437372579906764}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 196000, "timers": {"sample_time_ms": 3182.983, "sample_throughput": 1256.683, "learn_time_ms": 12134.18, "learn_throughput": 329.647, "update_time_ms": 3.832}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.016053691186243668, "policy_loss": -0.022958511603064835, "vf_loss": 0.0036370718080434017, "vf_explained_var": 0.543373703956604, "kl": 0.009682220275863074, "entropy": 1.2813799306750298, "entropy_coeff": 0.0}}, "num_steps_sampled": 196000, "num_steps_trained": 196000}, "done": false, "episodes_total": 70, "training_iteration": 49, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-42-20", "timestamp": 1619872940, "time_this_iter_s": 14.816141128540039, "time_total_s": 741.2498509883881, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dd90>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d488>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 741.2498509883881, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 20.39047619047619, "ram_util_percent": 58.0095238095238}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4359788732394366, "episode_len_mean": 2726.7042253521126, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4359788732394366}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005500000000000003, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002], "policy_pol_reward": [0.005500000000000003, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015]}, "sampler_perf": {"mean_env_wait_ms": 0.9495081878441367, "mean_raw_obs_processing_ms": 0.8866459658601638, "mean_inference_ms": 1.0304431954336606, "mean_action_processing_ms": 0.04442846907578395}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 200000, "timers": {"sample_time_ms": 3213.457, "sample_throughput": 1244.765, "learn_time_ms": 12081.971, "learn_throughput": 331.072, "update_time_ms": 3.876}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.028847805224359035, "policy_loss": -0.035536485782358795, "vf_loss": 0.00011075679753957957, "vf_explained_var": 0.7397732734680176, "kl": 0.019490151607897133, "entropy": 1.332412499934435, "entropy_coeff": 0.0}}, "num_steps_sampled": 200000, "num_steps_trained": 200000}, "done": false, "episodes_total": 71, "training_iteration": 50, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-42-35", "timestamp": 1619872955, "time_this_iter_s": 14.894161701202393, "time_total_s": 756.1440126895905, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600620>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 756.1440126895905, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 19.109523809523807, "ram_util_percent": 58.038095238095224}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4359788732394366, "episode_len_mean": 2726.7042253521126, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4359788732394366}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9495081878441367, "mean_raw_obs_processing_ms": 0.8866459658601638, "mean_inference_ms": 1.0304431954336606, "mean_action_processing_ms": 0.044428469075783954}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 204000, "timers": {"sample_time_ms": 3210.861, "sample_throughput": 1245.772, "learn_time_ms": 12099.6, "learn_throughput": 330.589, "update_time_ms": 3.792}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.3375, "cur_lr": 5e-05, "total_loss": -0.029811387707013637, "policy_loss": -0.03690622607246041, "vf_loss": 0.00017458599950259668, "vf_explained_var": 0.5821928977966309, "kl": 0.020504443789832294, "entropy": 1.1613044738769531, "entropy_coeff": 0.0}}, "num_steps_sampled": 204000, "num_steps_trained": 204000}, "done": false, "episodes_total": 71, "training_iteration": 51, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-42-51", "timestamp": 1619872971, "time_this_iter_s": 15.304117918014526, "time_total_s": 771.448130607605, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600d08>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec615a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 771.448130607605, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 19.963636363636365, "ram_util_percent": 57.99090909090909}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4239383561643835, "episode_len_mean": 2761.6438356164385, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4239383561643835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004500000000000002, 0.0025000000000000005, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002], "policy_pol_reward": [0.004500000000000002, 0.0025000000000000005, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9494500234941031, "mean_raw_obs_processing_ms": 0.88705289434942, "mean_inference_ms": 1.0305873437824478, "mean_action_processing_ms": 0.04442104085498803}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 208000, "timers": {"sample_time_ms": 3187.674, "sample_throughput": 1254.833, "learn_time_ms": 12147.413, "learn_throughput": 329.288, "update_time_ms": 3.793}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02049623290076852, "policy_loss": -0.025239159062039107, "vf_loss": 1.601047364374608e-05, "vf_explained_var": 0.5923010110855103, "kl": 0.009337117633549497, "entropy": 1.2256604507565498, "entropy_coeff": 0.0}}, "num_steps_sampled": 208000, "num_steps_trained": 208000}, "done": false, "episodes_total": 73, "training_iteration": 52, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-43-06", "timestamp": 1619872986, "time_this_iter_s": 15.596664190292358, "time_total_s": 787.0447947978973, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dd90>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d488>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 787.0447947978973, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 20.000000000000004, "ram_util_percent": 57.99545454545454}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.41820945945945937, "episode_len_mean": 2778.4054054054054, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.41820945945945937}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9495211122300706, "mean_raw_obs_processing_ms": 0.8866518284183679, "mean_inference_ms": 1.0305664162679542, "mean_action_processing_ms": 0.04442714388886777}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 212000, "timers": {"sample_time_ms": 3186.073, "sample_throughput": 1255.464, "learn_time_ms": 12158.262, "learn_throughput": 328.994, "update_time_ms": 3.763}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02767924848012626, "policy_loss": -0.03149908588966355, "vf_loss": 4.412494043037896e-06, "vf_explained_var": 0.6910073757171631, "kl": 0.007536642500781454, "entropy": 1.1945642456412315, "entropy_coeff": 0.0}}, "num_steps_sampled": 212000, "num_steps_trained": 212000}, "done": false, "episodes_total": 74, "training_iteration": 53, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-43-22", "timestamp": 1619873002, "time_this_iter_s": 15.283355712890625, "time_total_s": 802.328150510788, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6150d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec615ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 802.328150510788, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 19.645454545454545, "ram_util_percent": 58.07727272727271}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.41263333333333324, "episode_len_mean": 2794.72, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.41263333333333324}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9492552837142185, "mean_raw_obs_processing_ms": 0.8868386803298459, "mean_inference_ms": 1.0304264278313566, "mean_action_processing_ms": 0.04441847253046825}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 216000, "timers": {"sample_time_ms": 3162.28, "sample_throughput": 1264.91, "learn_time_ms": 12155.272, "learn_throughput": 329.075, "update_time_ms": 3.947}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02043215773301199, "policy_loss": -0.026399925001896918, "vf_loss": 4.582851914847197e-05, "vf_explained_var": 0.3031134307384491, "kl": 0.011697657057084143, "entropy": 1.2711076401174068, "entropy_coeff": 0.0}}, "num_steps_sampled": 216000, "num_steps_trained": 216000}, "done": false, "episodes_total": 75, "training_iteration": 54, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-43-37", "timestamp": 1619873017, "time_this_iter_s": 15.634012937545776, "time_total_s": 817.9621634483337, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600158>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 817.9621634483337, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 21.182608695652174, "ram_util_percent": 57.95652173913045}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.4126333333333333, "episode_len_mean": 2794.72, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.4126333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9492552837142187, "mean_raw_obs_processing_ms": 0.8868386803298457, "mean_inference_ms": 1.0304264278313564, "mean_action_processing_ms": 0.044418472530468246}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 220000, "timers": {"sample_time_ms": 3178.872, "sample_throughput": 1258.308, "learn_time_ms": 12179.148, "learn_throughput": 328.43, "update_time_ms": 3.994}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.020186185516649857, "policy_loss": -0.026207459799479693, "vf_loss": 0.00018572023645901936, "vf_explained_var": 0.33150941133499146, "kl": 0.011527018796186894, "entropy": 1.350462943315506, "entropy_coeff": 0.0}}, "num_steps_sampled": 220000, "num_steps_trained": 220000}, "done": false, "episodes_total": 75, "training_iteration": 55, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-43-53", "timestamp": 1619873033, "time_this_iter_s": 16.070805311203003, "time_total_s": 834.0329687595367, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 834.0329687595367, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 22.278260869565223, "ram_util_percent": 58.06521739130436}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.40184740259740254, "episode_len_mean": 2826.0779220779223, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.40184740259740254}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0037500000000000016, 0.0015, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0037500000000000016, 0.0015, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9492337602374866, "mean_raw_obs_processing_ms": 0.8872108732258024, "mean_inference_ms": 1.0306094228272056, "mean_action_processing_ms": 0.04441335059055227}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 224000, "timers": {"sample_time_ms": 3155.41, "sample_throughput": 1267.664, "learn_time_ms": 12176.194, "learn_throughput": 328.51, "update_time_ms": 3.917}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.018847526924218982, "policy_loss": -0.02334829542087391, "vf_loss": 1.3388951060733234e-05, "vf_explained_var": 0.42930492758750916, "kl": 0.008863958602887578, "entropy": 1.3326311632990837, "entropy_coeff": 0.0}}, "num_steps_sampled": 224000, "num_steps_trained": 224000}, "done": false, "episodes_total": 77, "training_iteration": 56, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-44-09", "timestamp": 1619873049, "time_this_iter_s": 15.150386333465576, "time_total_s": 849.1833550930023, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6000d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600950>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 849.1833550930023, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 19.98095238095238, "ram_util_percent": 58.09047619047618}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.39669551282051274, "episode_len_mean": 2841.153846153846, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.39669551282051274}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015]}, "sampler_perf": {"mean_env_wait_ms": 0.9493056707623939, "mean_raw_obs_processing_ms": 0.8870562532984033, "mean_inference_ms": 1.0306012082826908, "mean_action_processing_ms": 0.04441985477535676}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 228000, "timers": {"sample_time_ms": 3153.646, "sample_throughput": 1268.373, "learn_time_ms": 12177.578, "learn_throughput": 328.473, "update_time_ms": 4.02}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.025069044961128384, "policy_loss": -0.02945079014170915, "vf_loss": 4.033704723127585e-06, "vf_explained_var": 0.7616686820983887, "kl": 0.008647327253129333, "entropy": 1.319481734186411, "entropy_coeff": 0.0}}, "num_steps_sampled": 228000, "num_steps_trained": 228000}, "done": false, "episodes_total": 78, "training_iteration": 57, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-44-24", "timestamp": 1619873064, "time_this_iter_s": 15.433302879333496, "time_total_s": 864.6166579723358, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6002f0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec612a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 864.6166579723358, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 19.013636363636365, "ram_util_percent": 58.05}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.3916202531645569, "episode_len_mean": 2855.8481012658226, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.3916202531645569}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004250000000000002, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0], "episode_lengths": [4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.004250000000000002, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9490579167188402, "mean_raw_obs_processing_ms": 0.8872602492985604, "mean_inference_ms": 1.0304822211300477, "mean_action_processing_ms": 0.044412304132159575}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 232000, "timers": {"sample_time_ms": 3151.556, "sample_throughput": 1269.214, "learn_time_ms": 12210.116, "learn_throughput": 327.597, "update_time_ms": 3.985}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.03574502613628283, "policy_loss": -0.043252718896837905, "vf_loss": 1.7254677459277445e-05, "vf_explained_var": 0.5602726340293884, "kl": 0.01479592386749573, "entropy": 1.2817560248076916, "entropy_coeff": 0.0}}, "num_steps_sampled": 232000, "num_steps_trained": 232000}, "done": false, "episodes_total": 79, "training_iteration": 58, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-44-40", "timestamp": 1619873080, "time_this_iter_s": 15.556970357894897, "time_total_s": 880.1736283302307, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 880.1736283302307, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 20.621739130434786, "ram_util_percent": 58.01304347826087}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.39162025316455695, "episode_len_mean": 2855.8481012658226, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.39162025316455695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002]}, "sampler_perf": {"mean_env_wait_ms": 0.9490579167188402, "mean_raw_obs_processing_ms": 0.8872602492985603, "mean_inference_ms": 1.0304822211300475, "mean_action_processing_ms": 0.044412304132159575}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 236000, "timers": {"sample_time_ms": 3160.591, "sample_throughput": 1265.586, "learn_time_ms": 12239.361, "learn_throughput": 326.814, "update_time_ms": 3.857}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.03091975938878022, "policy_loss": -0.03727234108373523, "vf_loss": 1.0560545973703483e-05, "vf_explained_var": 0.6939941644668579, "kl": 0.012527450453490019, "entropy": 1.248208623379469, "entropy_coeff": 0.0}}, "num_steps_sampled": 236000, "num_steps_trained": 236000}, "done": false, "episodes_total": 79, "training_iteration": 59, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-44-55", "timestamp": 1619873095, "time_this_iter_s": 15.20454216003418, "time_total_s": 895.3781704902649, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6120d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec612ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 895.3781704902649, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 19.852380952380948, "ram_util_percent": 58.061904761904756}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.38185185185185183, "episode_len_mean": 2884.1481481481483, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.38185185185185183}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004250000000000002, 0.0037500000000000016, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.004250000000000002, 0.0037500000000000016, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002]}, "sampler_perf": {"mean_env_wait_ms": 0.9490600947670513, "mean_raw_obs_processing_ms": 0.887708384016778, "mean_inference_ms": 1.030670303343707, "mean_action_processing_ms": 0.044408088699879084}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 240000, "timers": {"sample_time_ms": 3173.036, "sample_throughput": 1260.622, "learn_time_ms": 12305.697, "learn_throughput": 325.053, "update_time_ms": 3.853}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.026738281900179572, "policy_loss": -0.03413658699719235, "vf_loss": 1.47215935442091e-05, "vf_explained_var": 0.6389948129653931, "kl": 0.01458485858165659, "entropy": 1.2154058739542961, "entropy_coeff": 0.0}}, "num_steps_sampled": 240000, "num_steps_trained": 240000}, "done": false, "episodes_total": 81, "training_iteration": 60, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-45-11", "timestamp": 1619873111, "time_this_iter_s": 15.682407140731812, "time_total_s": 911.0605776309967, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d9d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600b70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 911.0605776309967, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 20.208695652173912, "ram_util_percent": 58.060869565217374}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.39666566265060255, "episode_len_mean": 2890.975903614458, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.39666566265060255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99625, -0.997, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016], "episode_lengths": [3168, 3167, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-0.99625, -0.997, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016]}, "sampler_perf": {"mean_env_wait_ms": 0.948895087205775, "mean_raw_obs_processing_ms": 0.8877342642565844, "mean_inference_ms": 1.0305425889340207, "mean_action_processing_ms": 0.04440714947613196}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 244000, "timers": {"sample_time_ms": 3163.549, "sample_throughput": 1264.403, "learn_time_ms": 12258.708, "learn_throughput": 326.299, "update_time_ms": 3.877}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.023717222356935963, "policy_loss": -0.027050702192354947, "vf_loss": 0.0002526820373986993, "vf_explained_var": 0.9823324680328369, "kl": 0.006085526532842778, "entropy": 1.1251778863370419, "entropy_coeff": 0.0}}, "num_steps_sampled": 244000, "num_steps_trained": 244000}, "done": false, "episodes_total": 83, "training_iteration": 61, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-45-26", "timestamp": 1619873126, "time_this_iter_s": 14.740171909332275, "time_total_s": 925.800749540329, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69db70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dd90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 925.800749540329, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 20.27142857142857, "ram_util_percent": 58.0095238095238}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.39666566265060244, "episode_len_mean": 2890.975903614458, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.39666566265060244}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997]}, "sampler_perf": {"mean_env_wait_ms": 0.948895087205775, "mean_raw_obs_processing_ms": 0.8877342642565846, "mean_inference_ms": 1.0305425889340207, "mean_action_processing_ms": 0.04440714947613197}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 248000, "timers": {"sample_time_ms": 3152.41, "sample_throughput": 1268.87, "learn_time_ms": 12228.069, "learn_throughput": 327.116, "update_time_ms": 3.786}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.017813456244766712, "policy_loss": -0.024164310249034315, "vf_loss": 0.00043452805766719393, "vf_explained_var": 0.777751088142395, "kl": 0.011686567449942231, "entropy": 1.1259101033210754, "entropy_coeff": 0.0}}, "num_steps_sampled": 248000, "num_steps_trained": 248000}, "done": false, "episodes_total": 83, "training_iteration": 62, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-45-41", "timestamp": 1619873141, "time_this_iter_s": 15.175918579101562, "time_total_s": 940.9766681194305, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600c80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600730>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 940.9766681194305, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 20.045454545454543, "ram_util_percent": 58.03181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.39666566265060244, "episode_len_mean": 2890.975903614458, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.39666566265060244}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997]}, "sampler_perf": {"mean_env_wait_ms": 0.948895087205775, "mean_raw_obs_processing_ms": 0.8877342642565846, "mean_inference_ms": 1.0305425889340207, "mean_action_processing_ms": 0.04440714947613197}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 252000, "timers": {"sample_time_ms": 3150.741, "sample_throughput": 1269.543, "learn_time_ms": 12252.993, "learn_throughput": 326.451, "update_time_ms": 3.913}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02672508329851553, "policy_loss": -0.036949801578884944, "vf_loss": 0.000399993114569952, "vf_explained_var": 0.5122873187065125, "kl": 0.019406859297305346, "entropy": 1.263704564422369, "entropy_coeff": 0.0}}, "num_steps_sampled": 252000, "num_steps_trained": 252000}, "done": false, "episodes_total": 83, "training_iteration": 63, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-45-56", "timestamp": 1619873156, "time_this_iter_s": 15.516007661819458, "time_total_s": 956.49267578125, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600d08>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 956.49267578125, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 18.604545454545455, "ram_util_percent": 57.97727272727273}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.38725000000000004, "episode_len_mean": 2917.1176470588234, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.38725000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0022500000000000003, 0.0047500000000000025, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167], "policy_pol_reward": [0.0022500000000000003, 0.0047500000000000025, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997]}, "sampler_perf": {"mean_env_wait_ms": 0.9488875958179711, "mean_raw_obs_processing_ms": 0.8881021216818135, "mean_inference_ms": 1.0307320854690758, "mean_action_processing_ms": 0.04440379938136572}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 256000, "timers": {"sample_time_ms": 3163.142, "sample_throughput": 1264.565, "learn_time_ms": 12204.792, "learn_throughput": 327.74, "update_time_ms": 3.742}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.017258805164601654, "policy_loss": -0.023819129215553403, "vf_loss": 0.000164224073614605, "vf_explained_var": 0.457394003868103, "kl": 0.012634269456611946, "entropy": 1.237399984151125, "entropy_coeff": 0.0}}, "num_steps_sampled": 256000, "num_steps_trained": 256000}, "done": false, "episodes_total": 85, "training_iteration": 64, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-46-12", "timestamp": 1619873172, "time_this_iter_s": 15.273847103118896, "time_total_s": 971.7665228843689, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69db70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dd90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 971.7665228843689, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 24.00909090909091, "ram_util_percent": 57.909090909090885}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.3782931034482759, "episode_len_mean": 2942.057471264368, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.3782931034482759}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0047500000000000025, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002], "policy_pol_reward": [0.0047500000000000025, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025]}, "sampler_perf": {"mean_env_wait_ms": 0.9487372361604529, "mean_raw_obs_processing_ms": 0.8881124302484672, "mean_inference_ms": 1.030634231364478, "mean_action_processing_ms": 0.044404227439510745}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 260000, "timers": {"sample_time_ms": 3132.24, "sample_throughput": 1277.041, "learn_time_ms": 12174.255, "learn_throughput": 328.562, "update_time_ms": 3.679}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.0178755285742227, "policy_loss": -0.023682036815444008, "vf_loss": 5.5848269880698354e-05, "vf_explained_var": 0.39833223819732666, "kl": 0.01135932927718386, "entropy": 1.1692936606705189, "entropy_coeff": 0.0}}, "num_steps_sampled": 260000, "num_steps_trained": 260000}, "done": false, "episodes_total": 87, "training_iteration": 65, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-46-27", "timestamp": 1619873187, "time_this_iter_s": 15.454849243164062, "time_total_s": 987.221372127533, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6070d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 987.221372127533, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 20.245454545454546, "ram_util_percent": 58.01363636363636}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.3782931034482759, "episode_len_mean": 2942.057471264368, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.3782931034482759}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9487372361604526, "mean_raw_obs_processing_ms": 0.8881124302484673, "mean_inference_ms": 1.030634231364478, "mean_action_processing_ms": 0.044404227439510745}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 264000, "timers": {"sample_time_ms": 3142.236, "sample_throughput": 1272.979, "learn_time_ms": 12039.627, "learn_throughput": 332.236, "update_time_ms": 3.602}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.029454545758198947, "policy_loss": -0.03800272586522624, "vf_loss": 8.667151507779636e-05, "vf_explained_var": 0.5752884745597839, "kl": 0.016714086523279548, "entropy": 1.1906333081424236, "entropy_coeff": 0.0}}, "num_steps_sampled": 264000, "num_steps_trained": 264000}, "done": false, "episodes_total": 87, "training_iteration": 66, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-46-41", "timestamp": 1619873201, "time_this_iter_s": 13.898304224014282, "time_total_s": 1001.1196763515472, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dd90>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1001.1196763515472, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 17.490000000000002, "ram_util_percent": 57.975}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.3782931034482759, "episode_len_mean": 2942.057471264368, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.3782931034482759}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9487372361604526, "mean_raw_obs_processing_ms": 0.8881124302484673, "mean_inference_ms": 1.030634231364478, "mean_action_processing_ms": 0.044404227439510745}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 268000, "timers": {"sample_time_ms": 3156.204, "sample_throughput": 1267.345, "learn_time_ms": 12053.677, "learn_throughput": 331.849, "update_time_ms": 3.529}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.024365508630580734, "policy_loss": -0.029462382139172405, "vf_loss": 0.00018592619755963824, "vf_explained_var": 0.9200299978256226, "kl": 0.009700635389890522, "entropy": 1.207658015191555, "entropy_coeff": 0.0}}, "num_steps_sampled": 268000, "num_steps_trained": 268000}, "done": false, "episodes_total": 87, "training_iteration": 67, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-46-57", "timestamp": 1619873217, "time_this_iter_s": 15.712269306182861, "time_total_s": 1016.8319456577301, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69de18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d950>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1016.8319456577301, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 21.931818181818183, "ram_util_percent": 58.01363636363635}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.3696938202247191, "episode_len_mean": 2965.876404494382, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.3696938202247191}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004000000000000002, 0.0047500000000000025, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.004000000000000002, 0.0047500000000000025, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9487355869172042, "mean_raw_obs_processing_ms": 0.8884862779033632, "mean_inference_ms": 1.0308235632444478, "mean_action_processing_ms": 0.04440153486185724}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 272000, "timers": {"sample_time_ms": 3156.953, "sample_throughput": 1267.044, "learn_time_ms": 12077.874, "learn_throughput": 331.184, "update_time_ms": 3.437}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.0074075572192668915, "policy_loss": -0.011129551101475954, "vf_loss": 0.0004707709715603414, "vf_explained_var": 0.8463544249534607, "kl": 0.006422163947718218, "entropy": 1.0524724870920181, "entropy_coeff": 0.0}}, "num_steps_sampled": 272000, "num_steps_trained": 272000}, "done": false, "episodes_total": 89, "training_iteration": 68, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-47-13", "timestamp": 1619873233, "time_this_iter_s": 15.811829090118408, "time_total_s": 1032.6437747478485, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600620>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec600400>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1032.6437747478485, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 20.04782608695652, "ram_util_percent": 58.01739130434781}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.36149999999999993, "episode_len_mean": 2988.6483516483518, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.36149999999999993}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.0037500000000000016, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0025000000000000005, 0.0037500000000000016, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025]}, "sampler_perf": {"mean_env_wait_ms": 0.9486090720575303, "mean_raw_obs_processing_ms": 0.8885762055146651, "mean_inference_ms": 1.0307442149537944, "mean_action_processing_ms": 0.04440250134356041}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 276000, "timers": {"sample_time_ms": 3153.704, "sample_throughput": 1268.35, "learn_time_ms": 12094.105, "learn_throughput": 330.74, "update_time_ms": 3.522}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02437642397126183, "policy_loss": -0.029869754129322246, "vf_loss": 2.1140295643817808e-05, "vf_explained_var": 0.679429829120636, "kl": 0.010809265484567732, "entropy": 1.1354464292526245, "entropy_coeff": 0.0}}, "num_steps_sampled": 276000, "num_steps_trained": 276000}, "done": false, "episodes_total": 91, "training_iteration": 69, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-47-28", "timestamp": 1619873248, "time_this_iter_s": 15.331183910369873, "time_total_s": 1047.9749586582184, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6002f0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fa60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1047.9749586582184, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 19.88636363636364, "ram_util_percent": 58.02272727272725}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.36150000000000004, "episode_len_mean": 2988.6483516483518, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.36150000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016]}, "sampler_perf": {"mean_env_wait_ms": 0.9486090720575303, "mean_raw_obs_processing_ms": 0.8885762055146651, "mean_inference_ms": 1.0307442149537944, "mean_action_processing_ms": 0.04440250134356041}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 280000, "timers": {"sample_time_ms": 3142.166, "sample_throughput": 1273.007, "learn_time_ms": 12081.682, "learn_throughput": 331.08, "update_time_ms": 3.498}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02756609019706957, "policy_loss": -0.03402666316833347, "vf_loss": 0.00013020399046581588, "vf_explained_var": 0.5719798803329468, "kl": 0.012504428246757016, "entropy": 1.1765864491462708, "entropy_coeff": 0.0}}, "num_steps_sampled": 280000, "num_steps_trained": 280000}, "done": false, "episodes_total": 91, "training_iteration": 70, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-47-44", "timestamp": 1619873264, "time_this_iter_s": 15.435581922531128, "time_total_s": 1063.4105405807495, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69de18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d950>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1063.4105405807495, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 19.799999999999997, "ram_util_percent": 58.00454545454545}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.006500000000000004, "episode_reward_min": -1.0, "episode_reward_mean": -0.36150000000000004, "episode_len_mean": 2988.6483516483518, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.006500000000000004}, "policy_reward_mean": {"pol": -0.36150000000000004}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016]}, "sampler_perf": {"mean_env_wait_ms": 0.9486090720575303, "mean_raw_obs_processing_ms": 0.8885762055146651, "mean_inference_ms": 1.0307442149537944, "mean_action_processing_ms": 0.04440250134356041}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 284000, "timers": {"sample_time_ms": 3161.836, "sample_throughput": 1265.088, "learn_time_ms": 12119.894, "learn_throughput": 330.036, "update_time_ms": 3.512}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02818279733764939, "policy_loss": -0.034379898104816675, "vf_loss": 1.9174475085037557e-05, "vf_explained_var": 0.32986313104629517, "kl": 0.012203316116938367, "entropy": 1.1928226165473461, "entropy_coeff": 0.0}}, "num_steps_sampled": 284000, "num_steps_trained": 284000}, "done": false, "episodes_total": 91, "training_iteration": 71, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-47-59", "timestamp": 1619873279, "time_this_iter_s": 15.317222118377686, "time_total_s": 1078.7277626991272, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1078.7277626991272, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 18.795454545454543, "ram_util_percent": 57.98636363636365}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.35358333333333347, "episode_len_mean": 3010.440860215054, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.35358333333333347}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003250000000000001, 0.010000000000000007, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.003250000000000001, 0.010000000000000007, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016]}, "sampler_perf": {"mean_env_wait_ms": 0.9485964195500255, "mean_raw_obs_processing_ms": 0.8889662912584121, "mean_inference_ms": 1.0309130657818253, "mean_action_processing_ms": 0.044399363765505365}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 288000, "timers": {"sample_time_ms": 3202.355, "sample_throughput": 1249.081, "learn_time_ms": 12144.057, "learn_throughput": 329.379, "update_time_ms": 3.646}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.023398353543598205, "policy_loss": -0.02913263440132141, "vf_loss": 0.0001525585861372747, "vf_explained_var": 0.8044620156288147, "kl": 0.011025612329831347, "entropy": 1.182640366256237, "entropy_coeff": 0.0}}, "num_steps_sampled": 288000, "num_steps_trained": 288000}, "done": false, "episodes_total": 93, "training_iteration": 72, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-48-15", "timestamp": 1619873295, "time_this_iter_s": 15.82738971710205, "time_total_s": 1094.5551524162292, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6008c8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1094.5551524162292, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 20.922727272727272, "ram_util_percent": 58.01818181818181}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.3460315789473685, "episode_len_mean": 3031.315789473684, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.3460315789473685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0037500000000000016, 0.006500000000000004, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0037500000000000016, 0.006500000000000004, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007]}, "sampler_perf": {"mean_env_wait_ms": 0.948495345486748, "mean_raw_obs_processing_ms": 0.8891188472045434, "mean_inference_ms": 1.0308609233021337, "mean_action_processing_ms": 0.04440129594066444}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 292000, "timers": {"sample_time_ms": 3232.567, "sample_throughput": 1237.407, "learn_time_ms": 12167.288, "learn_throughput": 328.75, "update_time_ms": 3.68}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.025821112445555627, "policy_loss": -0.03311927174217999, "vf_loss": 1.9581568096782576e-05, "vf_explained_var": 0.5040472745895386, "kl": 0.014377434068592265, "entropy": 1.197405282407999, "entropy_coeff": 0.0}}, "num_steps_sampled": 292000, "num_steps_trained": 292000}, "done": false, "episodes_total": 95, "training_iteration": 73, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-48-31", "timestamp": 1619873311, "time_this_iter_s": 16.051774978637695, "time_total_s": 1110.606927394867, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69db70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1110.606927394867, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 22.32608695652174, "ram_util_percent": 58.04347826086955}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.34603157894736847, "episode_len_mean": 3031.315789473684, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.34603157894736847}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9484953454867481, "mean_raw_obs_processing_ms": 0.8891188472045436, "mean_inference_ms": 1.0308609233021337, "mean_action_processing_ms": 0.04440129594066444}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 296000, "timers": {"sample_time_ms": 3235.588, "sample_throughput": 1236.251, "learn_time_ms": 12193.379, "learn_throughput": 328.047, "update_time_ms": 3.705}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.045052532805129886, "policy_loss": -0.051568583061452955, "vf_loss": 1.3509609601669581e-05, "vf_explained_var": 0.35239338874816895, "kl": 0.012844525859691203, "entropy": 1.2019276395440102, "entropy_coeff": 0.0}}, "num_steps_sampled": 296000, "num_steps_trained": 296000}, "done": false, "episodes_total": 95, "training_iteration": 74, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-48-47", "timestamp": 1619873327, "time_this_iter_s": 15.567438840866089, "time_total_s": 1126.174366235733, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6000d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6009d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1126.174366235733, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 19.79565217391304, "ram_util_percent": 58.01739130434782}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.34603157894736847, "episode_len_mean": 3031.315789473684, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.34603157894736847}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9484953454867481, "mean_raw_obs_processing_ms": 0.8891188472045436, "mean_inference_ms": 1.0308609233021337, "mean_action_processing_ms": 0.04440129594066444}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 300000, "timers": {"sample_time_ms": 3235.017, "sample_throughput": 1236.469, "learn_time_ms": 12138.546, "learn_throughput": 329.529, "update_time_ms": 3.922}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.015238527761539444, "policy_loss": -0.0193715768691618, "vf_loss": 7.320741090666161e-06, "vf_explained_var": 0.07186967134475708, "kl": 0.008149577784934081, "entropy": 1.22479797154665, "entropy_coeff": 0.0}}, "num_steps_sampled": 300000, "num_steps_trained": 300000}, "done": false, "episodes_total": 95, "training_iteration": 75, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-49-02", "timestamp": 1619873342, "time_this_iter_s": 14.90259337425232, "time_total_s": 1141.0769596099854, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec600d08>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1141.0769596099854, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 20.514285714285716, "ram_util_percent": 58.0095238095238}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.3388453608247422, "episode_len_mean": 3051.3298969072166, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.3388453608247422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005000000000000003, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005000000000000003, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9484906926848128, "mean_raw_obs_processing_ms": 0.8895135424637362, "mean_inference_ms": 1.031033306405715, "mean_action_processing_ms": 0.044398724549697996}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 304000, "timers": {"sample_time_ms": 3211.586, "sample_throughput": 1245.491, "learn_time_ms": 12207.125, "learn_throughput": 327.677, "update_time_ms": 4.031}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.024717451684409752, "policy_loss": -0.02742120629409328, "vf_loss": 5.369208331273967e-06, "vf_explained_var": 0.2935442328453064, "kl": 0.005330143198079895, "entropy": 1.26953986287117, "entropy_coeff": 0.0}}, "num_steps_sampled": 304000, "num_steps_trained": 304000}, "done": false, "episodes_total": 97, "training_iteration": 76, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-49-16", "timestamp": 1619873356, "time_this_iter_s": 14.35434865951538, "time_total_s": 1155.4313082695007, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69db70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1155.4313082695007, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 20.004761904761907, "ram_util_percent": 58.02857142857141}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.33191161616161613, "episode_len_mean": 3070.5353535353534, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.33191161616161613}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.006250000000000004, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0], "episode_lengths": [4002, 4002, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0025000000000000005, 0.006250000000000004, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9483897573435441, "mean_raw_obs_processing_ms": 0.8895910377854253, "mean_inference_ms": 1.0309735236187048, "mean_action_processing_ms": 0.044400184672311604}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 308000, "timers": {"sample_time_ms": 3179.963, "sample_throughput": 1257.876, "learn_time_ms": 12216.067, "learn_throughput": 327.438, "update_time_ms": 4.046}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.01174456495209597, "policy_loss": -0.01590137236053124, "vf_loss": 2.0402318654078044e-05, "vf_explained_var": -0.7818635702133179, "kl": 0.008170679153408855, "entropy": 1.226453971117735, "entropy_coeff": 0.0}}, "num_steps_sampled": 308000, "num_steps_trained": 308000}, "done": false, "episodes_total": 99, "training_iteration": 77, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-49-32", "timestamp": 1619873372, "time_this_iter_s": 15.486669540405273, "time_total_s": 1170.917977809906, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6070d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1170.917977809906, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 19.5, "ram_util_percent": 57.990909090909106}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.33191161616161613, "episode_len_mean": 3070.5353535353534, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.33191161616161613}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004], "episode_lengths": [433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.948389757343544, "mean_raw_obs_processing_ms": 0.8895910377854255, "mean_inference_ms": 1.0309735236187048, "mean_action_processing_ms": 0.044400184672311604}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 312000, "timers": {"sample_time_ms": 3163.797, "sample_throughput": 1264.304, "learn_time_ms": 12159.914, "learn_throughput": 328.95, "update_time_ms": 4.107}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.026520457991864532, "policy_loss": -0.03179186733905226, "vf_loss": 5.565678900865123e-06, "vf_explained_var": 0.0023605208843946457, "kl": 0.010401666368125007, "entropy": 1.2053971663117409, "entropy_coeff": 0.0}}, "num_steps_sampled": 312000, "num_steps_trained": 312000}, "done": false, "episodes_total": 99, "training_iteration": 78, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-49-47", "timestamp": 1619873387, "time_this_iter_s": 15.083423852920532, "time_total_s": 1186.0014016628265, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607e18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6079d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1186.0014016628265, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 20.009523809523813, "ram_util_percent": 58.080952380952375}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.33859249999999996, "episode_len_mean": 3078.09, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.33859249999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004], "episode_lengths": [3826, 433, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9483423487983643, "mean_raw_obs_processing_ms": 0.8895623868194987, "mean_inference_ms": 1.0310900832131475, "mean_action_processing_ms": 0.044396545782999314}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 316000, "timers": {"sample_time_ms": 3179.131, "sample_throughput": 1258.206, "learn_time_ms": 12154.517, "learn_throughput": 329.096, "update_time_ms": 4.089}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.037217609671643004, "policy_loss": -0.042617290397174656, "vf_loss": 0.0006852714061551524, "vf_explained_var": 0.921622633934021, "kl": 0.009312417198088951, "entropy": 1.2437821812927723, "entropy_coeff": 0.0}}, "num_steps_sampled": 316000, "num_steps_trained": 316000}, "done": false, "episodes_total": 100, "training_iteration": 79, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-50-02", "timestamp": 1619873402, "time_this_iter_s": 15.432726621627808, "time_total_s": 1201.4341282844543, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6077b8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bc80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1201.4341282844543, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 20.499999999999996, "ram_util_percent": 58.040909090909075}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010000000000000007, "episode_reward_min": -1.0, "episode_reward_mean": -0.3285625, "episode_len_mean": 3113.78, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010000000000000007}, "policy_reward_mean": {"pol": -0.3285625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003000000000000001, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0], "episode_lengths": [4002, 516, 293, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826], "policy_pol_reward": [0.003000000000000001, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9479536055372388, "mean_raw_obs_processing_ms": 0.8883506312901507, "mean_inference_ms": 1.030924202977591, "mean_action_processing_ms": 0.04436438525004828}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 320000, "timers": {"sample_time_ms": 3176.553, "sample_throughput": 1259.227, "learn_time_ms": 12156.082, "learn_throughput": 329.053, "update_time_ms": 4.131}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.022585851285839453, "policy_loss": -0.028355266724247485, "vf_loss": 0.0007779617790220072, "vf_explained_var": 0.602403998374939, "kl": 0.009859659854555503, "entropy": 1.1854399517178535, "entropy_coeff": 0.0}}, "num_steps_sampled": 320000, "num_steps_trained": 320000}, "done": false, "episodes_total": 101, "training_iteration": 80, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-50-18", "timestamp": 1619873418, "time_this_iter_s": 15.429300785064697, "time_total_s": 1216.863429069519, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607400>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69db70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1216.863429069519, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 20.650000000000002, "ram_util_percent": 57.99999999999998}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010750000000000008, "episode_reward_min": -1.0, "episode_reward_mean": -0.308395, "episode_len_mean": 3185.73, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010750000000000008}, "policy_reward_mean": {"pol": -0.308395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.010750000000000008, 0.006000000000000004, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001], "episode_lengths": [4002, 4002, 260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002], "policy_pol_reward": [0.010750000000000008, 0.006000000000000004, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.947428203237367, "mean_raw_obs_processing_ms": 0.883658974971654, "mean_inference_ms": 1.0304449046082125, "mean_action_processing_ms": 0.044325883907560176}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 324000, "timers": {"sample_time_ms": 3160.817, "sample_throughput": 1265.495, "learn_time_ms": 12157.687, "learn_throughput": 329.01, "update_time_ms": 4.174}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.0353761809237767, "policy_loss": -0.042790768638951704, "vf_loss": 2.38796567089139e-05, "vf_explained_var": 0.7612635493278503, "kl": 0.014598929061321542, "entropy": 1.1823706179857254, "entropy_coeff": 0.0}}, "num_steps_sampled": 324000, "num_steps_trained": 324000}, "done": false, "episodes_total": 103, "training_iteration": 81, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-50-33", "timestamp": 1619873433, "time_this_iter_s": 15.176602840423584, "time_total_s": 1232.0400319099426, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bc80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1232.0400319099426, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 19.277272727272727, "ram_util_percent": 58.0681818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010750000000000008, "episode_reward_min": -1.0, "episode_reward_mean": -0.3083949999999999, "episode_len_mean": 3185.73, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010750000000000008}, "policy_reward_mean": {"pol": -0.3083949999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004], "episode_lengths": [260, 1011, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9474282032373671, "mean_raw_obs_processing_ms": 0.8836589749716539, "mean_inference_ms": 1.0304449046082125, "mean_action_processing_ms": 0.044325883907560176}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 328000, "timers": {"sample_time_ms": 3128.864, "sample_throughput": 1278.419, "learn_time_ms": 12227.468, "learn_throughput": 327.132, "update_time_ms": 4.193}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.03351420478429645, "policy_loss": -0.0411065224907361, "vf_loss": 0.00010014309839334601, "vf_explained_var": 0.522612452507019, "kl": 0.0147993533173576, "entropy": 1.1487081237137318, "entropy_coeff": 0.0}}, "num_steps_sampled": 328000, "num_steps_trained": 328000}, "done": false, "episodes_total": 103, "training_iteration": 82, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-50-49", "timestamp": 1619873449, "time_this_iter_s": 16.20604658126831, "time_total_s": 1248.246078491211, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dc80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6077b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1248.246078491211, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 22.617391304347823, "ram_util_percent": 58.08695652173911}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010750000000000008, "episode_reward_min": -1.0, "episode_reward_mean": -0.2983475, "episode_len_mean": 3236.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010750000000000008}, "policy_reward_mean": {"pol": -0.2983475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.998, 0.0027500000000000007, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004], "episode_lengths": [2334, 4002, 379, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002], "policy_pol_reward": [-0.998, 0.0027500000000000007, -1.0, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9472168379352037, "mean_raw_obs_processing_ms": 0.8798987759306602, "mean_inference_ms": 1.0304088439149317, "mean_action_processing_ms": 0.04430977949995758}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 332000, "timers": {"sample_time_ms": 3101.836, "sample_throughput": 1289.559, "learn_time_ms": 12171.769, "learn_throughput": 328.629, "update_time_ms": 3.972}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.0245373084617313, "policy_loss": -0.030826793401502073, "vf_loss": 0.001121081485052855, "vf_explained_var": 0.8871277570724487, "kl": 0.01020918863650877, "entropy": 1.173943616449833, "entropy_coeff": 0.0}}, "num_steps_sampled": 332000, "num_steps_trained": 332000}, "done": false, "episodes_total": 105, "training_iteration": 83, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-51-05", "timestamp": 1619873465, "time_this_iter_s": 15.223582029342651, "time_total_s": 1263.4696605205536, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6079d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1263.4696605205536, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 19.740909090909092, "ram_util_percent": 57.98636363636364}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.010750000000000008, "episode_reward_min": -1.0, "episode_reward_mean": -0.288315, "episode_len_mean": 3272.61, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.010750000000000008}, "policy_reward_mean": {"pol": -0.288315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003250000000000001, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007], "episode_lengths": [4002, 4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002], "policy_pol_reward": [0.003250000000000001, 0.0, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007]}, "sampler_perf": {"mean_env_wait_ms": 0.9471482194617182, "mean_raw_obs_processing_ms": 0.8789646851539987, "mean_inference_ms": 1.0303273435147868, "mean_action_processing_ms": 0.04430405307055645}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 336000, "timers": {"sample_time_ms": 3104.812, "sample_throughput": 1288.323, "learn_time_ms": 12054.162, "learn_throughput": 331.836, "update_time_ms": 4.025}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.015923221508273855, "policy_loss": -0.01975193462567404, "vf_loss": 3.30781909099187e-05, "vf_explained_var": 0.7737868428230286, "kl": 0.007497550104744732, "entropy": 1.1533431112766266, "entropy_coeff": 0.0}}, "num_steps_sampled": 336000, "num_steps_trained": 336000}, "done": false, "episodes_total": 106, "training_iteration": 84, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-51-19", "timestamp": 1619873479, "time_this_iter_s": 14.421146392822266, "time_total_s": 1277.8908069133759, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607620>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec606a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1277.8908069133759, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 20.200000000000006, "ram_util_percent": 58.01904761904761}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2881875, "episode_len_mean": 3272.61, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2881875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.01275000000000001, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001], "episode_lengths": [4002, 162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002], "policy_pol_reward": [0.01275000000000001, -1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9469073560804852, "mean_raw_obs_processing_ms": 0.8798971172531378, "mean_inference_ms": 1.0303983621676402, "mean_action_processing_ms": 0.044296659633457025}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 340000, "timers": {"sample_time_ms": 3098.099, "sample_throughput": 1291.114, "learn_time_ms": 12085.458, "learn_throughput": 330.976, "update_time_ms": 3.91}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.022049655599403195, "policy_loss": -0.02629443514160812, "vf_loss": 0.00011172477024956606, "vf_explained_var": 0.7288700342178345, "kl": 0.00816405436489731, "entropy": 1.0971178971230984, "entropy_coeff": 0.0}}, "num_steps_sampled": 340000, "num_steps_trained": 340000}, "done": false, "episodes_total": 107, "training_iteration": 85, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-51-34", "timestamp": 1619873494, "time_this_iter_s": 15.147766351699829, "time_total_s": 1293.0385732650757, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1293.0385732650757, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 19.428571428571427, "ram_util_percent": 58.01428571428571}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2881875, "episode_len_mean": 3272.61, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2881875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001], "episode_lengths": [162, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002], "policy_pol_reward": [-1.0, 0.0035000000000000014, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9469073560804852, "mean_raw_obs_processing_ms": 0.8798971172531378, "mean_inference_ms": 1.0303983621676402, "mean_action_processing_ms": 0.044296659633457025}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 344000, "timers": {"sample_time_ms": 3106.545, "sample_throughput": 1287.604, "learn_time_ms": 12149.509, "learn_throughput": 329.231, "update_time_ms": 3.913}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.012397584039717913, "policy_loss": -0.016793378541478887, "vf_loss": 7.916450567790889e-05, "vf_explained_var": 0.860503077507019, "kl": 0.008526673685992137, "entropy": 1.1414597444236279, "entropy_coeff": 0.0}}, "num_steps_sampled": 344000, "num_steps_trained": 344000}, "done": false, "episodes_total": 107, "training_iteration": 86, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-51-49", "timestamp": 1619873509, "time_this_iter_s": 15.079377889633179, "time_total_s": 1308.1179511547089, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec606048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bb70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1308.1179511547089, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 57.968181818181826}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.27817000000000003, "episode_len_mean": 3311.01, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.27817000000000003}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0037500000000000016, 0.0015, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001], "episode_lengths": [4002, 4002, 4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002], "policy_pol_reward": [0.0037500000000000016, 0.0015, 0.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9467197406662254, "mean_raw_obs_processing_ms": 0.8803832240540989, "mean_inference_ms": 1.0306317610139843, "mean_action_processing_ms": 0.04429313442675817}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 348000, "timers": {"sample_time_ms": 3126.267, "sample_throughput": 1279.481, "learn_time_ms": 12094.92, "learn_throughput": 330.717, "update_time_ms": 3.93}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.006286184652708471, "policy_loss": -0.010364517103880644, "vf_loss": 0.000172644505369135, "vf_explained_var": 0.3450557589530945, "kl": 0.007714937251876108, "entropy": 1.1715332046151161, "entropy_coeff": 0.0}}, "num_steps_sampled": 348000, "num_steps_trained": 348000}, "done": false, "episodes_total": 109, "training_iteration": 87, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-52-05", "timestamp": 1619873525, "time_this_iter_s": 15.139882802963257, "time_total_s": 1323.2578339576721, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec606ea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1323.2578339576721, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 18.345454545454547, "ram_util_percent": 58.02272727272726}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.27814249999999996, "episode_len_mean": 3311.01, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.27814249999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0027500000000000007, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015], "episode_lengths": [4002, 655, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0027500000000000007, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015]}, "sampler_perf": {"mean_env_wait_ms": 0.9468591777068078, "mean_raw_obs_processing_ms": 0.880302259882034, "mean_inference_ms": 1.0307619507252475, "mean_action_processing_ms": 0.04429939567205334}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 352000, "timers": {"sample_time_ms": 3105.863, "sample_throughput": 1287.887, "learn_time_ms": 12094.404, "learn_throughput": 330.731, "update_time_ms": 3.966}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.024778199091088027, "policy_loss": -0.031220459786709398, "vf_loss": 1.4837108803789079e-06, "vf_explained_var": 0.6653099060058594, "kl": 0.012722526720608585, "entropy": 1.2233575358986855, "entropy_coeff": 0.0}}, "num_steps_sampled": 352000, "num_steps_trained": 352000}, "done": false, "episodes_total": 110, "training_iteration": 88, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-52-20", "timestamp": 1619873540, "time_this_iter_s": 14.874309778213501, "time_total_s": 1338.1321437358856, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69db70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1338.1321437358856, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 18.014285714285716, "ram_util_percent": 58.019047619047626}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2680525, "episode_len_mean": 3344.48, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2680525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.009000000000000006, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007], "episode_lengths": [4002, 4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.009000000000000006, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007]}, "sampler_perf": {"mean_env_wait_ms": 0.9467710689615177, "mean_raw_obs_processing_ms": 0.8800401106197578, "mean_inference_ms": 1.0307504460368206, "mean_action_processing_ms": 0.044299068707061295}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 356000, "timers": {"sample_time_ms": 3089.931, "sample_throughput": 1294.527, "learn_time_ms": 12065.447, "learn_throughput": 331.525, "update_time_ms": 4.068}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.018668098986381665, "policy_loss": -0.02328274678438902, "vf_loss": 5.008350122182037e-06, "vf_explained_var": 0.7787594795227051, "kl": 0.009105462304432876, "entropy": 1.252101756632328, "entropy_coeff": 0.0}}, "num_steps_sampled": 356000, "num_steps_trained": 356000}, "done": false, "episodes_total": 111, "training_iteration": 89, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-52-35", "timestamp": 1619873555, "time_this_iter_s": 14.981209516525269, "time_total_s": 1353.113353252411, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607f28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6070d0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1353.113353252411, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 18.06666666666667, "ram_util_percent": 57.98571428571428}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.26805249999999997, "episode_len_mean": 3344.48, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.26805249999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006], "episode_lengths": [4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006]}, "sampler_perf": {"mean_env_wait_ms": 0.9467710689615177, "mean_raw_obs_processing_ms": 0.8800401106197577, "mean_inference_ms": 1.0307504460368209, "mean_action_processing_ms": 0.044299068707061295}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 360000, "timers": {"sample_time_ms": 3086.514, "sample_throughput": 1295.96, "learn_time_ms": 12088.654, "learn_throughput": 330.889, "update_time_ms": 4.024}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.03763213014462963, "policy_loss": -0.04433319624513388, "vf_loss": 1.7380941358169366e-05, "vf_explained_var": 0.7376437187194824, "kl": 0.01320233556907624, "entropy": 1.1003762520849705, "entropy_coeff": 0.0}}, "num_steps_sampled": 360000, "num_steps_trained": 360000}, "done": false, "episodes_total": 111, "training_iteration": 90, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-52-50", "timestamp": 1619873570, "time_this_iter_s": 15.625619411468506, "time_total_s": 1368.7389726638794, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607d08>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec608a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1368.7389726638794, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 18.01739130434783, "ram_util_percent": 58.02608695652172}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.268, "episode_len_mean": 3344.48, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.268}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.005250000000000003, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006], "episode_lengths": [4002, 4002, 4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.005250000000000003, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006]}, "sampler_perf": {"mean_env_wait_ms": 0.9468033833481176, "mean_raw_obs_processing_ms": 0.8814831371913331, "mean_inference_ms": 1.0309000199860017, "mean_action_processing_ms": 0.044299384156237485}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 364000, "timers": {"sample_time_ms": 3102.439, "sample_throughput": 1289.308, "learn_time_ms": 12141.492, "learn_throughput": 329.449, "update_time_ms": 3.934}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.031087806812138297, "policy_loss": -0.039626100508030504, "vf_loss": 7.077024392287967e-06, "vf_explained_var": 0.5839977264404297, "kl": 0.016851786203915253, "entropy": 1.0893542505800724, "entropy_coeff": 0.0}}, "num_steps_sampled": 364000, "num_steps_trained": 364000}, "done": false, "episodes_total": 113, "training_iteration": 91, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-53-06", "timestamp": 1619873586, "time_this_iter_s": 15.868207931518555, "time_total_s": 1384.607180595398, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1384.607180595398, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 21.031818181818185, "ram_util_percent": 58.09090909090908}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.26796, "episode_len_mean": 3344.48, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.26796}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004000000000000002, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003], "episode_lengths": [4002, 473, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.004000000000000002, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9467484817458911, "mean_raw_obs_processing_ms": 0.8819376922459, "mean_inference_ms": 1.0308711199212945, "mean_action_processing_ms": 0.04429631680325247}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 368000, "timers": {"sample_time_ms": 3160.496, "sample_throughput": 1265.624, "learn_time_ms": 12068.955, "learn_throughput": 331.429, "update_time_ms": 3.905}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.018276286427862942, "policy_loss": -0.02357109816512093, "vf_loss": 8.704053549024593e-06, "vf_explained_var": 0.6655867099761963, "kl": 0.010441697377245873, "entropy": 1.0841577500104904, "entropy_coeff": 0.0}}, "num_steps_sampled": 368000, "num_steps_trained": 368000}, "done": false, "episodes_total": 114, "training_iteration": 92, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-53-22", "timestamp": 1619873602, "time_this_iter_s": 16.056793451309204, "time_total_s": 1400.6639740467072, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec608048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec608400>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1400.6639740467072, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 21.208695652173912, "ram_util_percent": 58.03478260869564}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2578975, "episode_len_mean": 3379.77, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2578975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006250000000000004, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002], "episode_lengths": [4002, 4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006250000000000004, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002]}, "sampler_perf": {"mean_env_wait_ms": 0.946457876716929, "mean_raw_obs_processing_ms": 0.8823618752870501, "mean_inference_ms": 1.0306952514458987, "mean_action_processing_ms": 0.04428642759151926}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 372000, "timers": {"sample_time_ms": 3172.554, "sample_throughput": 1260.814, "learn_time_ms": 12055.931, "learn_throughput": 331.787, "update_time_ms": 4.033}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.0226127881614957, "policy_loss": -0.02604016085388139, "vf_loss": 2.046165416658141e-06, "vf_explained_var": 0.7126579284667969, "kl": 0.006766072430764325, "entropy": 1.0631275810301304, "entropy_coeff": 0.0}}, "num_steps_sampled": 372000, "num_steps_trained": 372000}, "done": false, "episodes_total": 115, "training_iteration": 93, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-53-38", "timestamp": 1619873618, "time_this_iter_s": 15.213645696640015, "time_total_s": 1415.8776197433472, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec608e18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607e18>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1415.8776197433472, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 20.37727272727273, "ram_util_percent": 58.0590909090909}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.25789749999999995, "episode_len_mean": 3379.77, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.25789749999999995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004], "episode_lengths": [4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9464578767169293, "mean_raw_obs_processing_ms": 0.8823618752870501, "mean_inference_ms": 1.0306952514458985, "mean_action_processing_ms": 0.04428642759151925}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 376000, "timers": {"sample_time_ms": 3169.067, "sample_throughput": 1262.201, "learn_time_ms": 12159.173, "learn_throughput": 328.97, "update_time_ms": 3.985}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.015093422611244023, "policy_loss": -0.01908311975421384, "vf_loss": 2.2224280343152714e-05, "vf_explained_var": 0.6624925136566162, "kl": 0.00783698956365697, "entropy": 1.1108240596950054, "entropy_coeff": 0.0}}, "num_steps_sampled": 376000, "num_steps_trained": 376000}, "done": false, "episodes_total": 115, "training_iteration": 94, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-53-53", "timestamp": 1619873633, "time_this_iter_s": 15.415452241897583, "time_total_s": 1431.2930719852448, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dd08>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1431.2930719852448, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 20.08181818181818, "ram_util_percent": 58.218181818181826}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.25781499999999996, "episode_len_mean": 3379.77, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.25781499999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006750000000000004, 0.0015, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004], "episode_lengths": [4002, 4002, 391, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006750000000000004, 0.0015, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9466754948374438, "mean_raw_obs_processing_ms": 0.8831864186457008, "mean_inference_ms": 1.0308135737214108, "mean_action_processing_ms": 0.04429617475556022}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 380000, "timers": {"sample_time_ms": 3187.277, "sample_throughput": 1254.99, "learn_time_ms": 12163.31, "learn_throughput": 328.858, "update_time_ms": 3.874}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.028762880683643743, "policy_loss": -0.03616013936698437, "vf_loss": 2.0362629612691308e-05, "vf_explained_var": 0.6950545310974121, "kl": 0.014571646373951808, "entropy": 1.1070396192371845, "entropy_coeff": 0.0}}, "num_steps_sampled": 380000, "num_steps_trained": 380000}, "done": false, "episodes_total": 117, "training_iteration": 95, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-54-09", "timestamp": 1619873649, "time_this_iter_s": 15.371743202209473, "time_total_s": 1446.6648151874542, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607c80>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607bf8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1446.6648151874542, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 21.08181818181818, "ram_util_percent": 58.199999999999996}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.24780249999999995, "episode_len_mean": 3415.88, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.24780249999999995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00125, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.00125, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015]}, "sampler_perf": {"mean_env_wait_ms": 0.9466331990076889, "mean_raw_obs_processing_ms": 0.8834607811474704, "mean_inference_ms": 1.0308167828648516, "mean_action_processing_ms": 0.044294453633161666}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 384000, "timers": {"sample_time_ms": 3185.384, "sample_throughput": 1255.736, "learn_time_ms": 12067.22, "learn_throughput": 331.477, "update_time_ms": 3.832}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.022606258688028902, "policy_loss": -0.028627583087654784, "vf_loss": 6.301244616224722e-05, "vf_explained_var": 0.640974760055542, "kl": 0.011769506119890139, "entropy": 1.1211916841566563, "entropy_coeff": 0.0}}, "num_steps_sampled": 384000, "num_steps_trained": 384000}, "done": false, "episodes_total": 118, "training_iteration": 96, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-54-23", "timestamp": 1619873663, "time_this_iter_s": 14.097903966903687, "time_total_s": 1460.762719154358, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607378>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fa60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1460.762719154358, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 20.925, "ram_util_percent": 58.225}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.24774749999999998, "episode_len_mean": 3415.88, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.24774749999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005500000000000003, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125], "episode_lengths": [4002, 4002, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005500000000000003, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125]}, "sampler_perf": {"mean_env_wait_ms": 0.9463986059008892, "mean_raw_obs_processing_ms": 0.8845551533633723, "mean_inference_ms": 1.030789187066942, "mean_action_processing_ms": 0.044285794000381094}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 388000, "timers": {"sample_time_ms": 3163.323, "sample_throughput": 1264.493, "learn_time_ms": 12124.228, "learn_throughput": 329.918, "update_time_ms": 3.845}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.021142660436453298, "policy_loss": -0.025058334911591373, "vf_loss": 2.5714284788591613e-05, "vf_explained_var": 0.6076198220252991, "kl": 0.007683870499022305, "entropy": 1.036767564713955, "entropy_coeff": 0.0}}, "num_steps_sampled": 388000, "num_steps_trained": 388000}, "done": false, "episodes_total": 119, "training_iteration": 97, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-54-38", "timestamp": 1619873678, "time_this_iter_s": 15.4891357421875, "time_total_s": 1476.2518548965454, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1476.2518548965454, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 19.930434782608696, "ram_util_percent": 58.25217391304348}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.25773999999999997, "episode_len_mean": 3394.51, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.25773999999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99925, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003], "episode_lengths": [1865, 4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-0.99925, 0.0, 0.0, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9466508172177351, "mean_raw_obs_processing_ms": 0.8851096299670849, "mean_inference_ms": 1.0309836709805338, "mean_action_processing_ms": 0.04429500787525858}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 392000, "timers": {"sample_time_ms": 3190.777, "sample_throughput": 1253.613, "learn_time_ms": 12188.573, "learn_throughput": 328.176, "update_time_ms": 3.818}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.020964818948414177, "policy_loss": -0.030815672711469233, "vf_loss": 0.0026347255225118715, "vf_explained_var": 0.7119539976119995, "kl": 0.014254082867410034, "entropy": 1.0519781950861216, "entropy_coeff": 0.0}}, "num_steps_sampled": 392000, "num_steps_trained": 392000}, "done": false, "episodes_total": 120, "training_iteration": 98, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-54-54", "timestamp": 1619873694, "time_this_iter_s": 15.793081045150757, "time_total_s": 1492.0449359416962, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f400>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1492.0449359416962, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 19.97727272727273, "ram_util_percent": 58.33181818181817}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2576475, "episode_len_mean": 3394.51, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2576475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0035000000000000014, 0.005750000000000003, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925], "episode_lengths": [4002, 4002, 55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865], "policy_pol_reward": [0.0035000000000000014, 0.005750000000000003, -1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925]}, "sampler_perf": {"mean_env_wait_ms": 0.9467165586308331, "mean_raw_obs_processing_ms": 0.8859413444608958, "mean_inference_ms": 1.0310841435567295, "mean_action_processing_ms": 0.0443033872815102}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 396000, "timers": {"sample_time_ms": 3216.743, "sample_throughput": 1243.494, "learn_time_ms": 12239.93, "learn_throughput": 326.799, "update_time_ms": 3.731}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.018703738052863628, "policy_loss": -0.0254546677460894, "vf_loss": 0.0001699504630323645, "vf_explained_var": 0.7107862234115601, "kl": 0.012999461207073182, "entropy": 1.107152733951807, "entropy_coeff": 0.0}}, "num_steps_sampled": 396000, "num_steps_trained": 396000}, "done": false, "episodes_total": 122, "training_iteration": 99, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-55-10", "timestamp": 1619873710, "time_this_iter_s": 15.755822896957397, "time_total_s": 1507.8007588386536, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60fe18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1507.8007588386536, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 21.317391304347826, "ram_util_percent": 58.22608695652175}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2576475, "episode_len_mean": 3394.51, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2576475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003], "episode_lengths": [55, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9467165586308331, "mean_raw_obs_processing_ms": 0.8859413444608958, "mean_inference_ms": 1.0310841435567297, "mean_action_processing_ms": 0.044303387281510176}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 400000, "timers": {"sample_time_ms": 3212.534, "sample_throughput": 1245.123, "learn_time_ms": 12204.473, "learn_throughput": 327.749, "update_time_ms": 3.745}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.03310605257865973, "policy_loss": -0.038336116645950824, "vf_loss": 7.316682058444712e-05, "vf_explained_var": 0.8201610445976257, "kl": 0.010186466053710319, "entropy": 1.13446481898427, "entropy_coeff": 0.0}}, "num_steps_sampled": 400000, "num_steps_trained": 400000}, "done": false, "episodes_total": 122, "training_iteration": 100, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-55-25", "timestamp": 1619873725, "time_this_iter_s": 15.228898048400879, "time_total_s": 1523.0296568870544, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1523.0296568870544, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 19.950000000000003, "ram_util_percent": 58.35454545454545}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.247635, "episode_len_mean": 3433.98, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.247635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00125, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003], "episode_lengths": [4002, 77, 1036, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002], "policy_pol_reward": [0.00125, -1.0, -1.0, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9465060568833763, "mean_raw_obs_processing_ms": 0.8863128423589964, "mean_inference_ms": 1.0310089089458976, "mean_action_processing_ms": 0.04429889330787301}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 404000, "timers": {"sample_time_ms": 3232.758, "sample_throughput": 1237.334, "learn_time_ms": 12177.729, "learn_throughput": 328.468, "update_time_ms": 3.692}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.011282938823569566, "policy_loss": -0.014775768562685698, "vf_loss": 0.00014269951782353019, "vf_explained_var": 0.7496528625488281, "kl": 0.006617544437176548, "entropy": 1.111656405031681, "entropy_coeff": 0.0}}, "num_steps_sampled": 404000, "num_steps_trained": 404000}, "done": false, "episodes_total": 123, "training_iteration": 101, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-55-41", "timestamp": 1619873741, "time_this_iter_s": 15.797316789627075, "time_total_s": 1538.8269736766815, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1538.8269736766815, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 22.21818181818182, "ram_util_percent": 58.37727272727273}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.23756750000000001, "episode_len_mean": 3495.43, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.23756750000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.9965, 0.003250000000000001, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125], "episode_lengths": [3256, 4002, 1409, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002], "policy_pol_reward": [-0.9965, 0.003250000000000001, -0.9975, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125]}, "sampler_perf": {"mean_env_wait_ms": 0.9465583516411771, "mean_raw_obs_processing_ms": 0.8868981377766382, "mean_inference_ms": 1.0311003005448274, "mean_action_processing_ms": 0.044307412003473476}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 408000, "timers": {"sample_time_ms": 3176.175, "sample_throughput": 1259.376, "learn_time_ms": 12161.476, "learn_throughput": 328.907, "update_time_ms": 3.693}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.01331529556773603, "policy_loss": -0.020205926964990795, "vf_loss": 0.001818659960918012, "vf_explained_var": 0.49217620491981506, "kl": 0.010018709042924456, "entropy": 1.0221899915486574, "entropy_coeff": 0.0}}, "num_steps_sampled": 408000, "num_steps_trained": 408000}, "done": false, "episodes_total": 125, "training_iteration": 102, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-55-56", "timestamp": 1619873756, "time_this_iter_s": 15.329290390014648, "time_total_s": 1554.1562640666962, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607b70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec604a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1554.1562640666962, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 20.290909090909093, "ram_util_percent": 58.281818181818174}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2275675, "episode_len_mean": 3521.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2275675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002], "policy_pol_reward": [0.0025000000000000005, 0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9467294900525693, "mean_raw_obs_processing_ms": 0.8869153729817948, "mean_inference_ms": 1.0313994687613706, "mean_action_processing_ms": 0.04431320214364056}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 412000, "timers": {"sample_time_ms": 3172.197, "sample_throughput": 1260.956, "learn_time_ms": 12240.295, "learn_throughput": 326.79, "update_time_ms": 3.564}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.011143064359202981, "policy_loss": -0.01630604633828625, "vf_loss": 0.0004669862628361443, "vf_explained_var": 0.6915346384048462, "kl": 0.009276041862904094, "entropy": 1.1157792657613754, "entropy_coeff": 0.0}}, "num_steps_sampled": 412000, "num_steps_trained": 412000}, "done": false, "episodes_total": 126, "training_iteration": 103, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-56-12", "timestamp": 1619873772, "time_this_iter_s": 15.960438251495361, "time_total_s": 1570.1167023181915, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d9d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1570.1167023181915, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 19.84347826086957, "ram_util_percent": 58.286956521739114}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2275675, "episode_len_mean": 3521.36, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2275675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9467294900525693, "mean_raw_obs_processing_ms": 0.8869153729817948, "mean_inference_ms": 1.0313994687613706, "mean_action_processing_ms": 0.04431320214364056}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 416000, "timers": {"sample_time_ms": 3149.859, "sample_throughput": 1269.898, "learn_time_ms": 12270.35, "learn_throughput": 325.989, "update_time_ms": 3.574}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.0028075367445126176, "policy_loss": -0.007430437835864723, "vf_loss": 0.0006817353323640418, "vf_explained_var": 0.5448681116104126, "kl": 0.007785016598063521, "entropy": 1.067409086972475, "entropy_coeff": 0.0}}, "num_steps_sampled": 416000, "num_steps_trained": 416000}, "done": false, "episodes_total": 126, "training_iteration": 104, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-56-28", "timestamp": 1619873788, "time_this_iter_s": 15.499148607254028, "time_total_s": 1585.6158509254456, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec604048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec604400>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1585.6158509254456, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 20.213636363636365, "ram_util_percent": 58.29545454545453}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.22753999999999996, "episode_len_mean": 3521.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.22753999999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0027500000000000007, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002], "policy_pol_reward": [0.0027500000000000007, 0.0, 0.0, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9465264327427789, "mean_raw_obs_processing_ms": 0.8879878562243947, "mean_inference_ms": 1.031429854369566, "mean_action_processing_ms": 0.04430670654250199}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 420000, "timers": {"sample_time_ms": 3123.802, "sample_throughput": 1280.491, "learn_time_ms": 12258.863, "learn_throughput": 326.295, "update_time_ms": 3.573}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.027815122331958264, "policy_loss": -0.0363941861432977, "vf_loss": 0.000988961130133248, "vf_explained_var": 0.6116085052490234, "kl": 0.014992791839176789, "entropy": 0.8369040787220001, "entropy_coeff": 0.0}}, "num_steps_sampled": 420000, "num_steps_trained": 420000}, "done": false, "episodes_total": 127, "training_iteration": 105, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-56-43", "timestamp": 1619873803, "time_this_iter_s": 14.994452714920044, "time_total_s": 1600.6103036403656, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec604e18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607d90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1600.6103036403656, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 20.481818181818184, "ram_util_percent": 58.25}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2274375, "episode_len_mean": 3521.36, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2274375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004250000000000002, 0.006000000000000004, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007], "episode_lengths": [4002, 4002, 4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002], "policy_pol_reward": [0.004250000000000002, 0.006000000000000004, 0.006500000000000004, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007]}, "sampler_perf": {"mean_env_wait_ms": 0.9466707583733937, "mean_raw_obs_processing_ms": 0.888902651962691, "mean_inference_ms": 1.031446391593458, "mean_action_processing_ms": 0.044320138595588386}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 424000, "timers": {"sample_time_ms": 3139.946, "sample_throughput": 1273.907, "learn_time_ms": 12374.193, "learn_throughput": 323.253, "update_time_ms": 3.402}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.03275415451207664, "policy_loss": -0.042095195065485314, "vf_loss": 0.00011274606936240161, "vf_explained_var": 0.597524881362915, "kl": 0.018228728062240407, "entropy": 0.9042915496975183, "entropy_coeff": 0.0}}, "num_steps_sampled": 424000, "num_steps_trained": 424000}, "done": false, "episodes_total": 129, "training_iteration": 106, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-56-59", "timestamp": 1619873819, "time_this_iter_s": 15.411300897598267, "time_total_s": 1616.0216045379639, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1616.0216045379639, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 19.63636363636364, "ram_util_percent": 58.368181818181824}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.22748000000000002, "episode_len_mean": 3521.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.22748000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0022500000000000003, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004], "episode_lengths": [4002, 4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0022500000000000003, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9468278076308131, "mean_raw_obs_processing_ms": 0.8888933856107815, "mean_inference_ms": 1.0317164832364534, "mean_action_processing_ms": 0.04432517453740984}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 428000, "timers": {"sample_time_ms": 3143.83, "sample_throughput": 1272.333, "learn_time_ms": 12347.996, "learn_throughput": 323.939, "update_time_ms": 3.333}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.027420308731961995, "policy_loss": -0.03404792561195791, "vf_loss": 1.5158346599264405e-05, "vf_explained_var": 0.6083477139472961, "kl": 0.013061648525763303, "entropy": 1.0968015175312757, "entropy_coeff": 0.0}}, "num_steps_sampled": 428000, "num_steps_trained": 428000}, "done": false, "episodes_total": 130, "training_iteration": 107, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-57-14", "timestamp": 1619873834, "time_this_iter_s": 15.263336181640625, "time_total_s": 1631.2849407196045, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6070d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607ea0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1631.2849407196045, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 20.68095238095238, "ram_util_percent": 58.32380952380953}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.22748000000000002, "episode_len_mean": 3521.36, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.22748000000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003], "episode_lengths": [4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.946827807630813, "mean_raw_obs_processing_ms": 0.8888933856107815, "mean_inference_ms": 1.0317164832364534, "mean_action_processing_ms": 0.04432517453740984}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 432000, "timers": {"sample_time_ms": 3120.214, "sample_throughput": 1281.963, "learn_time_ms": 12306.453, "learn_throughput": 325.033, "update_time_ms": 3.248}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.018867385981138796, "policy_loss": -0.025384590146131814, "vf_loss": 7.49721142767612e-06, "vf_explained_var": 0.39930349588394165, "kl": 0.012858676505857147, "entropy": 1.0198425501585007, "entropy_coeff": 0.0}}, "num_steps_sampled": 432000, "num_steps_trained": 432000}, "done": false, "episodes_total": 130, "training_iteration": 108, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-57-29", "timestamp": 1619873849, "time_this_iter_s": 15.140111923217773, "time_total_s": 1646.4250526428223, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6079d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec617a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1646.4250526428223, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 19.545454545454547, "ram_util_percent": 58.30454545454545}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.22746750000000002, "episode_len_mean": 3521.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.22746750000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003], "episode_lengths": [4002, 153, 1736, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.00125, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9465941861768014, "mean_raw_obs_processing_ms": 0.8898334091597729, "mean_inference_ms": 1.0316979605383132, "mean_action_processing_ms": 0.04431662147852566}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 436000, "timers": {"sample_time_ms": 3106.601, "sample_throughput": 1287.581, "learn_time_ms": 12282.542, "learn_throughput": 325.665, "update_time_ms": 3.183}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.013558030419517308, "policy_loss": -0.018166111316531897, "vf_loss": 6.717562530411669e-05, "vf_explained_var": 0.8974825739860535, "kl": 0.008969692164100707, "entropy": 1.0635302551090717, "entropy_coeff": 0.0}}, "num_steps_sampled": 436000, "num_steps_trained": 436000}, "done": false, "episodes_total": 131, "training_iteration": 109, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-57-45", "timestamp": 1619873865, "time_this_iter_s": 15.377254486083984, "time_total_s": 1661.8023071289062, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1661.8023071289062, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 19.236363636363635, "ram_util_percent": 58.29090909090908}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.2073725, "episode_len_mean": 3582.51, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.2073725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0070000000000000045, 0.0025000000000000005, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125], "episode_lengths": [4002, 4002, 58, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0070000000000000045, 0.0025000000000000005, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125]}, "sampler_perf": {"mean_env_wait_ms": 0.9465877880299206, "mean_raw_obs_processing_ms": 0.8907658976200544, "mean_inference_ms": 1.0318215045385672, "mean_action_processing_ms": 0.044320606059965156}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 440000, "timers": {"sample_time_ms": 3134.814, "sample_throughput": 1275.993, "learn_time_ms": 12346.265, "learn_throughput": 323.985, "update_time_ms": 3.026}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02853670308832079, "policy_loss": -0.034222477916046046, "vf_loss": 0.00032726934341553715, "vf_explained_var": 0.6690083146095276, "kl": 0.010584700576146133, "entropy": 1.123166412115097, "entropy_coeff": 0.0}}, "num_steps_sampled": 440000, "num_steps_trained": 440000}, "done": false, "episodes_total": 133, "training_iteration": 110, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-58-01", "timestamp": 1619873881, "time_this_iter_s": 16.14994168281555, "time_total_s": 1677.9522488117218, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec617048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec617400>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1677.9522488117218, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 22.178260869565218, "ram_util_percent": 58.31739130434784}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.20735499999999998, "episode_len_mean": 3613.67, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.20735499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99825, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005], "episode_lengths": [3174, 29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-0.99825, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.946437958593919, "mean_raw_obs_processing_ms": 0.8905791191630378, "mean_inference_ms": 1.031893293788289, "mean_action_processing_ms": 0.044315370042043646}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 444000, "timers": {"sample_time_ms": 3097.146, "sample_throughput": 1291.512, "learn_time_ms": 12284.32, "learn_throughput": 325.618, "update_time_ms": 3.181}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02773992804577574, "policy_loss": -0.031041164824273437, "vf_loss": 4.835267355929318e-05, "vf_explained_var": 0.9935375452041626, "kl": 0.006425449093512725, "entropy": 1.2359084896743298, "entropy_coeff": 0.0}}, "num_steps_sampled": 444000, "num_steps_trained": 444000}, "done": false, "episodes_total": 134, "training_iteration": 111, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-58-16", "timestamp": 1619873896, "time_this_iter_s": 14.80320405960083, "time_total_s": 1692.7554528713226, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec617e18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec607598>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1692.7554528713226, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 19.014285714285716, "ram_util_percent": 58.23809523809525}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.20735499999999996, "episode_len_mean": 3613.67, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.20735499999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825], "episode_lengths": [29, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174], "policy_pol_reward": [-1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825]}, "sampler_perf": {"mean_env_wait_ms": 0.9464379585939191, "mean_raw_obs_processing_ms": 0.8905791191630377, "mean_inference_ms": 1.031893293788289, "mean_action_processing_ms": 0.04431537004204364}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 448000, "timers": {"sample_time_ms": 3100.816, "sample_throughput": 1289.983, "learn_time_ms": 12257.139, "learn_throughput": 326.34, "update_time_ms": 3.087}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.019429610096267425, "policy_loss": -0.024207985494285822, "vf_loss": 4.930198173269673e-06, "vf_explained_var": 0.4329785108566284, "kl": 0.009429024154087529, "entropy": 1.249964252114296, "entropy_coeff": 0.0}}, "num_steps_sampled": 448000, "num_steps_trained": 448000}, "done": false, "episodes_total": 134, "training_iteration": 112, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-58-31", "timestamp": 1619873911, "time_this_iter_s": 15.093408107757568, "time_total_s": 1707.8488609790802, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1707.8488609790802, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 17.05454545454546, "ram_util_percent": 58.35454545454545}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.19735499999999995, "episode_len_mean": 3653.4, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.19735499999999995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825], "episode_lengths": [4002, 311, 159, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825]}, "sampler_perf": {"mean_env_wait_ms": 0.9461816688333003, "mean_raw_obs_processing_ms": 0.8905743903085624, "mean_inference_ms": 1.0317859270393848, "mean_action_processing_ms": 0.044309294057234105}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 452000, "timers": {"sample_time_ms": 3083.969, "sample_throughput": 1297.03, "learn_time_ms": 12192.285, "learn_throughput": 328.076, "update_time_ms": 2.981}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.009547244757413864, "policy_loss": -0.012800190888810903, "vf_loss": 6.127509416842258e-05, "vf_explained_var": 0.9561594128608704, "kl": 0.006304532544163521, "entropy": 1.1659034714102745, "entropy_coeff": 0.0}}, "num_steps_sampled": 452000, "num_steps_trained": 452000}, "done": false, "episodes_total": 135, "training_iteration": 113, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-58-46", "timestamp": 1619873926, "time_this_iter_s": 15.14093279838562, "time_total_s": 1722.9897937774658, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607bf8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec6078c8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1722.9897937774658, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 18.15, "ram_util_percent": 58.29999999999998}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.17729249999999994, "episode_len_mean": 3728.74, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.17729249999999994}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0015, 0.0047500000000000025, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0], "episode_lengths": [4002, 4002, 186, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002], "policy_pol_reward": [0.0015, 0.0047500000000000025, -1.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9461412452468442, "mean_raw_obs_processing_ms": 0.8905480829667534, "mean_inference_ms": 1.031803521090675, "mean_action_processing_ms": 0.04431513154224958}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 456000, "timers": {"sample_time_ms": 3091.125, "sample_throughput": 1294.027, "learn_time_ms": 12191.539, "learn_throughput": 328.096, "update_time_ms": 2.836}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.011649260821286589, "policy_loss": -0.016954298363998532, "vf_loss": 0.00037737588081654394, "vf_explained_var": 0.7213639616966248, "kl": 0.009733649552799761, "entropy": 1.1522495709359646, "entropy_coeff": 0.0}}, "num_steps_sampled": 456000, "num_steps_trained": 456000}, "done": false, "episodes_total": 137, "training_iteration": 114, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-59-02", "timestamp": 1619873942, "time_this_iter_s": 15.5572350025177, "time_total_s": 1738.5470287799835, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec607f28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60da60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1738.5470287799835, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 20.413636363636364, "ram_util_percent": 58.25454545454545}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.16729249999999996, "episode_len_mean": 3766.9, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.16729249999999996}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025], "episode_lengths": [4002, 102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025]}, "sampler_perf": {"mean_env_wait_ms": 0.9459886708340579, "mean_raw_obs_processing_ms": 0.8903692405206448, "mean_inference_ms": 1.031868412971685, "mean_action_processing_ms": 0.04430957477673503}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 460000, "timers": {"sample_time_ms": 3102.72, "sample_throughput": 1289.192, "learn_time_ms": 12224.487, "learn_throughput": 327.212, "update_time_ms": 2.824}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02225375917623751, "policy_loss": -0.027605472540017217, "vf_loss": 9.275869473412968e-06, "vf_explained_var": 0.4273122251033783, "kl": 0.010552964959060773, "entropy": 1.2084227502346039, "entropy_coeff": 0.0}}, "num_steps_sampled": 460000, "num_steps_trained": 460000}, "done": false, "episodes_total": 138, "training_iteration": 115, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-59-17", "timestamp": 1619873957, "time_this_iter_s": 15.44030499458313, "time_total_s": 1753.9873337745667, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dbf8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d7b8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1753.9873337745667, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 17.013636363636362, "ram_util_percent": 58.17272727272727}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1672925, "episode_len_mean": 3766.9, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1672925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0], "episode_lengths": [102, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9459886708340579, "mean_raw_obs_processing_ms": 0.8903692405206446, "mean_inference_ms": 1.031868412971685, "mean_action_processing_ms": 0.04430957477673502}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 464000, "timers": {"sample_time_ms": 3087.959, "sample_throughput": 1295.354, "learn_time_ms": 12268.274, "learn_throughput": 326.044, "update_time_ms": 3.067}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.02769920538412407, "policy_loss": -0.03324794478248805, "vf_loss": 3.9934339888247905e-06, "vf_explained_var": 0.2376152127981186, "kl": 0.010952582801110111, "entropy": 1.242097407579422, "entropy_coeff": 0.0}}, "num_steps_sampled": 464000, "num_steps_trained": 464000}, "done": false, "episodes_total": 138, "training_iteration": 116, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-59-33", "timestamp": 1619873973, "time_this_iter_s": 15.705979585647583, "time_total_s": 1769.6933133602142, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d048>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d400>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1769.6933133602142, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 18.122727272727275, "ram_util_percent": 58.131818181818176}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1572725, "episode_len_mean": 3805.9, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1572725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.002, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0], "episode_lengths": [4002, 4002, 160, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.002, 0.0, -1.0, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9457327431010731, "mean_raw_obs_processing_ms": 0.8903805804370105, "mean_inference_ms": 1.0317566888831942, "mean_action_processing_ms": 0.04430415676039759}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 468000, "timers": {"sample_time_ms": 3092.75, "sample_throughput": 1293.347, "learn_time_ms": 12284.346, "learn_throughput": 325.618, "update_time_ms": 2.996}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.5062500000000001, "cur_lr": 5e-05, "total_loss": -0.013137215719325468, "policy_loss": -0.01564518702798523, "vf_loss": 1.4768217813099227e-06, "vf_explained_var": 0.7793724536895752, "kl": 0.004951106166117825, "entropy": 1.1974444799125195, "entropy_coeff": 0.0}}, "num_steps_sampled": 468000, "num_steps_trained": 468000}, "done": false, "episodes_total": 139, "training_iteration": 117, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_21-59-48", "timestamp": 1619873988, "time_this_iter_s": 15.478889226913452, "time_total_s": 1785.1722025871277, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73f63c41e0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1785.1722025871277, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 17.804347826086953, "ram_util_percent": 58.06956521739129}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.14718499999999998, "episode_len_mean": 3844.32, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.14718499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006250000000000004, 0.0025000000000000005, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002], "episode_lengths": [4002, 4002, 4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006250000000000004, 0.0025000000000000005, 0.0, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002]}, "sampler_perf": {"mean_env_wait_ms": 0.9458736735188213, "mean_raw_obs_processing_ms": 0.8907619798085936, "mean_inference_ms": 1.0318041312118131, "mean_action_processing_ms": 0.04431903725352049}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 472000, "timers": {"sample_time_ms": 3130.363, "sample_throughput": 1277.807, "learn_time_ms": 12285.373, "learn_throughput": 325.59, "update_time_ms": 3.138}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000004, "cur_lr": 5e-05, "total_loss": -0.016228951863013208, "policy_loss": -0.018926488235592842, "vf_loss": 0.00012413018339429982, "vf_explained_var": 0.725248396396637, "kl": 0.010166532432776876, "entropy": 1.0657258443534374, "entropy_coeff": 0.0}}, "num_steps_sampled": 472000, "num_steps_trained": 472000}, "done": false, "episodes_total": 141, "training_iteration": 118, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-00-04", "timestamp": 1619874004, "time_this_iter_s": 15.529714107513428, "time_total_s": 1800.701916694641, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d6a8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d2f0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1800.701916694641, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 20.90454545454546, "ram_util_percent": 58.045454545454525}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1471125, "episode_len_mean": 3844.32, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1471125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.007250000000000005, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005], "episode_lengths": [4002, 3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.007250000000000005, -1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9460017914648181, "mean_raw_obs_processing_ms": 0.8905541795069432, "mean_inference_ms": 1.0320777974832158, "mean_action_processing_ms": 0.04432392362794674}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 476000, "timers": {"sample_time_ms": 3159.073, "sample_throughput": 1266.194, "learn_time_ms": 12247.834, "learn_throughput": 326.588, "update_time_ms": 3.293}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000004, "cur_lr": 5e-05, "total_loss": -0.02678804419701919, "policy_loss": -0.03094777395017445, "vf_loss": 2.431897777910308e-05, "vf_explained_var": 0.5836138725280762, "kl": 0.016337430803105235, "entropy": 1.1464148573577404, "entropy_coeff": 0.0}}, "num_steps_sampled": 476000, "num_steps_trained": 476000}, "done": false, "episodes_total": 142, "training_iteration": 119, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-00-19", "timestamp": 1619874019, "time_this_iter_s": 15.290190696716309, "time_total_s": 1815.9921073913574, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60da60>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1815.9921073913574, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 23.118181818181814, "ram_util_percent": 58.09999999999998}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1471125, "episode_len_mean": 3844.32, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1471125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005], "episode_lengths": [3153, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9460017914648181, "mean_raw_obs_processing_ms": 0.8905541795069432, "mean_inference_ms": 1.0320777974832156, "mean_action_processing_ms": 0.044323923627946744}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 480000, "timers": {"sample_time_ms": 3139.581, "sample_throughput": 1274.055, "learn_time_ms": 12142.223, "learn_throughput": 329.429, "update_time_ms": 3.356}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000004, "cur_lr": 5e-05, "total_loss": -0.021689657005481422, "policy_loss": -0.026258472818881273, "vf_loss": 2.0821049332653274e-05, "vf_explained_var": 0.6458470821380615, "kl": 0.017967383551876992, "entropy": 1.1642997562885284, "entropy_coeff": 0.0}}, "num_steps_sampled": 480000, "num_steps_trained": 480000}, "done": false, "episodes_total": 142, "training_iteration": 120, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-00-34", "timestamp": 1619874034, "time_this_iter_s": 14.896443843841553, "time_total_s": 1830.888551235199, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1830.888551235199, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 19.638095238095243, "ram_util_percent": 57.99047619047619}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.13705749999999997, "episode_len_mean": 3852.81, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.13705749999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005500000000000003, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005500000000000003, 0.00125, 0.0, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9457898093050281, "mean_raw_obs_processing_ms": 0.8915482978759601, "mean_inference_ms": 1.0320911794327794, "mean_action_processing_ms": 0.0443162152146865}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 484000, "timers": {"sample_time_ms": 3162.213, "sample_throughput": 1264.937, "learn_time_ms": 12123.022, "learn_throughput": 329.951, "update_time_ms": 3.207}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.25312500000000004, "cur_lr": 5e-05, "total_loss": -0.037481026840396225, "policy_loss": -0.044537892972584814, "vf_loss": 3.3655599303017425e-06, "vf_explained_var": 0.6018218398094177, "kl": 0.027865682495757937, "entropy": 1.137187547981739, "entropy_coeff": 0.0}}, "num_steps_sampled": 484000, "num_steps_trained": 484000}, "done": false, "episodes_total": 143, "training_iteration": 121, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-00-49", "timestamp": 1619874049, "time_this_iter_s": 14.835563659667969, "time_total_s": 1845.724114894867, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69de18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d6a8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1845.724114894867, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 20.390476190476193, "ram_util_percent": 58.04761904761905}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.136985, "episode_len_mean": 3852.81, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.136985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.006000000000000004, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0025000000000000005, 0.006000000000000004, 0.0025000000000000005, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9459868581286149, "mean_raw_obs_processing_ms": 0.8919028500529699, "mean_inference_ms": 1.0322451141102698, "mean_action_processing_ms": 0.04433578793241329}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 488000, "timers": {"sample_time_ms": 3180.574, "sample_throughput": 1257.635, "learn_time_ms": 12100.987, "learn_throughput": 330.552, "update_time_ms": 3.289}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.02103314400301315, "policy_loss": -0.024136719177477062, "vf_loss": 3.566854154257726e-06, "vf_explained_var": 0.1792048215866089, "kl": 0.008164628066879231, "entropy": 1.044225288555026, "entropy_coeff": 0.0}}, "num_steps_sampled": 488000, "num_steps_trained": 488000}, "done": false, "episodes_total": 145, "training_iteration": 122, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-01-04", "timestamp": 1619874064, "time_this_iter_s": 15.05741286277771, "time_total_s": 1860.7815277576447, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d9d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60dd08>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1860.7815277576447, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 19.313636363636363, "ram_util_percent": 58.04999999999998}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1369525, "episode_len_mean": 3852.81, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1369525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005750000000000003, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005750000000000003, 0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9461432619906769, "mean_raw_obs_processing_ms": 0.891841234297492, "mean_inference_ms": 1.0325423230093445, "mean_action_processing_ms": 0.044341393347052775}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 492000, "timers": {"sample_time_ms": 3195.021, "sample_throughput": 1251.948, "learn_time_ms": 12139.556, "learn_throughput": 329.501, "update_time_ms": 3.352}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.020813657174585387, "policy_loss": -0.025115420925430954, "vf_loss": 6.055211358102497e-06, "vf_explained_var": 0.48350656032562256, "kl": 0.01131380395963788, "entropy": 1.1490666083991528, "entropy_coeff": 0.0}}, "num_steps_sampled": 492000, "num_steps_trained": 492000}, "done": false, "episodes_total": 146, "training_iteration": 123, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-01-20", "timestamp": 1619874080, "time_this_iter_s": 15.67702603340149, "time_total_s": 1876.4585537910461, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec615a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1876.4585537910461, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 20.200000000000003, "ram_util_percent": 58.01818181818182}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1369525, "episode_len_mean": 3852.81, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1369525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.004000000000000002, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9461432619906767, "mean_raw_obs_processing_ms": 0.891841234297492, "mean_inference_ms": 1.0325423230093445, "mean_action_processing_ms": 0.044341393347052775}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 496000, "timers": {"sample_time_ms": 3215.615, "sample_throughput": 1243.93, "learn_time_ms": 12155.136, "learn_throughput": 329.079, "update_time_ms": 3.483}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.024827330140396953, "policy_loss": -0.029186703788582236, "vf_loss": 1.42344498144098e-06, "vf_explained_var": 0.42709124088287354, "kl": 0.011477736436063424, "entropy": 1.1767207011580467, "entropy_coeff": 0.0}}, "num_steps_sampled": 496000, "num_steps_trained": 496000}, "done": false, "episodes_total": 146, "training_iteration": 124, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-01-36", "timestamp": 1619874096, "time_this_iter_s": 15.920482397079468, "time_total_s": 1892.3790361881256, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69df28>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1892.3790361881256, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 20.83478260869565, "ram_util_percent": 58.113043478260884}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1369175, "episode_len_mean": 3852.81, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1369175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.007500000000000005, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.007500000000000005, 0.0037500000000000016, 0.00175, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9459458662015585, "mean_raw_obs_processing_ms": 0.892820529001248, "mean_inference_ms": 1.0325695836496227, "mean_action_processing_ms": 0.044334886911696805}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 500000, "timers": {"sample_time_ms": 3216.75, "sample_throughput": 1243.491, "learn_time_ms": 12052.625, "learn_throughput": 331.878, "update_time_ms": 3.444}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.02567014953820035, "policy_loss": -0.031206946761813015, "vf_loss": 0.0001507746430888801, "vf_explained_var": 0.580756425857544, "kl": 0.014185414474923164, "entropy": 1.067135464400053, "entropy_coeff": 0.0}}, "num_steps_sampled": 500000, "num_steps_trained": 500000}, "done": false, "episodes_total": 147, "training_iteration": 125, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-01-50", "timestamp": 1619874110, "time_this_iter_s": 14.42673945426941, "time_total_s": 1906.805775642395, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6150d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec615ae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1906.805775642395, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 20.18095238095238, "ram_util_percent": 58.05714285714285}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1369375, "episode_len_mean": 3852.81, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1369375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0035000000000000014, 0.0, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0035000000000000014, 0.0, 0.0, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9461312154069603, "mean_raw_obs_processing_ms": 0.8929311045617794, "mean_inference_ms": 1.0327183143353273, "mean_action_processing_ms": 0.04435426724268935}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 504000, "timers": {"sample_time_ms": 3229.537, "sample_throughput": 1238.568, "learn_time_ms": 12015.351, "learn_throughput": 332.907, "update_time_ms": 3.417}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.023237946908921003, "policy_loss": -0.02766050468198955, "vf_loss": 4.898694135135884e-05, "vf_explained_var": 0.47951751947402954, "kl": 0.011518879153300077, "entropy": 0.9885481130331755, "entropy_coeff": 0.0}}, "num_steps_sampled": 504000, "num_steps_trained": 504000}, "done": false, "episodes_total": 149, "training_iteration": 126, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-02-06", "timestamp": 1619874126, "time_this_iter_s": 15.45961618423462, "time_total_s": 1922.2653918266296, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69de18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d048>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1922.2653918266296, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 19.695454545454545, "ram_util_percent": 58.01818181818181}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.13686, "episode_len_mean": 3852.81, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.13686}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.007750000000000005, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.007750000000000005, 0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9462825581995113, "mean_raw_obs_processing_ms": 0.8929409759081481, "mean_inference_ms": 1.0330158153909885, "mean_action_processing_ms": 0.044358984700229295}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 508000, "timers": {"sample_time_ms": 3263.911, "sample_throughput": 1225.523, "learn_time_ms": 11919.83, "learn_throughput": 335.575, "update_time_ms": 3.54}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.01420595045783557, "policy_loss": -0.01992834181874059, "vf_loss": 0.0008252529232777306, "vf_explained_var": 0.6908352375030518, "kl": 0.012897809559945017, "entropy": 0.915005762130022, "entropy_coeff": 0.0}}, "num_steps_sampled": 508000, "num_steps_trained": 508000}, "done": false, "episodes_total": 150, "training_iteration": 127, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-02-21", "timestamp": 1619874141, "time_this_iter_s": 14.861018657684326, "time_total_s": 1937.126410484314, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69df28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d1e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1937.126410484314, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 20.804761904761907, "ram_util_percent": 58.10476190476191}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.13686, "episode_len_mean": 3852.81, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.13686}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005], "episode_lengths": [4002, 4002, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0027500000000000007, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9462825581995115, "mean_raw_obs_processing_ms": 0.8929409759081481, "mean_inference_ms": 1.0330158153909885, "mean_action_processing_ms": 0.044358984700229295}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 512000, "timers": {"sample_time_ms": 3261.33, "sample_throughput": 1226.494, "learn_time_ms": 11885.129, "learn_throughput": 336.555, "update_time_ms": 3.44}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.010894290753640234, "policy_loss": -0.014266797166783363, "vf_loss": 4.482676891370829e-05, "vf_explained_var": 0.7612552046775818, "kl": 0.008764268044615164, "entropy": 0.9803972356021404, "entropy_coeff": 0.0}}, "num_steps_sampled": 512000, "num_steps_trained": 512000}, "done": false, "episodes_total": 150, "training_iteration": 128, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-02-36", "timestamp": 1619874156, "time_this_iter_s": 15.158170700073242, "time_total_s": 1952.2845811843872, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d378>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1952.2845811843872, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 19.604545454545455, "ram_util_percent": 58.136363636363626}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1468075, "episode_len_mean": 3844.41, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1468075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005250000000000003, -0.99725, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005], "episode_lengths": [4002, 3162, 4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005250000000000003, -0.99725, 0.0, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9462731458565484, "mean_raw_obs_processing_ms": 0.8940895641250982, "mean_inference_ms": 1.0331834003531073, "mean_action_processing_ms": 0.04436533558686637}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 516000, "timers": {"sample_time_ms": 3278.228, "sample_throughput": 1220.172, "learn_time_ms": 11931.8, "learn_throughput": 335.239, "update_time_ms": 3.438}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.023529650236014277, "policy_loss": -0.026959159644320607, "vf_loss": 0.0002240263347630389, "vf_explained_var": 0.9255783557891846, "kl": 0.008442426864348818, "entropy": 0.9461400583386421, "entropy_coeff": 0.0}}, "num_steps_sampled": 516000, "num_steps_trained": 516000}, "done": false, "episodes_total": 152, "training_iteration": 129, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-02-52", "timestamp": 1619874172, "time_this_iter_s": 15.9262113571167, "time_total_s": 1968.210792541504, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d8c8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec61ba60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1968.210792541504, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 20.10454545454546, "ram_util_percent": 57.99545454545454}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1467425, "episode_len_mean": 3844.41, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1467425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006500000000000004, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725], "episode_lengths": [4002, 3712, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162], "policy_pol_reward": [0.006500000000000004, -0.99725, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725]}, "sampler_perf": {"mean_env_wait_ms": 0.9463113337404971, "mean_raw_obs_processing_ms": 0.8939195760711135, "mean_inference_ms": 1.0332434472875383, "mean_action_processing_ms": 0.0443731464614468}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 520000, "timers": {"sample_time_ms": 3280.884, "sample_throughput": 1219.184, "learn_time_ms": 11962.6, "learn_throughput": 334.375, "update_time_ms": 3.404}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.014692971832118928, "policy_loss": -0.018407295632641762, "vf_loss": 2.492201044645981e-06, "vf_explained_var": 0.1180596798658371, "kl": 0.009776016740943305, "entropy": 0.9685056637972593, "entropy_coeff": 0.0}}, "num_steps_sampled": 520000, "num_steps_trained": 520000}, "done": false, "episodes_total": 153, "training_iteration": 130, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-03-07", "timestamp": 1619874187, "time_this_iter_s": 15.229196786880493, "time_total_s": 1983.4399893283844, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69df28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d1e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1983.4399893283844, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 16.58181818181818, "ram_util_percent": 58.05}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.13668999999999998, "episode_len_mean": 3847.31, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.13668999999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.008000000000000005, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004], "episode_lengths": [4002, 3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002], "policy_pol_reward": [0.008000000000000005, -0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9464583357429653, "mean_raw_obs_processing_ms": 0.8940175955550654, "mean_inference_ms": 1.033539045485774, "mean_action_processing_ms": 0.0443779164686027}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 524000, "timers": {"sample_time_ms": 3287.507, "sample_throughput": 1216.728, "learn_time_ms": 12009.464, "learn_throughput": 333.071, "update_time_ms": 3.354}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.003634188382420689, "policy_loss": -0.006498996866866946, "vf_loss": 1.0278568574051405e-06, "vf_explained_var": 0.13122504949569702, "kl": 0.007542459876276553, "entropy": 1.036954902112484, "entropy_coeff": 0.0}}, "num_steps_sampled": 524000, "num_steps_trained": 524000}, "done": false, "episodes_total": 154, "training_iteration": 131, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-03-23", "timestamp": 1619874203, "time_this_iter_s": 15.371695756912231, "time_total_s": 1998.8116850852966, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec61b0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 1998.8116850852966, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 18.504545454545454, "ram_util_percent": 58.02727272727271}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.13669, "episode_len_mean": 3847.31, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.13669}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005], "episode_lengths": [3407, 2950, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002], "policy_pol_reward": [-0.99725, -1.0, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9464583357429653, "mean_raw_obs_processing_ms": 0.8940175955550653, "mean_inference_ms": 1.0335390454857742, "mean_action_processing_ms": 0.0443779164686027}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 528000, "timers": {"sample_time_ms": 3292.616, "sample_throughput": 1214.839, "learn_time_ms": 12080.666, "learn_throughput": 331.108, "update_time_ms": 3.242}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.03354122556629591, "policy_loss": -0.0395570209948346, "vf_loss": 9.337944834442169e-05, "vf_explained_var": 0.6926838755607605, "kl": 0.015598137048073113, "entropy": 0.9887534491717815, "entropy_coeff": 0.0}}, "num_steps_sampled": 528000, "num_steps_trained": 528000}, "done": false, "episodes_total": 154, "training_iteration": 132, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-03-39", "timestamp": 1619874219, "time_this_iter_s": 15.819090843200684, "time_total_s": 2014.6307759284973, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec61bea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d598>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2014.6307759284973, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 17.726086956521737, "ram_util_percent": 57.99130434782609}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.11662499999999999, "episode_len_mean": 3863.78, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.11662499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003000000000000001, 0.006250000000000004, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002], "policy_pol_reward": [0.003000000000000001, 0.006250000000000004, 0.0022500000000000003, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9465566678548721, "mean_raw_obs_processing_ms": 0.8949526428232432, "mean_inference_ms": 1.033861953666446, "mean_action_processing_ms": 0.04438353084072281}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 532000, "timers": {"sample_time_ms": 3293.227, "sample_throughput": 1214.614, "learn_time_ms": 12079.269, "learn_throughput": 331.146, "update_time_ms": 3.336}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.02107886428711936, "policy_loss": -0.025150432891678065, "vf_loss": 3.8193894994265065e-05, "vf_explained_var": 0.5977451801300049, "kl": 0.010622885660268366, "entropy": 0.864002263173461, "entropy_coeff": 0.0}}, "num_steps_sampled": 532000, "num_steps_trained": 532000}, "done": false, "episodes_total": 156, "training_iteration": 133, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-03-54", "timestamp": 1619874234, "time_this_iter_s": 15.666381120681763, "time_total_s": 2030.297157049179, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d6a8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d1e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2030.297157049179, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 18.01818181818182, "ram_util_percent": 58.02272727272725}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.11662, "episode_len_mean": 3863.78, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.11662}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0027500000000000007, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004], "episode_lengths": [4002, 4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0027500000000000007, 0.0, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9467266811550323, "mean_raw_obs_processing_ms": 0.8954083632522141, "mean_inference_ms": 1.033893857180187, "mean_action_processing_ms": 0.04439805293014719}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 536000, "timers": {"sample_time_ms": 3280.873, "sample_throughput": 1219.188, "learn_time_ms": 12010.919, "learn_throughput": 333.03, "update_time_ms": 3.215}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.01708045377745293, "policy_loss": -0.021344913577195257, "vf_loss": 8.399712683626603e-06, "vf_explained_var": 0.8190048933029175, "kl": 0.011209370102733374, "entropy": 0.9393348786979914, "entropy_coeff": 0.0}}, "num_steps_sampled": 536000, "num_steps_trained": 536000}, "done": false, "episodes_total": 157, "training_iteration": 134, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-04-10", "timestamp": 1619874250, "time_this_iter_s": 15.112998247146606, "time_total_s": 2045.4101552963257, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2045.4101552963257, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 17.768181818181816, "ram_util_percent": 57.99545454545453}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.11655750000000001, "episode_len_mean": 3863.78, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.11655750000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006250000000000004, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007], "episode_lengths": [4002, 4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006250000000000004, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007]}, "sampler_perf": {"mean_env_wait_ms": 0.9466302071507087, "mean_raw_obs_processing_ms": 0.8953845153318062, "mean_inference_ms": 1.034032483084038, "mean_action_processing_ms": 0.044395351037324816}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 540000, "timers": {"sample_time_ms": 3289.541, "sample_throughput": 1215.975, "learn_time_ms": 12082.946, "learn_throughput": 331.045, "update_time_ms": 3.265}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.022204053937457502, "policy_loss": -0.02497690002201125, "vf_loss": 6.008263838452876e-06, "vf_explained_var": 0.9058271646499634, "kl": 0.007287144122528844, "entropy": 1.0753444209694862, "entropy_coeff": 0.0}}, "num_steps_sampled": 540000, "num_steps_trained": 540000}, "done": false, "episodes_total": 158, "training_iteration": 135, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-04-25", "timestamp": 1619874265, "time_this_iter_s": 15.234113216400146, "time_total_s": 2060.644268512726, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec613a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2060.644268512726, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 16.190909090909095, "ram_util_percent": 58.03181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.1165575, "episode_len_mean": 3863.78, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.1165575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004], "episode_lengths": [4002, 2836, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9466302071507087, "mean_raw_obs_processing_ms": 0.8953845153318063, "mean_inference_ms": 1.0340324830840377, "mean_action_processing_ms": 0.044395351037324816}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 544000, "timers": {"sample_time_ms": 3309.582, "sample_throughput": 1208.612, "learn_time_ms": 12074.555, "learn_throughput": 331.275, "update_time_ms": 3.291}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.007689505990128964, "policy_loss": -0.009849959140410647, "vf_loss": 8.50589496081966e-06, "vf_explained_var": 0.5842578411102295, "kl": 0.005667680976330303, "entropy": 1.0172497816383839, "entropy_coeff": 0.0}}, "num_steps_sampled": 544000, "num_steps_trained": 544000}, "done": false, "episodes_total": 158, "training_iteration": 136, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-04-41", "timestamp": 1619874281, "time_this_iter_s": 15.58145523071289, "time_total_s": 2076.2257237434387, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d1e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2076.2257237434387, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 18.55, "ram_util_percent": 58.02272727272727}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.10643500000000002, "episode_len_mean": 3875.44, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.10643500000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0070000000000000045, 0.005250000000000003, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004], "episode_lengths": [4002, 4002, 1531, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0070000000000000045, 0.005250000000000003, -1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9464900984308814, "mean_raw_obs_processing_ms": 0.8963341876215984, "mean_inference_ms": 1.0341978451119145, "mean_action_processing_ms": 0.044393705706351344}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 548000, "timers": {"sample_time_ms": 3291.347, "sample_throughput": 1215.308, "learn_time_ms": 12167.328, "learn_throughput": 328.749, "update_time_ms": 3.377}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.03839785512536764, "policy_loss": -0.04229838924948126, "vf_loss": 1.6394227593252708e-06, "vf_explained_var": 0.6329070925712585, "kl": 0.010268696307321079, "entropy": 1.0476890243589878, "entropy_coeff": 0.0}}, "num_steps_sampled": 548000, "num_steps_trained": 548000}, "done": false, "episodes_total": 160, "training_iteration": 137, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-04-56", "timestamp": 1619874296, "time_this_iter_s": 15.609968185424805, "time_total_s": 2091.8356919288635, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6130d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec613488>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2091.8356919288635, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 19.777272727272727, "ram_util_percent": 57.95000000000002}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.09636750000000001, "episode_len_mean": 3900.15, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.09636750000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006750000000000004, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006750000000000004, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9465643994677557, "mean_raw_obs_processing_ms": 0.8970850589461127, "mean_inference_ms": 1.0343305525061601, "mean_action_processing_ms": 0.04439752966802857}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 552000, "timers": {"sample_time_ms": 3313.501, "sample_throughput": 1207.182, "learn_time_ms": 12191.379, "learn_throughput": 328.101, "update_time_ms": 3.459}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.027043819485697895, "policy_loss": -0.03090218742727302, "vf_loss": 8.85062338085163e-06, "vf_explained_var": 0.5197038650512695, "kl": 0.010138644080143422, "entropy": 1.0238402169197798, "entropy_coeff": 0.0}}, "num_steps_sampled": 552000, "num_steps_trained": 552000}, "done": false, "episodes_total": 161, "training_iteration": 138, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-05-12", "timestamp": 1619874312, "time_this_iter_s": 15.61806869506836, "time_total_s": 2107.453760623932, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d6a8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60df28>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2107.453760623932, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 19.7, "ram_util_percent": 57.91304347826087}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.09631500000000001, "episode_len_mean": 3900.15, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.09631500000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005250000000000003, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004], "episode_lengths": [4002, 4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005250000000000003, 0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9467163583701536, "mean_raw_obs_processing_ms": 0.8974029470731095, "mean_inference_ms": 1.0346127200470314, "mean_action_processing_ms": 0.04440181062038326}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 556000, "timers": {"sample_time_ms": 3276.782, "sample_throughput": 1220.71, "learn_time_ms": 12183.051, "learn_throughput": 328.325, "update_time_ms": 3.487}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.023672279552556574, "policy_loss": -0.027463556092698127, "vf_loss": 8.764155197127366e-07, "vf_explained_var": 0.20624923706054688, "kl": 0.009982946401578374, "entropy": 1.0143544059246778, "entropy_coeff": 0.0}}, "num_steps_sampled": 556000, "num_steps_trained": 556000}, "done": false, "episodes_total": 162, "training_iteration": 139, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-05-27", "timestamp": 1619874327, "time_this_iter_s": 15.476045370101929, "time_total_s": 2122.929805994034, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d9d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2122.929805994034, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 17.27272727272727, "ram_util_percent": 58.0590909090909}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.09631500000000001, "episode_len_mean": 3900.15, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.09631500000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003], "episode_lengths": [4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9467163583701536, "mean_raw_obs_processing_ms": 0.8974029470731096, "mean_inference_ms": 1.0346127200470312, "mean_action_processing_ms": 0.044401810620383265}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 560000, "timers": {"sample_time_ms": 3306.325, "sample_throughput": 1209.803, "learn_time_ms": 12230.009, "learn_throughput": 327.064, "update_time_ms": 3.599}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.017355708812829107, "policy_loss": -0.022748404822777957, "vf_loss": 2.260232311979138e-06, "vf_explained_var": 0.12702885270118713, "kl": 0.014197028707712889, "entropy": 1.0195724684745073, "entropy_coeff": 0.0}}, "num_steps_sampled": 560000, "num_steps_trained": 560000}, "done": false, "episodes_total": 162, "training_iteration": 140, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-05-43", "timestamp": 1619874343, "time_this_iter_s": 15.99483871459961, "time_total_s": 2138.9246447086334, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60dd08>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2138.9246447086334, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 18.46521739130435, "ram_util_percent": 58.03043478260868}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.096225, "episode_len_mean": 3900.15, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.096225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005500000000000003, 0.0035000000000000014, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003], "episode_lengths": [4002, 4002, 4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005500000000000003, 0.0035000000000000014, 0.0, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9466983584666163, "mean_raw_obs_processing_ms": 0.8980690368770027, "mean_inference_ms": 1.0346808098821842, "mean_action_processing_ms": 0.04441086412242015}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 564000, "timers": {"sample_time_ms": 3295.51, "sample_throughput": 1213.773, "learn_time_ms": 12211.593, "learn_throughput": 327.558, "update_time_ms": 3.734}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.37968750000000007, "cur_lr": 5e-05, "total_loss": -0.035234894981840625, "policy_loss": -0.04380529289483093, "vf_loss": 2.1270098926606806e-05, "vf_explained_var": 0.4951089918613434, "kl": 0.022516222670674324, "entropy": 1.1063698753714561, "entropy_coeff": 0.0}}, "num_steps_sampled": 564000, "num_steps_trained": 564000}, "done": false, "episodes_total": 164, "training_iteration": 141, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-05-59", "timestamp": 1619874359, "time_this_iter_s": 15.077844381332397, "time_total_s": 2154.002489089966, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60da60>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec61aa60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2154.002489089966, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 18.22857142857143, "ram_util_percent": 57.9904761904762}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.09619749999999999, "episode_len_mean": 3900.15, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.09619749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0027500000000000007, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014], "episode_lengths": [4002, 3043, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0027500000000000007, -1.0, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014]}, "sampler_perf": {"mean_env_wait_ms": 0.9467689935743236, "mean_raw_obs_processing_ms": 0.8986343384527846, "mean_inference_ms": 1.0347919241503765, "mean_action_processing_ms": 0.044414365002915374}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 568000, "timers": {"sample_time_ms": 3297.448, "sample_throughput": 1213.059, "learn_time_ms": 12203.902, "learn_throughput": 327.764, "update_time_ms": 3.898}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5e-05, "total_loss": -0.01687986234901473, "policy_loss": -0.019733537861611694, "vf_loss": 1.1411794975657585e-06, "vf_explained_var": 0.4176693558692932, "kl": 0.005008560692658648, "entropy": 1.044881546869874, "entropy_coeff": 0.0}}, "num_steps_sampled": 568000, "num_steps_trained": 568000}, "done": false, "episodes_total": 165, "training_iteration": 142, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-06-14", "timestamp": 1619874374, "time_this_iter_s": 15.765981435775757, "time_total_s": 2169.7684705257416, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d9d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2169.7684705257416, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 16.791304347826088, "ram_util_percent": 58.078260869565206}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.08616749999999998, "episode_len_mean": 3909.74, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.08616749999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003000000000000001, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007], "episode_lengths": [4002, 4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.003000000000000001, 0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007]}, "sampler_perf": {"mean_env_wait_ms": 0.9467842299876985, "mean_raw_obs_processing_ms": 0.8992370319079831, "mean_inference_ms": 1.0348731122189037, "mean_action_processing_ms": 0.044417189367193126}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 572000, "timers": {"sample_time_ms": 3318.054, "sample_throughput": 1205.526, "learn_time_ms": 12058.698, "learn_throughput": 331.711, "update_time_ms": 4.089}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5e-05, "total_loss": -0.01530424552038312, "policy_loss": -0.0208239242201671, "vf_loss": 2.772353060009891e-06, "vf_explained_var": -0.27615922689437866, "kl": 0.009686742676422, "entropy": 1.0515527352690697, "entropy_coeff": 0.0}}, "num_steps_sampled": 572000, "num_steps_trained": 572000}, "done": false, "episodes_total": 166, "training_iteration": 143, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-06-29", "timestamp": 1619874389, "time_this_iter_s": 14.421720027923584, "time_total_s": 2184.190190553665, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec61a0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2184.190190553665, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 18.29, "ram_util_percent": 58.035000000000004}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.08616749999999998, "episode_len_mean": 3909.74, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.08616749999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001], "episode_lengths": [4002, 2840, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -0.99775, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9467842299876985, "mean_raw_obs_processing_ms": 0.8992370319079831, "mean_inference_ms": 1.0348731122189034, "mean_action_processing_ms": 0.04441718936719312}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 576000, "timers": {"sample_time_ms": 3328.725, "sample_throughput": 1201.661, "learn_time_ms": 12074.082, "learn_throughput": 331.288, "update_time_ms": 4.243}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5e-05, "total_loss": -0.014625918760430068, "policy_loss": -0.020696450606919825, "vf_loss": 0.00011037619356102368, "vf_explained_var": 0.5256772041320801, "kl": 0.010465018232935108, "entropy": 0.9952097628265619, "entropy_coeff": 0.0}}, "num_steps_sampled": 576000, "num_steps_trained": 576000}, "done": false, "episodes_total": 166, "training_iteration": 144, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-06-44", "timestamp": 1619874404, "time_this_iter_s": 15.374637603759766, "time_total_s": 2199.564828157425, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec61aea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d048>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2199.564828157425, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 20.063636363636363, "ram_util_percent": 58.036363636363625}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07606500000000001, "episode_len_mean": 3921.36, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07606500000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.007500000000000005, 0.005000000000000003, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.007500000000000005, 0.005000000000000003, 0.0, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9469489530913481, "mean_raw_obs_processing_ms": 0.9003304392110708, "mean_inference_ms": 1.0349659727930842, "mean_action_processing_ms": 0.044428254567441997}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 580000, "timers": {"sample_time_ms": 3327.848, "sample_throughput": 1201.978, "learn_time_ms": 12127.711, "learn_throughput": 329.823, "update_time_ms": 4.356}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5e-05, "total_loss": -0.028002491453662515, "policy_loss": -0.03288011741824448, "vf_loss": 8.166119211949763e-07, "vf_explained_var": 0.653191328048706, "kl": 0.00856284803012386, "entropy": 1.0670811533927917, "entropy_coeff": 0.0}}, "num_steps_sampled": 580000, "num_steps_trained": 580000}, "done": false, "episodes_total": 168, "training_iteration": 145, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-07-00", "timestamp": 1619874420, "time_this_iter_s": 15.763558387756348, "time_total_s": 2215.3283865451813, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d400>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2215.3283865451813, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 19.65217391304348, "ram_util_percent": 58.06956521739128}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07598749999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07598749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.007750000000000005, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.007750000000000005, 0.0015, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9469978082742949, "mean_raw_obs_processing_ms": 0.9001800010741704, "mean_inference_ms": 1.0349746502010513, "mean_action_processing_ms": 0.044433760852367506}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 584000, "timers": {"sample_time_ms": 3309.02, "sample_throughput": 1208.817, "learn_time_ms": 12114.291, "learn_throughput": 330.189, "update_time_ms": 4.362}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.56953125, "cur_lr": 5e-05, "total_loss": -0.018265345046529546, "policy_loss": -0.020563109137583524, "vf_loss": 1.3556017535165665e-06, "vf_explained_var": 0.3778771162033081, "kl": 0.0040321039596165065, "entropy": 0.9978205133229494, "entropy_coeff": 0.0}}, "num_steps_sampled": 584000, "num_steps_trained": 584000}, "done": false, "episodes_total": 169, "training_iteration": 146, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-07-15", "timestamp": 1619874435, "time_this_iter_s": 15.255641222000122, "time_total_s": 2230.5840277671814, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67b950>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2230.5840277671814, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 20.5, "ram_util_percent": 58.00909090909093}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07597749999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07597749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0025000000000000005, 0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.946911477335744, "mean_raw_obs_processing_ms": 0.900835318038811, "mean_inference_ms": 1.035136634227744, "mean_action_processing_ms": 0.04442593570004238}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 588000, "timers": {"sample_time_ms": 3347.03, "sample_throughput": 1195.089, "learn_time_ms": 12061.047, "learn_throughput": 331.646, "update_time_ms": 4.264}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.284765625, "cur_lr": 5e-05, "total_loss": -0.013234221609309316, "policy_loss": -0.015327539527788758, "vf_loss": 8.712974253199945e-07, "vf_explained_var": 0.19930756092071533, "kl": 0.007347966617089696, "entropy": 1.0441095922142267, "entropy_coeff": 0.0}}, "num_steps_sampled": 588000, "num_steps_trained": 588000}, "done": false, "episodes_total": 170, "training_iteration": 147, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-07-31", "timestamp": 1619874451, "time_this_iter_s": 15.454444169998169, "time_total_s": 2246.0384719371796, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec608a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2246.0384719371796, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 23.91363636363637, "ram_util_percent": 57.98181818181817}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07597749999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07597749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.005500000000000003, 0.004500000000000002, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9469114773357441, "mean_raw_obs_processing_ms": 0.900835318038811, "mean_inference_ms": 1.035136634227744, "mean_action_processing_ms": 0.04442593570004238}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 592000, "timers": {"sample_time_ms": 3321.173, "sample_throughput": 1204.394, "learn_time_ms": 12082.459, "learn_throughput": 331.058, "update_time_ms": 4.395}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.284765625, "cur_lr": 5e-05, "total_loss": -0.0257471673830878, "policy_loss": -0.03174962944467552, "vf_loss": 7.332953657623875e-07, "vf_explained_var": -0.1502315253019333, "kl": 0.021076019038446248, "entropy": 1.0747248157858849, "entropy_coeff": 0.0}}, "num_steps_sampled": 592000, "num_steps_trained": 592000}, "done": false, "episodes_total": 170, "training_iteration": 148, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-07-47", "timestamp": 1619874467, "time_this_iter_s": 15.573508262634277, "time_total_s": 2261.611980199814, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d400>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2261.611980199814, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 19.39545454545455, "ram_util_percent": 58.03181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07602249999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07602249999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003000000000000001, 0.0025000000000000005, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.003000000000000001, 0.0025000000000000005, 0.0025000000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9470926639190409, "mean_raw_obs_processing_ms": 0.9020266490893024, "mean_inference_ms": 1.0352442528916355, "mean_action_processing_ms": 0.04443754654224384}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 596000, "timers": {"sample_time_ms": 3339.954, "sample_throughput": 1197.621, "learn_time_ms": 12057.531, "learn_throughput": 331.743, "update_time_ms": 4.218}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.42714843750000003, "cur_lr": 5e-05, "total_loss": -0.004604315210599452, "policy_loss": -0.006342025997582823, "vf_loss": 4.470802050349221e-06, "vf_explained_var": -0.2831180691719055, "kl": 0.004057697849930264, "entropy": 1.0139380116015673, "entropy_coeff": 0.0}}, "num_steps_sampled": 596000, "num_steps_trained": 596000}, "done": false, "episodes_total": 172, "training_iteration": 149, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-08-02", "timestamp": 1619874482, "time_this_iter_s": 15.41140365600586, "time_total_s": 2277.0233838558197, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6080d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2277.0233838558197, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 19.386363636363637, "ram_util_percent": 58.095454545454544}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07597499999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07597499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.007250000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.007250000000000005, 0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9471524798854687, "mean_raw_obs_processing_ms": 0.9020444091565807, "mean_inference_ms": 1.0352661034609592, "mean_action_processing_ms": 0.044443673232115906}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 600000, "timers": {"sample_time_ms": 3323.038, "sample_throughput": 1203.718, "learn_time_ms": 12014.749, "learn_throughput": 332.924, "update_time_ms": 4.264}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.0062065867823548615, "policy_loss": -0.00751614331966266, "vf_loss": 1.2029350013875728e-06, "vf_explained_var": 0.37504255771636963, "kl": 0.006125981381046586, "entropy": 1.004070058465004, "entropy_coeff": 0.0}}, "num_steps_sampled": 600000, "num_steps_trained": 600000}, "done": false, "episodes_total": 173, "training_iteration": 150, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-08-18", "timestamp": 1619874498, "time_this_iter_s": 15.399689674377441, "time_total_s": 2292.423073530197, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec608ea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60d598>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2292.423073530197, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 21.477272727272727, "ram_util_percent": 58.063636363636355}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07597499999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07597499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005]}, "sampler_perf": {"mean_env_wait_ms": 0.9470494901875426, "mean_raw_obs_processing_ms": 0.9028367939188126, "mean_inference_ms": 1.035414767568997, "mean_action_processing_ms": 0.04443530887246263}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 604000, "timers": {"sample_time_ms": 3335.423, "sample_throughput": 1199.248, "learn_time_ms": 12005.749, "learn_throughput": 333.174, "update_time_ms": 4.22}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.020975312421796843, "policy_loss": -0.024331893568160012, "vf_loss": 1.1557705521525463e-06, "vf_explained_var": -0.10794980823993683, "kl": 0.015710823266999796, "entropy": 1.080884400755167, "entropy_coeff": 0.0}}, "num_steps_sampled": 604000, "num_steps_trained": 604000}, "done": false, "episodes_total": 174, "training_iteration": 151, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-08-33", "timestamp": 1619874513, "time_this_iter_s": 15.114577770233154, "time_total_s": 2307.5376513004303, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d378>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2307.5376513004303, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 20.795454545454543, "ram_util_percent": 58.07272727272727}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07597499999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07597499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0037500000000000016, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9470494901875425, "mean_raw_obs_processing_ms": 0.9028367939188126, "mean_inference_ms": 1.035414767568997, "mean_action_processing_ms": 0.04443530887246262}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 608000, "timers": {"sample_time_ms": 3349.527, "sample_throughput": 1194.199, "learn_time_ms": 11937.7, "learn_throughput": 335.073, "update_time_ms": 4.134}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.02363610063912347, "policy_loss": -0.027834140782942995, "vf_loss": 7.343826551320376e-07, "vf_explained_var": -0.7807263135910034, "kl": 0.019652702030725777, "entropy": 1.1286215670406818, "entropy_coeff": 0.0}}, "num_steps_sampled": 608000, "num_steps_trained": 608000}, "done": false, "episodes_total": 174, "training_iteration": 152, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-08-48", "timestamp": 1619874528, "time_this_iter_s": 15.223658561706543, "time_total_s": 2322.761309862137, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67b510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2322.761309862137, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 19.08636363636364, "ram_util_percent": 58.07727272727272}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07600499999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07600499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00075, 0.0, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.00075, 0.0, 0.0015, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9472355648955277, "mean_raw_obs_processing_ms": 0.904062101636725, "mean_inference_ms": 1.03552580542721, "mean_action_processing_ms": 0.04444710987015033}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 612000, "timers": {"sample_time_ms": 3352.635, "sample_throughput": 1193.092, "learn_time_ms": 11985.183, "learn_throughput": 333.745, "update_time_ms": 3.975}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.020951415761373937, "policy_loss": -0.023654143602470867, "vf_loss": 4.6530046624582155e-06, "vf_explained_var": 0.05934610962867737, "kl": 0.012632972808205523, "entropy": 1.0524641126394272, "entropy_coeff": 0.0}}, "num_steps_sampled": 612000, "num_steps_trained": 612000}, "done": false, "episodes_total": 176, "training_iteration": 153, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-09-03", "timestamp": 1619874543, "time_this_iter_s": 14.927082061767578, "time_total_s": 2337.6883919239044, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60d158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fa60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2337.6883919239044, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 20.057142857142857, "ram_util_percent": 57.995238095238086}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07601999999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07601999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9472795683678444, "mean_raw_obs_processing_ms": 0.9041705082462158, "mean_inference_ms": 1.0355222306448786, "mean_action_processing_ms": 0.04445234625681563}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 616000, "timers": {"sample_time_ms": 3343.823, "sample_throughput": 1196.235, "learn_time_ms": 11993.789, "learn_throughput": 333.506, "update_time_ms": 3.827}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.014481054444331676, "policy_loss": -0.016138523700647056, "vf_loss": 1.1727885208756561e-05, "vf_explained_var": -0.03277471289038658, "kl": 0.0077057114176568575, "entropy": 0.9958368055522442, "entropy_coeff": 0.0}}, "num_steps_sampled": 616000, "num_steps_trained": 616000}, "done": false, "episodes_total": 177, "training_iteration": 154, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-09-18", "timestamp": 1619874558, "time_this_iter_s": 15.374042510986328, "time_total_s": 2353.0624344348907, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d378>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2353.0624344348907, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 17.18181818181818, "ram_util_percent": 58.07272727272727}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.0760025, "episode_len_mean": 3921.36, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.0760025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00175, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.00175, 0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9471762646196541, "mean_raw_obs_processing_ms": 0.9048368854360278, "mean_inference_ms": 1.0356615377931815, "mean_action_processing_ms": 0.04444349239275291}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 620000, "timers": {"sample_time_ms": 3346.675, "sample_throughput": 1195.216, "learn_time_ms": 11972.173, "learn_throughput": 334.108, "update_time_ms": 3.825}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.014858696842566133, "policy_loss": -0.018008049577474594, "vf_loss": 0.00014616249436016915, "vf_explained_var": 0.09995786845684052, "kl": 0.014061572815990075, "entropy": 1.0572628267109394, "entropy_coeff": 0.0}}, "num_steps_sampled": 620000, "num_steps_trained": 620000}, "done": false, "episodes_total": 178, "training_iteration": 155, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-09-34", "timestamp": 1619874574, "time_this_iter_s": 15.573926210403442, "time_total_s": 2368.636360645294, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2368.636360645294, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 18.25, "ram_util_percent": 58.01818181818181}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07600249999999999, "episode_len_mean": 3921.36, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07600249999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175], "episode_lengths": [4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.004250000000000002, 0.004250000000000002, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175]}, "sampler_perf": {"mean_env_wait_ms": 0.9471762646196542, "mean_raw_obs_processing_ms": 0.9048368854360278, "mean_inference_ms": 1.0356615377931815, "mean_action_processing_ms": 0.04444349239275291}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 624000, "timers": {"sample_time_ms": 3360.104, "sample_throughput": 1190.439, "learn_time_ms": 12045.986, "learn_throughput": 332.061, "update_time_ms": 3.834}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.21357421875000002, "cur_lr": 5e-05, "total_loss": -0.02482989977579564, "policy_loss": -0.031778941629454494, "vf_loss": 0.0003026884478458669, "vf_explained_var": 0.4562486410140991, "kl": 0.03111965087009594, "entropy": 1.0967266708612442, "entropy_coeff": 0.0}}, "num_steps_sampled": 624000, "num_steps_trained": 624000}, "done": false, "episodes_total": 178, "training_iteration": 156, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-09-50", "timestamp": 1619874590, "time_this_iter_s": 16.125367164611816, "time_total_s": 2384.761727809906, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73f6b62510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2384.761727809906, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 20.565217391304348, "ram_util_percent": 57.99565217391305}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.075965, "episode_len_mean": 3921.36, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.075965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0070000000000000045, 0.005250000000000003, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175], "episode_lengths": [4002, 4002, 4002, 3168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0070000000000000045, 0.005250000000000003, 0.0037500000000000016, -0.99625, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175]}, "sampler_perf": {"mean_env_wait_ms": 0.9473527496027733, "mean_raw_obs_processing_ms": 0.9060948579968869, "mean_inference_ms": 1.0357560742623715, "mean_action_processing_ms": 0.044454581202441695}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 628000, "timers": {"sample_time_ms": 3326.799, "sample_throughput": 1202.357, "learn_time_ms": 12058.341, "learn_throughput": 331.721, "update_time_ms": 3.841}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.320361328125, "cur_lr": 5e-05, "total_loss": -0.027443205355666578, "policy_loss": -0.0328458042931743, "vf_loss": 4.1616127418819815e-05, "vf_explained_var": 0.6085937023162842, "kl": 0.016734180244384333, "entropy": 1.0273240823298693, "entropy_coeff": 0.0}}, "num_steps_sampled": 628000, "num_steps_trained": 628000}, "done": false, "episodes_total": 180, "training_iteration": 157, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-10-06", "timestamp": 1619874606, "time_this_iter_s": 15.245300531387329, "time_total_s": 2400.0070283412933, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f6a8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f378>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2400.0070283412933, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 18.85909090909091, "ram_util_percent": 58.00454545454546}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07600749999999999, "episode_len_mean": 3891.36, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07600749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003250000000000001, -1.0, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003], "episode_lengths": [4002, 168, 3167, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.003250000000000001, -1.0, -0.997, 0.0022500000000000003, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003]}, "sampler_perf": {"mean_env_wait_ms": 0.9476701674209659, "mean_raw_obs_processing_ms": 0.9064994220297596, "mean_inference_ms": 1.0358922434359317, "mean_action_processing_ms": 0.044472053355014245}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 632000, "timers": {"sample_time_ms": 3310.299, "sample_throughput": 1208.35, "learn_time_ms": 12062.182, "learn_throughput": 331.615, "update_time_ms": 3.734}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.320361328125, "cur_lr": 5e-05, "total_loss": -0.0025163167156279087, "policy_loss": -0.0076398507808335125, "vf_loss": 0.003673615845400491, "vf_explained_var": -0.010461658239364624, "kl": 0.004525894306425471, "entropy": 1.0871606804430485, "entropy_coeff": 0.0}}, "num_steps_sampled": 632000, "num_steps_trained": 632000}, "done": false, "episodes_total": 182, "training_iteration": 158, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-10-21", "timestamp": 1619874621, "time_this_iter_s": 15.446054697036743, "time_total_s": 2415.45308303833, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60fa60>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d488>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2415.45308303833, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 17.072727272727274, "ram_util_percent": 58.063636363636355}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07605999999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07605999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, 0.0, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0], "episode_lengths": [1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168], "policy_pol_reward": [-1.0, 0.0, 0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9477101691679174, "mean_raw_obs_processing_ms": 0.9078145393092112, "mean_inference_ms": 1.0359842888023478, "mean_action_processing_ms": 0.044474039615921016}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 636000, "timers": {"sample_time_ms": 3289.94, "sample_throughput": 1215.828, "learn_time_ms": 12095.495, "learn_throughput": 330.702, "update_time_ms": 3.845}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1601806640625, "cur_lr": 5e-05, "total_loss": -0.03323625249322504, "policy_loss": -0.034922144608572125, "vf_loss": 0.00021804476887155033, "vf_explained_var": 0.8807457089424133, "kl": 0.009163710637949407, "entropy": 1.0918165296316147, "entropy_coeff": 0.0}}, "num_steps_sampled": 636000, "num_steps_trained": 636000}, "done": false, "episodes_total": 184, "training_iteration": 159, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-10-37", "timestamp": 1619874637, "time_this_iter_s": 15.54464077949524, "time_total_s": 2430.9977238178253, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2430.9977238178253, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 17.954545454545457, "ram_util_percent": 58.0}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07605999999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07605999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002], "policy_pol_reward": [0.0047500000000000025, 0.0047500000000000025, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9477101691679174, "mean_raw_obs_processing_ms": 0.9078145393092113, "mean_inference_ms": 1.0359842888023478, "mean_action_processing_ms": 0.044474039615921016}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 640000, "timers": {"sample_time_ms": 3276.171, "sample_throughput": 1220.938, "learn_time_ms": 12078.676, "learn_throughput": 331.162, "update_time_ms": 3.809}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1601806640625, "cur_lr": 5e-05, "total_loss": -0.015943103469908237, "policy_loss": -0.0189720019698143, "vf_loss": 5.547310976794506e-06, "vf_explained_var": 0.15076377987861633, "kl": 0.018874637957196683, "entropy": 1.1193376332521439, "entropy_coeff": 0.0}}, "num_steps_sampled": 640000, "num_steps_trained": 640000}, "done": false, "episodes_total": 184, "training_iteration": 160, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-10-52", "timestamp": 1619874652, "time_this_iter_s": 15.093313932418823, "time_total_s": 2446.091037750244, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dae8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f6a8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2446.091037750244, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 17.695454545454545, "ram_util_percent": 58.00454545454546}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07615499999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07615499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9477846970062249, "mean_raw_obs_processing_ms": 0.908558892484199, "mean_inference_ms": 1.0360869494189273, "mean_action_processing_ms": 0.04447798048080813}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 644000, "timers": {"sample_time_ms": 3268.86, "sample_throughput": 1223.668, "learn_time_ms": 12142.593, "learn_throughput": 329.419, "update_time_ms": 3.857}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1601806640625, "cur_lr": 5e-05, "total_loss": -0.035152915748767555, "policy_loss": -0.03809907173854299, "vf_loss": 2.2786855105039194e-06, "vf_explained_var": 0.558574914932251, "kl": 0.018378479609964415, "entropy": 1.1457521803677082, "entropy_coeff": 0.0}}, "num_steps_sampled": 644000, "num_steps_trained": 644000}, "done": false, "episodes_total": 186, "training_iteration": 161, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-11-08", "timestamp": 1619874668, "time_this_iter_s": 15.679372072219849, "time_total_s": 2461.770409822464, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fd08>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2461.770409822464, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 17.55454545454545, "ram_util_percent": 58.04999999999998}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07615499999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07615499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.004000000000000002, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9477846970062249, "mean_raw_obs_processing_ms": 0.9085588924841989, "mean_inference_ms": 1.0360869494189273, "mean_action_processing_ms": 0.0444779804808081}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 648000, "timers": {"sample_time_ms": 3244.024, "sample_throughput": 1233.036, "learn_time_ms": 12049.558, "learn_throughput": 331.962, "update_time_ms": 3.963}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1601806640625, "cur_lr": 5e-05, "total_loss": -0.0013433475978672504, "policy_loss": -0.00317534088389948, "vf_loss": 0.00043209261139054433, "vf_explained_var": 0.47810155153274536, "kl": 0.008739510012674145, "entropy": 1.0221050772815943, "entropy_coeff": 0.0}}, "num_steps_sampled": 648000, "num_steps_trained": 648000}, "done": false, "episodes_total": 186, "training_iteration": 162, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-11-22", "timestamp": 1619874682, "time_this_iter_s": 14.045771598815918, "time_total_s": 2475.81618142128, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60ba60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2475.81618142128, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 17.91, "ram_util_percent": 57.975}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07619499999999998, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07619499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9478118937058774, "mean_raw_obs_processing_ms": 0.9099114142792477, "mean_inference_ms": 1.0361510886754828, "mean_action_processing_ms": 0.04447873940499896}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 652000, "timers": {"sample_time_ms": 3236.932, "sample_throughput": 1235.738, "learn_time_ms": 12145.777, "learn_throughput": 329.333, "update_time_ms": 3.959}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1601806640625, "cur_lr": 5e-05, "total_loss": -0.03850211240933277, "policy_loss": -0.044036914652679116, "vf_loss": 2.2300394618923747e-05, "vf_explained_var": 0.4182191491127014, "kl": 0.03441427933285013, "entropy": 1.0940494388341904, "entropy_coeff": 0.0}}, "num_steps_sampled": 652000, "num_steps_trained": 652000}, "done": false, "episodes_total": 188, "training_iteration": 163, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-11-38", "timestamp": 1619874698, "time_this_iter_s": 15.818490982055664, "time_total_s": 2491.6346724033356, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69df28>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d598>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2491.6346724033356, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 18.182608695652174, "ram_util_percent": 58.03913043478259}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07619499999999998, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07619499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0047500000000000025, 0.0025000000000000005, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9478118937058774, "mean_raw_obs_processing_ms": 0.9099114142792477, "mean_inference_ms": 1.0361510886754828, "mean_action_processing_ms": 0.04447873940499896}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 656000, "timers": {"sample_time_ms": 3227.366, "sample_throughput": 1239.401, "learn_time_ms": 12112.204, "learn_throughput": 330.245, "update_time_ms": 4.019}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.24027099609375002, "cur_lr": 5e-05, "total_loss": -0.026795225421665236, "policy_loss": -0.030880423088092357, "vf_loss": 3.2639355197261466e-05, "vf_explained_var": 0.7022519707679749, "kl": 0.01686661533312872, "entropy": 1.1026191413402557, "entropy_coeff": 0.0}}, "num_steps_sampled": 656000, "num_steps_trained": 656000}, "done": false, "episodes_total": 188, "training_iteration": 164, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-11-53", "timestamp": 1619874713, "time_this_iter_s": 14.942103385925293, "time_total_s": 2506.576775789261, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60b0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60bae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2506.576775789261, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 17.752380952380953, "ram_util_percent": 57.98095238095239}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.076235, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.076235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.003250000000000001, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.003250000000000001, 0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9478747531956749, "mean_raw_obs_processing_ms": 0.9106400161700171, "mean_inference_ms": 1.0362336021975844, "mean_action_processing_ms": 0.044481866651007715}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 660000, "timers": {"sample_time_ms": 3191.205, "sample_throughput": 1253.445, "learn_time_ms": 12141.801, "learn_throughput": 329.44, "update_time_ms": 3.864}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.24027099609375002, "cur_lr": 5e-05, "total_loss": -0.01777224850957282, "policy_loss": -0.020771979383425787, "vf_loss": 3.016970268276964e-05, "vf_explained_var": 0.6220008730888367, "kl": 0.012359216809272766, "entropy": 1.1157109923660755, "entropy_coeff": 0.0}}, "num_steps_sampled": 660000, "num_steps_trained": 660000}, "done": false, "episodes_total": 190, "training_iteration": 165, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-12-08", "timestamp": 1619874728, "time_this_iter_s": 15.513247966766357, "time_total_s": 2522.090023756027, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69dae8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f378>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2522.090023756027, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 20.260869565217387, "ram_util_percent": 57.98695652173913}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07623499999999998, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07623499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0037500000000000016, 0.003250000000000001, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9478747531956749, "mean_raw_obs_processing_ms": 0.9106400161700171, "mean_inference_ms": 1.0362336021975844, "mean_action_processing_ms": 0.044481866651007715}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 664000, "timers": {"sample_time_ms": 3168.86, "sample_throughput": 1262.284, "learn_time_ms": 11973.998, "learn_throughput": 334.057, "update_time_ms": 3.775}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.24027099609375002, "cur_lr": 5e-05, "total_loss": -0.023231309780385345, "policy_loss": -0.02795972872991115, "vf_loss": 2.1483383164877523e-05, "vf_explained_var": 0.40743619203567505, "kl": 0.019590113312005997, "entropy": 1.10207249969244, "entropy_coeff": 0.0}}, "num_steps_sampled": 664000, "num_steps_trained": 664000}, "done": false, "episodes_total": 190, "training_iteration": 166, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-12-22", "timestamp": 1619874742, "time_this_iter_s": 14.224766731262207, "time_total_s": 2536.3147904872894, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2536.3147904872894, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 18.04, "ram_util_percent": 57.97499999999999}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07623749999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07623749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.006750000000000004, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.006750000000000004, 0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001]}, "sampler_perf": {"mean_env_wait_ms": 0.9478994578559233, "mean_raw_obs_processing_ms": 0.9118647208246642, "mean_inference_ms": 1.0362880921609472, "mean_action_processing_ms": 0.044482358722755445}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 668000, "timers": {"sample_time_ms": 3161.374, "sample_throughput": 1265.272, "learn_time_ms": 12008.167, "learn_throughput": 333.107, "update_time_ms": 3.831}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.24027099609375002, "cur_lr": 5e-05, "total_loss": -0.033876621251692995, "policy_loss": -0.03960617529810406, "vf_loss": 2.2265407125132697e-05, "vf_explained_var": 0.4878891408443451, "kl": 0.02375354361720383, "entropy": 1.1555097959935665, "entropy_coeff": 0.0}}, "num_steps_sampled": 668000, "num_steps_trained": 668000}, "done": false, "episodes_total": 192, "training_iteration": 167, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-12-38", "timestamp": 1619874758, "time_this_iter_s": 15.51142168045044, "time_total_s": 2551.82621216774, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f2f0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f0d0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2551.82621216774, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 17.14090909090909, "ram_util_percent": 58.07727272727271}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07623749999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07623749999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.010000000000000007, 0.0037500000000000016, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9478994578559232, "mean_raw_obs_processing_ms": 0.9118647208246644, "mean_inference_ms": 1.0362880921609472, "mean_action_processing_ms": 0.04448235872275544}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 672000, "timers": {"sample_time_ms": 3176.652, "sample_throughput": 1259.188, "learn_time_ms": 11906.034, "learn_throughput": 335.964, "update_time_ms": 3.751}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.00981647934531793, "policy_loss": -0.012080878135748208, "vf_loss": 2.881582474856259e-05, "vf_explained_var": 0.6988018751144409, "kl": 0.006202951408340596, "entropy": 1.037238946184516, "entropy_coeff": 0.0}}, "num_steps_sampled": 672000, "num_steps_trained": 672000}, "done": false, "episodes_total": 192, "training_iteration": 168, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-12-53", "timestamp": 1619874773, "time_this_iter_s": 14.576118230819702, "time_total_s": 2566.4023303985596, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec613a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2566.4023303985596, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 18.947619047619046, "ram_util_percent": 57.971428571428554}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07637499999999998, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07637499999999998}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004]}, "sampler_perf": {"mean_env_wait_ms": 0.9479537033762594, "mean_raw_obs_processing_ms": 0.9125217296118353, "mean_inference_ms": 1.0363519434863868, "mean_action_processing_ms": 0.0444847806452375}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 676000, "timers": {"sample_time_ms": 3175.852, "sample_throughput": 1259.504, "learn_time_ms": 11886.292, "learn_throughput": 336.522, "update_time_ms": 3.71}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.020208840956911445, "policy_loss": -0.025467771338298917, "vf_loss": 4.592369791112105e-05, "vf_explained_var": 0.4584432542324066, "kl": 0.01446425128960982, "entropy": 1.1848201230168343, "entropy_coeff": 0.0}}, "num_steps_sampled": 676000, "num_steps_trained": 676000}, "done": false, "episodes_total": 194, "training_iteration": 169, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-13-08", "timestamp": 1619874788, "time_this_iter_s": 15.33743405342102, "time_total_s": 2581.7397644519806, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d598>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2581.7397644519806, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 16.922727272727272, "ram_util_percent": 58.04545454545453}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.076375, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.076375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006500000000000004, 0.005000000000000003, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9479537033762593, "mean_raw_obs_processing_ms": 0.9125217296118353, "mean_inference_ms": 1.0363519434863868, "mean_action_processing_ms": 0.044484780645237504}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 680000, "timers": {"sample_time_ms": 3177.331, "sample_throughput": 1258.918, "learn_time_ms": 11864.923, "learn_throughput": 337.128, "update_time_ms": 3.653}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.017682989564491436, "policy_loss": -0.021271069039357826, "vf_loss": 3.286108179167968e-05, "vf_explained_var": 0.5270960330963135, "kl": 0.009864463165285997, "entropy": 1.1909703314304352, "entropy_coeff": 0.0}}, "num_steps_sampled": 680000, "num_steps_trained": 680000}, "done": false, "episodes_total": 194, "training_iteration": 170, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-13-23", "timestamp": 1619874803, "time_this_iter_s": 14.892720699310303, "time_total_s": 2596.632485151291, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6130d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2596.632485151291, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 18.238095238095237, "ram_util_percent": 58.00952380952381}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07648999999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07648999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9479674624456088, "mean_raw_obs_processing_ms": 0.9136669164836619, "mean_inference_ms": 1.0363790962637724, "mean_action_processing_ms": 0.044484264427395254}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 684000, "timers": {"sample_time_ms": 3165.501, "sample_throughput": 1263.623, "learn_time_ms": 11672.493, "learn_throughput": 342.686, "update_time_ms": 3.474}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.029305251402547583, "policy_loss": -0.03545634279726073, "vf_loss": 8.228534248644337e-06, "vf_explained_var": 0.30635184049606323, "kl": 0.017044265696313232, "entropy": 1.176783811300993, "entropy_coeff": 0.0}}, "num_steps_sampled": 684000, "num_steps_trained": 684000}, "done": false, "episodes_total": 196, "training_iteration": 171, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-13-37", "timestamp": 1619874817, "time_this_iter_s": 13.633811235427856, "time_total_s": 2610.2662963867188, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec613ea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fbf8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2610.2662963867188, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 16.605, "ram_util_percent": 57.970000000000006}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.07648999999999999, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.07648999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0025000000000000005, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9479674624456089, "mean_raw_obs_processing_ms": 0.9136669164836618, "mean_inference_ms": 1.0363790962637724, "mean_action_processing_ms": 0.04448426442739526}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 688000, "timers": {"sample_time_ms": 3156.331, "sample_throughput": 1267.294, "learn_time_ms": 11815.918, "learn_throughput": 338.526, "update_time_ms": 3.397}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.023798030335456133, "policy_loss": -0.029129023023415357, "vf_loss": 1.0481775838400154e-06, "vf_explained_var": 0.14981067180633545, "kl": 0.014788709173444659, "entropy": 1.1793951205909252, "entropy_coeff": 0.0}}, "num_steps_sampled": 688000, "num_steps_trained": 688000}, "done": false, "episodes_total": 196, "training_iteration": 172, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-13-52", "timestamp": 1619874832, "time_this_iter_s": 15.38779616355896, "time_total_s": 2625.6540925502777, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d730>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2625.6540925502777, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 18.236363636363635, "ram_util_percent": 58.02272727272727}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.076515, "episode_len_mean": 3870.38, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.076515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480167364950357, "mean_raw_obs_processing_ms": 0.9144207824325347, "mean_inference_ms": 1.036435447740675, "mean_action_processing_ms": 0.044486241468892074}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 692000, "timers": {"sample_time_ms": 3144.203, "sample_throughput": 1272.182, "learn_time_ms": 11789.337, "learn_throughput": 339.29, "update_time_ms": 3.486}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.029768775450065732, "policy_loss": -0.033369723983923905, "vf_loss": 4.922098830739685e-07, "vf_explained_var": 0.06672210991382599, "kl": 0.009989986749133095, "entropy": 1.1512543261051178, "entropy_coeff": 0.0}}, "num_steps_sampled": 692000, "num_steps_trained": 692000}, "done": false, "episodes_total": 198, "training_iteration": 173, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-14-08", "timestamp": 1619874848, "time_this_iter_s": 15.431264877319336, "time_total_s": 2641.085357427597, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60fe18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bc80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2641.085357427597, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 17.53181818181818, "ram_util_percent": 57.98636363636364}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.076515, "episode_len_mean": 3870.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.076515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 3826, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006250000000000004, -1.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480167364950357, "mean_raw_obs_processing_ms": 0.9144207824325347, "mean_inference_ms": 1.0364354477406748, "mean_action_processing_ms": 0.04448624146889208}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 696000, "timers": {"sample_time_ms": 3148.253, "sample_throughput": 1270.546, "learn_time_ms": 11858.237, "learn_throughput": 337.318, "update_time_ms": 3.391}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.02528300604899414, "policy_loss": -0.030013460549525917, "vf_loss": 9.282374771046875e-07, "vf_explained_var": -0.3237881362438202, "kl": 0.013122756077791564, "entropy": 1.1193105690181255, "entropy_coeff": 0.0}}, "num_steps_sampled": 696000, "num_steps_trained": 696000}, "done": false, "episodes_total": 198, "training_iteration": 174, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-14-23", "timestamp": 1619874863, "time_this_iter_s": 15.671639919281006, "time_total_s": 2656.756997346878, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f9d8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec61ca60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2656.756997346878, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 19.363636363636363, "ram_util_percent": 57.9318181818182}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.0665775, "episode_len_mean": 3872.14, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.0665775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480269876898793, "mean_raw_obs_processing_ms": 0.9156092097051541, "mean_inference_ms": 1.036446722507791, "mean_action_processing_ms": 0.04448521839978703}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 700000, "timers": {"sample_time_ms": 3192.208, "sample_throughput": 1253.051, "learn_time_ms": 11854.362, "learn_throughput": 337.429, "update_time_ms": 3.628}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.024256168719148263, "policy_loss": -0.028112073428928852, "vf_loss": 3.084689819132791e-06, "vf_explained_var": -0.08519652485847473, "kl": 0.010690210183383897, "entropy": 1.106008369475603, "entropy_coeff": 0.0}}, "num_steps_sampled": 700000, "num_steps_trained": 700000}, "done": false, "episodes_total": 200, "training_iteration": 175, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-14-39", "timestamp": 1619874879, "time_this_iter_s": 15.910755395889282, "time_total_s": 2672.6677527427673, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d730>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2672.6677527427673, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 19.48695652173913, "ram_util_percent": 57.97391304347825}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.0665775, "episode_len_mean": 3872.14, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.0665775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.003000000000000001, 0.010750000000000008, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480269876898793, "mean_raw_obs_processing_ms": 0.9156092097051542, "mean_inference_ms": 1.036446722507791, "mean_action_processing_ms": 0.04448521839978703}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 704000, "timers": {"sample_time_ms": 3199.415, "sample_throughput": 1250.229, "learn_time_ms": 11991.214, "learn_throughput": 333.578, "update_time_ms": 3.677}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.019324897381011397, "policy_loss": -0.024711624952033162, "vf_loss": 2.9856036860564927e-06, "vf_explained_var": -0.9679785966873169, "kl": 0.014937981468392536, "entropy": 1.1816352307796478, "entropy_coeff": 0.0}}, "num_steps_sampled": 704000, "num_steps_trained": 704000}, "done": false, "episodes_total": 200, "training_iteration": 176, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-14-55", "timestamp": 1619874895, "time_this_iter_s": 15.665615797042847, "time_total_s": 2688.33336853981, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec61c0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2688.33336853981, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 18.026086956521738, "ram_util_percent": 58.01739130434781}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.066715, "episode_len_mean": 3872.14, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.066715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480721360507895, "mean_raw_obs_processing_ms": 0.9163761223922141, "mean_inference_ms": 1.0364988784107279, "mean_action_processing_ms": 0.04448682584172617}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 708000, "timers": {"sample_time_ms": 3180.542, "sample_throughput": 1257.647, "learn_time_ms": 11970.654, "learn_throughput": 334.15, "update_time_ms": 3.572}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.0060300357872620225, "policy_loss": -0.011234142177272588, "vf_loss": 2.092155700239573e-06, "vf_explained_var": -0.28054168820381165, "kl": 0.014433738979278132, "entropy": 1.102110467851162, "entropy_coeff": 0.0}}, "num_steps_sampled": 708000, "num_steps_trained": 708000}, "done": false, "episodes_total": 202, "training_iteration": 177, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-15-10", "timestamp": 1619874910, "time_this_iter_s": 15.11722469329834, "time_total_s": 2703.4505932331085, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec61cea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60fd90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2703.4505932331085, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 17.42380952380952, "ram_util_percent": 57.94285714285714}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.066715, "episode_len_mean": 3872.14, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.066715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 2334, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006000000000000004, -0.998, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480721360507895, "mean_raw_obs_processing_ms": 0.916376122392214, "mean_inference_ms": 1.036498878410728, "mean_action_processing_ms": 0.04448682584172616}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 712000, "timers": {"sample_time_ms": 3158.617, "sample_throughput": 1266.377, "learn_time_ms": 12109.55, "learn_throughput": 330.318, "update_time_ms": 3.597}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.030180583547917195, "policy_loss": -0.036110714194364846, "vf_loss": 2.706324909951263e-06, "vf_explained_var": -0.8502541780471802, "kl": 0.016446501191239804, "entropy": 1.1241965256631374, "entropy_coeff": 0.0}}, "num_steps_sampled": 712000, "num_steps_trained": 712000}, "done": false, "episodes_total": 202, "training_iteration": 178, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-15-26", "timestamp": 1619874926, "time_this_iter_s": 15.745072603225708, "time_total_s": 2719.1956658363342, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69de18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2719.1956658363342, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 16.76521739130435, "ram_util_percent": 58.06521739130435}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.01275000000000001, "episode_reward_min": -1.0, "episode_reward_mean": -0.056795, "episode_len_mean": 3888.82, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.01275000000000001}, "policy_reward_mean": {"pol": -0.056795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0027500000000000007, 0.003250000000000001, 0.01275000000000001, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9479595637972044, "mean_raw_obs_processing_ms": 0.9175916777902319, "mean_inference_ms": 1.0366008561682971, "mean_action_processing_ms": 0.04447596840648446}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 716000, "timers": {"sample_time_ms": 3147.7, "sample_throughput": 1270.769, "learn_time_ms": 12127.17, "learn_throughput": 329.838, "update_time_ms": 3.692}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.01820968632819131, "policy_loss": -0.022813146992120892, "vf_loss": 1.643755287439319e-07, "vf_explained_var": 0.12774111330509186, "kl": 0.012772526330081746, "entropy": 1.1492213159799576, "entropy_coeff": 0.0}}, "num_steps_sampled": 716000, "num_steps_trained": 716000}, "done": false, "episodes_total": 204, "training_iteration": 179, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-15-41", "timestamp": 1619874941, "time_this_iter_s": 15.408959150314331, "time_total_s": 2734.6046249866486, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bb70>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2734.6046249866486, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 18.263636363636365, "ram_util_percent": 58.01363636363636}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.009000000000000006, "episode_reward_min": -1.0, "episode_reward_mean": -0.08686500000000001, "episode_len_mean": 3789.6, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.009000000000000006}, "policy_reward_mean": {"pol": -0.08686500000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, -1.0, -0.98825, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 143, 1441, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, -1.0, -0.98825, 0.0037500000000000016, 0.0015, 0.0027500000000000007, 0.009000000000000006, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9482465852309534, "mean_raw_obs_processing_ms": 0.9189650126775102, "mean_inference_ms": 1.036622102938033, "mean_action_processing_ms": 0.044488513684607094}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 720000, "timers": {"sample_time_ms": 3140.022, "sample_throughput": 1273.876, "learn_time_ms": 12163.492, "learn_throughput": 328.853, "update_time_ms": 3.806}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.03149655455490574, "policy_loss": -0.03960742166964337, "vf_loss": 0.002002497811190551, "vf_explained_var": 0.9080660343170166, "kl": 0.016948557371506467, "entropy": 1.1465045772492886, "entropy_coeff": 0.0}}, "num_steps_sampled": 720000, "num_steps_trained": 720000}, "done": false, "episodes_total": 207, "training_iteration": 180, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-15-57", "timestamp": 1619874957, "time_this_iter_s": 15.180905818939209, "time_total_s": 2749.7855308055878, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f2f0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec613a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2749.7855308055878, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 17.580952380952382, "ram_util_percent": 57.976190476190474}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10703500000000002, "episode_len_mean": 3723.5, "episodes_this_iter": 4, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10703500000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, 0.0, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825], "episode_lengths": [4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441], "policy_pol_reward": [0.0, -1.0, -1.0, 0.0, 0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825]}, "sampler_perf": {"mean_env_wait_ms": 0.948277779497839, "mean_raw_obs_processing_ms": 0.9211920143327598, "mean_inference_ms": 1.036638309005674, "mean_action_processing_ms": 0.04448753194670871}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 724000, "timers": {"sample_time_ms": 3142.729, "sample_throughput": 1272.779, "learn_time_ms": 12318.638, "learn_throughput": 324.711, "update_time_ms": 3.846}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.012603750394191593, "policy_loss": -0.01947929078596644, "vf_loss": 0.0025887912797770696, "vf_explained_var": 0.8837918639183044, "kl": 0.011894199880771339, "entropy": 1.088385708630085, "entropy_coeff": 0.0}}, "num_steps_sampled": 724000, "num_steps_trained": 724000}, "done": false, "episodes_total": 211, "training_iteration": 181, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-16-12", "timestamp": 1619874972, "time_this_iter_s": 15.213680267333984, "time_total_s": 2764.9992110729218, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69de18>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2764.9992110729218, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 18.381818181818183, "ram_util_percent": 58.036363636363625}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.107035, "episode_len_mean": 3723.5, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.107035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002], "policy_pol_reward": [0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9482777794978391, "mean_raw_obs_processing_ms": 0.9211920143327598, "mean_inference_ms": 1.036638309005674, "mean_action_processing_ms": 0.044487531946708715}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 728000, "timers": {"sample_time_ms": 3148.0, "sample_throughput": 1270.648, "learn_time_ms": 12272.821, "learn_throughput": 325.923, "update_time_ms": 3.939}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.023466727521736175, "policy_loss": -0.029595194500871003, "vf_loss": 0.0003377010380063439, "vf_explained_var": 0.35968416929244995, "kl": 0.01606731559149921, "entropy": 1.1108305715024471, "entropy_coeff": 0.0}}, "num_steps_sampled": 728000, "num_steps_trained": 728000}, "done": false, "episodes_total": 211, "training_iteration": 182, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-16-27", "timestamp": 1619874987, "time_this_iter_s": 14.982615947723389, "time_total_s": 2779.981827020645, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6130d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2779.981827020645, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 17.39090909090909, "ram_util_percent": 57.9909090909091}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.107035, "episode_len_mean": 3723.5, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.107035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002], "policy_pol_reward": [0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9482777794978391, "mean_raw_obs_processing_ms": 0.9211920143327598, "mean_inference_ms": 1.036638309005674, "mean_action_processing_ms": 0.044487531946708715}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 732000, "timers": {"sample_time_ms": 3156.456, "sample_throughput": 1267.244, "learn_time_ms": 12309.836, "learn_throughput": 324.943, "update_time_ms": 3.856}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.012658575898967683, "policy_loss": -0.016367176780477166, "vf_loss": 7.261246787493292e-05, "vf_explained_var": 0.5401633977890015, "kl": 0.010088589813676663, "entropy": 1.1255865506827831, "entropy_coeff": 0.0}}, "num_steps_sampled": 732000, "num_steps_trained": 732000}, "done": false, "episodes_total": 211, "training_iteration": 183, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-16-43", "timestamp": 1619875003, "time_this_iter_s": 15.886252880096436, "time_total_s": 2795.8680799007416, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec613ea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f268>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2795.8680799007416, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 18.309090909090912, "ram_util_percent": 57.959090909090925}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.107035, "episode_len_mean": 3723.5, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.107035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002], "policy_pol_reward": [0.0, 0.005250000000000003, 0.004000000000000002, 0.006250000000000004, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9482777794978391, "mean_raw_obs_processing_ms": 0.9211920143327598, "mean_inference_ms": 1.036638309005674, "mean_action_processing_ms": 0.044487531946708715}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 736000, "timers": {"sample_time_ms": 3164.092, "sample_throughput": 1264.186, "learn_time_ms": 12301.145, "learn_throughput": 325.173, "update_time_ms": 3.867}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.019206678436603397, "policy_loss": -0.023569625336676836, "vf_loss": 5.644495917067616e-05, "vf_explained_var": 0.42792069911956787, "kl": 0.011949015315622091, "entropy": 1.148960780352354, "entropy_coeff": 0.0}}, "num_steps_sampled": 736000, "num_steps_trained": 736000}, "done": false, "episodes_total": 211, "training_iteration": 184, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-16-59", "timestamp": 1619875019, "time_this_iter_s": 15.662060499191284, "time_total_s": 2811.530140399933, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69db70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2811.530140399933, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 20.64782608695652, "ram_util_percent": 57.969565217391285}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10719000000000001, "episode_len_mean": 3723.5, "episodes_this_iter": 4, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10719000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, 0.0, 0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9483204998077543, "mean_raw_obs_processing_ms": 0.9234340134480661, "mean_inference_ms": 1.036667307352531, "mean_action_processing_ms": 0.044487007280368855}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 740000, "timers": {"sample_time_ms": 3152.678, "sample_throughput": 1268.763, "learn_time_ms": 12223.435, "learn_throughput": 327.24, "update_time_ms": 3.95}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.033490636269561946, "policy_loss": -0.037631745130056515, "vf_loss": 1.6209152761348378e-05, "vf_explained_var": 0.47139522433280945, "kl": 0.011445126467151567, "entropy": 1.1123533584177494, "entropy_coeff": 0.0}}, "num_steps_sampled": 740000, "num_steps_trained": 740000}, "done": false, "episodes_total": 215, "training_iteration": 185, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-17-14", "timestamp": 1619875034, "time_this_iter_s": 15.023967027664185, "time_total_s": 2826.554107427597, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60fa60>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bbf8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2826.554107427597, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 18.152380952380952, "ram_util_percent": 57.98571428571428}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10719000000000001, "episode_len_mean": 3723.5, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10719000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9483204998077541, "mean_raw_obs_processing_ms": 0.9234340134480661, "mean_inference_ms": 1.036667307352531, "mean_action_processing_ms": 0.04448700728036885}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 744000, "timers": {"sample_time_ms": 3120.457, "sample_throughput": 1281.864, "learn_time_ms": 12157.343, "learn_throughput": 329.019, "update_time_ms": 3.906}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.016705252550309524, "policy_loss": -0.01881645477260463, "vf_loss": 9.615329486223345e-05, "vf_explained_var": 0.20905566215515137, "kl": 0.005591039938735776, "entropy": 1.1056567579507828, "entropy_coeff": 0.0}}, "num_steps_sampled": 744000, "num_steps_trained": 744000}, "done": false, "episodes_total": 215, "training_iteration": 186, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-17-29", "timestamp": 1619875049, "time_this_iter_s": 14.681910991668701, "time_total_s": 2841.2360184192657, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f1e0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec608a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2841.2360184192657, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 17.59523809523809, "ram_util_percent": 58.0}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10719000000000001, "episode_len_mean": 3723.5, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10719000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9483204998077541, "mean_raw_obs_processing_ms": 0.9234340134480661, "mean_inference_ms": 1.036667307352531, "mean_action_processing_ms": 0.04448700728036885}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 748000, "timers": {"sample_time_ms": 3114.459, "sample_throughput": 1284.332, "learn_time_ms": 12212.673, "learn_throughput": 327.529, "update_time_ms": 4.057}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.017403390287654474, "policy_loss": -0.02215863880701363, "vf_loss": 9.95467044617726e-06, "vf_explained_var": -0.011966655030846596, "kl": 0.013166505406843498, "entropy": 0.9606965705752373, "entropy_coeff": 0.0}}, "num_steps_sampled": 748000, "num_steps_trained": 748000}, "done": false, "episodes_total": 215, "training_iteration": 187, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-17-44", "timestamp": 1619875064, "time_this_iter_s": 15.612634658813477, "time_total_s": 2856.848653078079, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69db70>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2856.848653078079, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 16.786956521739132, "ram_util_percent": 58.05652173913043}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10719000000000001, "episode_len_mean": 3723.5, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10719000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 1865, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.006750000000000004, 0.0015, 0.00125, 0.005500000000000003, -0.99925, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9483204998077541, "mean_raw_obs_processing_ms": 0.9234340134480661, "mean_inference_ms": 1.036667307352531, "mean_action_processing_ms": 0.04448700728036885}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 752000, "timers": {"sample_time_ms": 3099.739, "sample_throughput": 1290.431, "learn_time_ms": 12152.481, "learn_throughput": 329.151, "update_time_ms": 3.963}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": -0.002971340174553916, "policy_loss": -0.0063173667003866285, "vf_loss": 2.0469332611128266e-06, "vf_explained_var": 0.4810933470726013, "kl": 0.009278362922486849, "entropy": 0.9523648750036955, "entropy_coeff": 0.0}}, "num_steps_sampled": 752000, "num_steps_trained": 752000}, "done": false, "episodes_total": 215, "training_iteration": 188, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-17-59", "timestamp": 1619875079, "time_this_iter_s": 15.003071546554565, "time_total_s": 2871.851724624634, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6080d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2871.851724624634, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 18.38095238095238, "ram_util_percent": 58.028571428571425}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.1073475, "episode_len_mean": 3707.16, "episodes_this_iter": 5, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.1073475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -1.0, 0.0, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, -1.0, 0.0, 0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481837201414015, "mean_raw_obs_processing_ms": 0.9259457654849936, "mean_inference_ms": 1.0366460983594439, "mean_action_processing_ms": 0.04447624270615841}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 756000, "timers": {"sample_time_ms": 3105.898, "sample_throughput": 1287.872, "learn_time_ms": 12117.163, "learn_throughput": 330.11, "update_time_ms": 3.839}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.36040649414062503, "cur_lr": 5e-05, "total_loss": 0.0029203963931649923, "policy_loss": -0.0031117289909161627, "vf_loss": 0.0050009667211270425, "vf_explained_var": 0.07709693908691406, "kl": 0.0028611030320462305, "entropy": 1.0208899360150099, "entropy_coeff": 0.0}}, "num_steps_sampled": 756000, "num_steps_trained": 756000}, "done": false, "episodes_total": 220, "training_iteration": 189, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-18-14", "timestamp": 1619875094, "time_this_iter_s": 15.117489099502563, "time_total_s": 2886.9692137241364, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec608ea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec60f048>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2886.9692137241364, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 17.595454545454544, "ram_util_percent": 57.97727272727273}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10734750000000001, "episode_len_mean": 3707.16, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10734750000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002], "policy_pol_reward": [0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481837201414016, "mean_raw_obs_processing_ms": 0.9259457654849933, "mean_inference_ms": 1.036646098359444, "mean_action_processing_ms": 0.04447624270615841}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 760000, "timers": {"sample_time_ms": 3111.551, "sample_throughput": 1285.532, "learn_time_ms": 12173.224, "learn_throughput": 328.59, "update_time_ms": 3.795}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.18020324707031252, "cur_lr": 5e-05, "total_loss": -0.0296772665460594, "policy_loss": -0.03536450720275752, "vf_loss": 1.3661757066074642e-05, "vf_explained_var": 0.7955991625785828, "kl": 0.03148434736067429, "entropy": 1.0594289675354958, "entropy_coeff": 0.0}}, "num_steps_sampled": 760000, "num_steps_trained": 760000}, "done": false, "episodes_total": 220, "training_iteration": 190, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-18-30", "timestamp": 1619875110, "time_this_iter_s": 15.798115968704224, "time_total_s": 2902.7673296928406, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2902.7673296928406, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 18.236363636363638, "ram_util_percent": 58.02727272727271}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10734750000000001, "episode_len_mean": 3707.16, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10734750000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002], "policy_pol_reward": [0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481837201414016, "mean_raw_obs_processing_ms": 0.9259457654849933, "mean_inference_ms": 1.036646098359444, "mean_action_processing_ms": 0.04447624270615841}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 764000, "timers": {"sample_time_ms": 3102.446, "sample_throughput": 1289.305, "learn_time_ms": 12185.843, "learn_throughput": 328.25, "update_time_ms": 4.004}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.02362127508968115, "policy_loss": -0.026710339298006147, "vf_loss": 1.2407863074770376e-06, "vf_explained_var": 0.47456541657447815, "kl": 0.011423485644627362, "entropy": 0.9805576633661985, "entropy_coeff": 0.0}}, "num_steps_sampled": 764000, "num_steps_trained": 764000}, "done": false, "episodes_total": 220, "training_iteration": 191, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-18-46", "timestamp": 1619875126, "time_this_iter_s": 15.251610279083252, "time_total_s": 2918.018939971924, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60fea0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec67bc80>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2918.018939971924, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 17.936363636363634, "ram_util_percent": 58.0181818181818}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10734750000000001, "episode_len_mean": 3707.16, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10734750000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 3256, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002], "policy_pol_reward": [0.0035000000000000014, 0.005750000000000003, 0.00125, -0.9965, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481837201414016, "mean_raw_obs_processing_ms": 0.9259457654849933, "mean_inference_ms": 1.036646098359444, "mean_action_processing_ms": 0.04447624270615841}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 768000, "timers": {"sample_time_ms": 3090.463, "sample_throughput": 1294.304, "learn_time_ms": 12225.238, "learn_throughput": 327.192, "update_time_ms": 3.951}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.034838323132134974, "policy_loss": -0.03876751789357513, "vf_loss": 4.2754286377899575e-07, "vf_explained_var": 0.8358291983604431, "kl": 0.01453458120522555, "entropy": 0.9783731549978256, "entropy_coeff": 0.0}}, "num_steps_sampled": 768000, "num_steps_trained": 768000}, "done": false, "episodes_total": 220, "training_iteration": 192, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-19-01", "timestamp": 1619875141, "time_this_iter_s": 15.257381916046143, "time_total_s": 2933.27632188797, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec60f730>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fda60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2933.27632188797, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 17.581818181818182, "ram_util_percent": 57.9909090909091}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.0974875, "episode_len_mean": 3714.62, "episodes_this_iter": 4, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.0974875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002], "policy_pol_reward": [0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481376340881659, "mean_raw_obs_processing_ms": 0.927931787608951, "mean_inference_ms": 1.0366349965437376, "mean_action_processing_ms": 0.04446813257744562}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 772000, "timers": {"sample_time_ms": 3104.465, "sample_throughput": 1288.467, "learn_time_ms": 12118.736, "learn_throughput": 330.067, "update_time_ms": 3.968}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.01771780743729323, "policy_loss": -0.02080356451915577, "vf_loss": 9.207269641819948e-06, "vf_explained_var": 0.5089870691299438, "kl": 0.011381788121070713, "entropy": 0.9859333727508783, "entropy_coeff": 0.0}}, "num_steps_sampled": 772000, "num_steps_trained": 772000}, "done": false, "episodes_total": 224, "training_iteration": 193, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-19-16", "timestamp": 1619875156, "time_this_iter_s": 14.96254563331604, "time_total_s": 2948.238867521286, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2948.238867521286, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 20.666666666666664, "ram_util_percent": 57.976190476190474}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.0974875, "episode_len_mean": 3714.62, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.0974875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.003250000000000001, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481376340881656, "mean_raw_obs_processing_ms": 0.9279317876089511, "mean_inference_ms": 1.0366349965437376, "mean_action_processing_ms": 0.04446813257744563}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 776000, "timers": {"sample_time_ms": 3111.583, "sample_throughput": 1285.519, "learn_time_ms": 12106.922, "learn_throughput": 330.39, "update_time_ms": 3.965}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.021130600769538432, "policy_loss": -0.025537276203976944, "vf_loss": 9.702762334029558e-06, "vf_explained_var": 0.2115052193403244, "kl": 0.0162667210388463, "entropy": 1.1656995229423046, "entropy_coeff": 0.0}}, "num_steps_sampled": 776000, "num_steps_trained": 776000}, "done": false, "episodes_total": 224, "training_iteration": 194, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-19-32", "timestamp": 1619875172, "time_this_iter_s": 15.612350225448608, "time_total_s": 2963.8512177467346, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f6b62510>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2963.8512177467346, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 17.7695652173913, "ram_util_percent": 58.04347826086956}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10752, "episode_len_mean": 3699.38, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10752}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [2478, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-1.0, 0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481387042854464, "mean_raw_obs_processing_ms": 0.928334217740004, "mean_inference_ms": 1.0365512566291655, "mean_action_processing_ms": 0.04447050304127953}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 780000, "timers": {"sample_time_ms": 3108.822, "sample_throughput": 1286.661, "learn_time_ms": 12100.845, "learn_throughput": 330.555, "update_time_ms": 3.719}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.002405367442406714, "policy_loss": -0.00482742307940498, "vf_loss": 0.0005562943871950665, "vf_explained_var": 0.5643786191940308, "kl": 0.006902422974235378, "entropy": 1.1584459468722343, "entropy_coeff": 0.0}}, "num_steps_sampled": 780000, "num_steps_trained": 780000}, "done": false, "episodes_total": 225, "training_iteration": 195, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-19-47", "timestamp": 1619875187, "time_this_iter_s": 14.930173635482788, "time_total_s": 2978.7813913822174, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73f63c41e0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fd9d8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2978.7813913822174, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 17.54761904761905, "ram_util_percent": 58.019047619047626}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10752, "episode_len_mean": 3699.38, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10752}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478], "policy_pol_reward": [0.0025000000000000005, 0.0027500000000000007, 0.004250000000000002, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9481387042854464, "mean_raw_obs_processing_ms": 0.9283342177400041, "mean_inference_ms": 1.0365512566291653, "mean_action_processing_ms": 0.04447050304127953}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 784000, "timers": {"sample_time_ms": 3159.207, "sample_throughput": 1266.141, "learn_time_ms": 12138.023, "learn_throughput": 329.543, "update_time_ms": 3.785}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.017037968442309648, "policy_loss": -0.020399344357429072, "vf_loss": 1.2967363531402043e-05, "vf_explained_var": 0.3287524878978729, "kl": 0.012387520197080448, "entropy": 1.1474071815609932, "entropy_coeff": 0.0}}, "num_steps_sampled": 784000, "num_steps_trained": 784000}, "done": false, "episodes_total": 225, "training_iteration": 196, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-20-02", "timestamp": 1619875202, "time_this_iter_s": 15.557409286499023, "time_total_s": 2994.3388006687164, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd6a8>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fd378>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 2994.3388006687164, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 18.095454545454547, "ram_util_percent": 57.99545454545455}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.117615, "episode_len_mean": 3698.2, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.117615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -1.0, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478], "policy_pol_reward": [0.0, 0.0, -1.0, 0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480895896670367, "mean_raw_obs_processing_ms": 0.9301143625042743, "mean_inference_ms": 1.036516829742667, "mean_action_processing_ms": 0.04446188024289585}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 788000, "timers": {"sample_time_ms": 3193.542, "sample_throughput": 1252.528, "learn_time_ms": 12122.619, "learn_throughput": 329.962, "update_time_ms": 3.629}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.02127761603333056, "policy_loss": -0.02286928682588041, "vf_loss": 0.00017733462948399392, "vf_explained_var": 0.8147770166397095, "kl": 0.005232373543549329, "entropy": 1.175620898604393, "entropy_coeff": 0.0}}, "num_steps_sampled": 788000, "num_steps_trained": 788000}, "done": false, "episodes_total": 228, "training_iteration": 197, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-20-18", "timestamp": 1619875218, "time_this_iter_s": 15.799453735351562, "time_total_s": 3010.138254404068, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fda60>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d730>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3010.138254404068, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 18.295652173913044, "ram_util_percent": 58.04347826086955}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.117615, "episode_len_mean": 3698.2, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.117615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884], "policy_pol_reward": [0.006000000000000004, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480895896670369, "mean_raw_obs_processing_ms": 0.9301143625042743, "mean_inference_ms": 1.036516829742667, "mean_action_processing_ms": 0.04446188024289583}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 792000, "timers": {"sample_time_ms": 3225.688, "sample_throughput": 1240.045, "learn_time_ms": 12117.133, "learn_throughput": 330.111, "update_time_ms": 3.715}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.01902214961592108, "policy_loss": -0.022709929384291172, "vf_loss": 6.548228583369564e-06, "vf_explained_var": 0.2319619506597519, "kl": 0.013618822733405977, "entropy": 1.137103095650673, "entropy_coeff": 0.0}}, "num_steps_sampled": 792000, "num_steps_trained": 792000}, "done": false, "episodes_total": 228, "training_iteration": 198, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-20-33", "timestamp": 1619875233, "time_this_iter_s": 15.265655755996704, "time_total_s": 3025.4039101600647, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd510>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3025.4039101600647, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 18.459090909090907, "ram_util_percent": 57.96818181818182}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.11767499999999999, "episode_len_mean": 3698.2, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.11767499999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884], "policy_pol_reward": [0.0, 0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480872881927211, "mean_raw_obs_processing_ms": 0.9305553646296759, "mean_inference_ms": 1.0364214391205087, "mean_action_processing_ms": 0.04446341224795014}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 796000, "timers": {"sample_time_ms": 3241.235, "sample_throughput": 1234.098, "learn_time_ms": 12133.326, "learn_throughput": 329.671, "update_time_ms": 3.821}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.021472842840012163, "policy_loss": -0.023733527428703383, "vf_loss": 8.937154696297966e-07, "vf_explained_var": 0.3262476921081543, "kl": 0.008360167368664406, "entropy": 1.1008127257227898, "entropy_coeff": 0.0}}, "num_steps_sampled": 796000, "num_steps_trained": 796000}, "done": false, "episodes_total": 229, "training_iteration": 199, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-20-49", "timestamp": 1619875249, "time_this_iter_s": 15.429405212402344, "time_total_s": 3040.833315372467, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fd6a8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3040.833315372467, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 16.995454545454546, "ram_util_percent": 58.095454545454544}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.117675, "episode_len_mean": 3698.2, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.117675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002], "policy_pol_reward": [0.0022500000000000003, 0.00125, 0.0070000000000000045, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480872881927211, "mean_raw_obs_processing_ms": 0.9305553646296759, "mean_inference_ms": 1.0364214391205084, "mean_action_processing_ms": 0.04446341224795014}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 800000, "timers": {"sample_time_ms": 3240.625, "sample_throughput": 1234.33, "learn_time_ms": 12065.026, "learn_throughput": 331.537, "update_time_ms": 3.853}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.019419820280745625, "policy_loss": -0.022552772366907448, "vf_loss": 3.6433873429331243e-07, "vf_explained_var": 0.007507734000682831, "kl": 0.011589106870815158, "entropy": 1.1370231211185455, "entropy_coeff": 0.0}}, "num_steps_sampled": 800000, "num_steps_trained": 800000}, "done": false, "episodes_total": 229, "training_iteration": 200, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-21-04", "timestamp": 1619875264, "time_this_iter_s": 15.111668348312378, "time_total_s": 3055.9449837207794, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fdd08>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3055.9449837207794, "timesteps_since_restore": 0, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 17.376190476190477, "ram_util_percent": 58.028571428571425}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.11776999999999999, "episode_len_mean": 3698.2, "episodes_this_iter": 3, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.11776999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.00075, 0.0, 0.00025, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002], "policy_pol_reward": [0.00075, 0.0, 0.00025, 0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480411449692618, "mean_raw_obs_processing_ms": 0.932465690092449, "mean_inference_ms": 1.0363737335102456, "mean_action_processing_ms": 0.04445426016924672}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 804000, "timers": {"sample_time_ms": 3275.429, "sample_throughput": 1221.214, "learn_time_ms": 11949.967, "learn_throughput": 334.729, "update_time_ms": 3.732}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.27030487060546876, "cur_lr": 5e-05, "total_loss": -0.003622104733949527, "policy_loss": -0.004321761487517506, "vf_loss": 4.2248795273369666e-07, "vf_explained_var": -0.8248687982559204, "kl": 0.0025868376942526083, "entropy": 1.1342014335095882, "entropy_coeff": 0.0}}, "num_steps_sampled": 804000, "num_steps_trained": 804000}, "done": false, "episodes_total": 232, "training_iteration": 201, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-21-19", "timestamp": 1619875279, "time_this_iter_s": 14.451244354248047, "time_total_s": 3070.3962280750275, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd158>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fea60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3070.3962280750275, "timesteps_since_restore": 0, "iterations_since_restore": 201, "perf": {"cpu_util_percent": 17.98095238095238, "ram_util_percent": 58.01428571428571}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.11776999999999999, "episode_len_mean": 3698.2, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.11776999999999999}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025], "episode_lengths": [4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0025000000000000005, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025]}, "sampler_perf": {"mean_env_wait_ms": 0.9480411449692617, "mean_raw_obs_processing_ms": 0.932465690092449, "mean_inference_ms": 1.0363737335102454, "mean_action_processing_ms": 0.04445426016924674}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 808000, "timers": {"sample_time_ms": 3312.959, "sample_throughput": 1207.38, "learn_time_ms": 11965.493, "learn_throughput": 334.295, "update_time_ms": 3.82}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.13515243530273438, "cur_lr": 5e-05, "total_loss": -0.016639770416077226, "policy_loss": -0.018304889323189855, "vf_loss": 3.7471759634088997e-07, "vf_explained_var": -0.6665947437286377, "kl": 0.012317535612965003, "entropy": 1.1378131248056889, "entropy_coeff": 0.0}}, "num_steps_sampled": 808000, "num_steps_trained": 808000}, "done": false, "episodes_total": 232, "training_iteration": 202, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-21-35", "timestamp": 1619875295, "time_this_iter_s": 15.78819489479065, "time_total_s": 3086.184422969818, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d488>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69d620>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3086.184422969818, "timesteps_since_restore": 0, "iterations_since_restore": 202, "perf": {"cpu_util_percent": 21.36521739130435, "ram_util_percent": 57.95652173913044}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.11779500000000001, "episode_len_mean": 3698.2, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.11779500000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025], "episode_lengths": [4002, 3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025]}, "sampler_perf": {"mean_env_wait_ms": 0.9480385249312807, "mean_raw_obs_processing_ms": 0.9329337031895117, "mean_inference_ms": 1.0362699339945023, "mean_action_processing_ms": 0.04445546607022384}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 812000, "timers": {"sample_time_ms": 3310.015, "sample_throughput": 1208.454, "learn_time_ms": 12036.246, "learn_throughput": 332.33, "update_time_ms": 3.847}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.13515243530273438, "cur_lr": 5e-05, "total_loss": -0.003269431064836681, "policy_loss": -0.0036037190002389252, "vf_loss": 2.6723271773221313e-07, "vf_explained_var": -0.3795778751373291, "kl": 0.002471432206220925, "entropy": 1.136858955025673, "entropy_coeff": 0.0}}, "num_steps_sampled": 812000, "num_steps_trained": 812000}, "done": false, "episodes_total": 233, "training_iteration": 203, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-21-50", "timestamp": 1619875310, "time_this_iter_s": 15.638171911239624, "time_total_s": 3101.8225948810577, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fe0d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5feae8>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3101.8225948810577, "timesteps_since_restore": 0, "iterations_since_restore": 203, "perf": {"cpu_util_percent": 17.349999999999998, "ram_util_percent": 58.054545454545455}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.11779500000000001, "episode_len_mean": 3698.2, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.11779500000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0], "episode_lengths": [3174, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [-0.99825, 0.0, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480385249312809, "mean_raw_obs_processing_ms": 0.9329337031895117, "mean_inference_ms": 1.0362699339945025, "mean_action_processing_ms": 0.04445546607022384}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 816000, "timers": {"sample_time_ms": 3309.1, "sample_throughput": 1208.788, "learn_time_ms": 12015.813, "learn_throughput": 332.895, "update_time_ms": 3.909}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.06757621765136719, "cur_lr": 5e-05, "total_loss": -0.010045676535810344, "policy_loss": -0.01069247296982212, "vf_loss": 1.0376637149533963e-07, "vf_explained_var": -0.08255104720592499, "kl": 0.009569824003847316, "entropy": 1.1329663507640362, "entropy_coeff": 0.0}}, "num_steps_sampled": 816000, "num_steps_trained": 816000}, "done": false, "episodes_total": 233, "training_iteration": 204, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-22-06", "timestamp": 1619875326, "time_this_iter_s": 15.398614883422852, "time_total_s": 3117.2212097644806, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d268>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fd378>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3117.2212097644806, "timesteps_since_restore": 0, "iterations_since_restore": 204, "perf": {"cpu_util_percent": 18.94090909090909, "ram_util_percent": 57.95}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.1077975, "episode_len_mean": 3706.48, "episodes_this_iter": 2, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.1077975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0015, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0015, 0.0015, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9482572633675593, "mean_raw_obs_processing_ms": 0.9343011054896186, "mean_inference_ms": 1.036335159301976, "mean_action_processing_ms": 0.04445827811023283}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 820000, "timers": {"sample_time_ms": 3325.055, "sample_throughput": 1202.987, "learn_time_ms": 12100.375, "learn_throughput": 330.568, "update_time_ms": 4.119}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.06757621765136719, "cur_lr": 5e-05, "total_loss": -0.03128439944703132, "policy_loss": -0.032524829293834046, "vf_loss": 3.8050200190653527e-07, "vf_explained_var": -1.0, "kl": 0.018350344034843147, "entropy": 1.1542061381042004, "entropy_coeff": 0.0}}, "num_steps_sampled": 820000, "num_steps_trained": 820000}, "done": false, "episodes_total": 235, "training_iteration": 205, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-22-22", "timestamp": 1619875342, "time_this_iter_s": 15.93686318397522, "time_total_s": 3133.158072948456, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d620>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dd90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3133.158072948456, "timesteps_since_restore": 0, "iterations_since_restore": 205, "perf": {"cpu_util_percent": 17.456521739130434, "ram_util_percent": 58.06956521739128}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10781250000000002, "episode_len_mean": 3706.48, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10781250000000002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0047500000000000025, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015]}, "sampler_perf": {"mean_env_wait_ms": 0.9480089824952904, "mean_raw_obs_processing_ms": 0.9349765188942882, "mean_inference_ms": 1.0362207112901671, "mean_action_processing_ms": 0.044446244181385125}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 824000, "timers": {"sample_time_ms": 3309.012, "sample_throughput": 1208.82, "learn_time_ms": 12155.307, "learn_throughput": 329.074, "update_time_ms": 4.088}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.06757621765136719, "cur_lr": 5e-05, "total_loss": -0.007491779571864754, "policy_loss": -0.009179779328405857, "vf_loss": 7.972344018281063e-07, "vf_explained_var": -0.7912001609802246, "kl": 0.02496740286005661, "entropy": 1.19075495749712, "entropy_coeff": 0.0}}, "num_steps_sampled": 824000, "num_steps_trained": 824000}, "done": false, "episodes_total": 236, "training_iteration": 206, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-22-38", "timestamp": 1619875358, "time_this_iter_s": 15.94611406326294, "time_total_s": 3149.1041870117188, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd2f0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec5fd0d0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3149.1041870117188, "timesteps_since_restore": 0, "iterations_since_restore": 206, "perf": {"cpu_util_percent": 18.056521739130435, "ram_util_percent": 58.03913043478259}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10786000000000001, "episode_len_mean": 3706.48, "episodes_this_iter": 1, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10786000000000001}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480080484590486, "mean_raw_obs_processing_ms": 0.9354882237078864, "mean_inference_ms": 1.0361162848629577, "mean_action_processing_ms": 0.044447415660920545}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 828000, "timers": {"sample_time_ms": 3301.06, "sample_throughput": 1211.732, "learn_time_ms": 12139.063, "learn_throughput": 329.515, "update_time_ms": 4.262}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10136432647705079, "cur_lr": 5e-05, "total_loss": -0.015516949904849753, "policy_loss": -0.017649460292886943, "vf_loss": 1.072238916544066e-06, "vf_explained_var": -0.5928820967674255, "kl": 0.02102748746983707, "entropy": 1.24659363925457, "entropy_coeff": 0.0}}, "num_steps_sampled": 828000, "num_steps_trained": 828000}, "done": false, "episodes_total": 237, "training_iteration": 207, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-22-53", "timestamp": 1619875373, "time_this_iter_s": 15.559753894805908, "time_total_s": 3164.6639409065247, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec5fd950>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec604a60>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3164.6639409065247, "timesteps_since_restore": 0, "iterations_since_restore": 207, "perf": {"cpu_util_percent": 18.822727272727274, "ram_util_percent": 57.97727272727272}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.10786, "episode_len_mean": 3706.48, "episodes_this_iter": 0, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.10786}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015, 0.0, 0.0], "episode_lengths": [4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, 0.002, 0.006250000000000004, 0.0025000000000000005, 0.007250000000000005, 0.005500000000000003, 0.0025000000000000005, 0.006000000000000004, 0.005750000000000003, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9480080484590485, "mean_raw_obs_processing_ms": 0.9354882237078864, "mean_inference_ms": 1.0361162848629575, "mean_action_processing_ms": 0.04444741566092054}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 832000, "timers": {"sample_time_ms": 3298.125, "sample_throughput": 1212.81, "learn_time_ms": 12209.514, "learn_throughput": 327.613, "update_time_ms": 4.293}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1520464897155762, "cur_lr": 5e-05, "total_loss": -0.0138981225900352, "policy_loss": -0.015483040479011834, "vf_loss": 3.636589096345233e-05, "vf_explained_var": 0.8471733331680298, "kl": 0.010184741317061707, "entropy": 1.2125265039503574, "entropy_coeff": 0.0}}, "num_steps_sampled": 832000, "num_steps_trained": 832000}, "done": false, "episodes_total": 237, "training_iteration": 208, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-23-09", "timestamp": 1619875389, "time_this_iter_s": 15.940140724182129, "time_total_s": 3180.604081630707, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec69d620>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73ec69dd90>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3180.604081630707, "timesteps_since_restore": 0, "iterations_since_restore": 208, "perf": {"cpu_util_percent": 16.030434782608694, "ram_util_percent": 58.047826086956526}, "trial_id": "e60dd_00000"}
{"episode_reward_max": 0.008000000000000005, "episode_reward_min": -1.0, "episode_reward_mean": -0.17821749999999997, "episode_len_mean": 3430.42, "episodes_this_iter": 9, "policy_reward_min": {"pol": -1.0}, "policy_reward_max": {"pol": 0.008000000000000005}, "policy_reward_mean": {"pol": -0.17821749999999997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.002, -1.0, -1.0, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015, 0.0, 0.0], "episode_lengths": [4002, 52, 43, 48, 66, 91, 4002, 60, 48, 4002, 4002, 4002, 4002, 4002, 3162, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 168, 1069, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 500, 143, 1441, 4002, 573, 821, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 231, 4002, 4002, 4002, 4002, 4002, 2478, 4002, 4002, 3884, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002, 4002], "policy_pol_reward": [0.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.002, -1.0, -1.0, 0.007500000000000005, 0.0035000000000000014, 0.0, 0.007750000000000005, 0.005250000000000003, -0.99725, 0.006500000000000004, 0.008000000000000005, 0.003000000000000001, 0.006250000000000004, 0.0027500000000000007, 0.006250000000000004, 0.0070000000000000045, 0.005250000000000003, 0.006750000000000004, 0.005250000000000003, 0.005500000000000003, 0.0035000000000000014, 0.0027500000000000007, 0.003000000000000001, 0.007500000000000005, 0.005000000000000003, 0.007750000000000005, 0.0025000000000000005, 0.003000000000000001, 0.0025000000000000005, 0.007250000000000005, 0.0, 0.00075, 0.0, 0.0, 0.00175, 0.0070000000000000045, 0.005250000000000003, 0.003250000000000001, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003250000000000001, 0.0, 0.006750000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -0.98825, 0.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.00075, 0.0, 0.00025, 0.0, 0.0, 0.0015, 0.0, 0.0]}, "sampler_perf": {"mean_env_wait_ms": 0.9479868488925857, "mean_raw_obs_processing_ms": 0.941435359275978, "mean_inference_ms": 1.0362025578316105, "mean_action_processing_ms": 0.044411952935833464}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 836000, "timers": {"sample_time_ms": 3308.037, "sample_throughput": 1209.176, "learn_time_ms": 12237.568, "learn_throughput": 326.862, "update_time_ms": 4.293}, "info": {"learner": {"pol": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1520464897155762, "cur_lr": 5e-05, "total_loss": -0.018120772438123822, "policy_loss": -0.032352683308999985, "vf_loss": 0.010661776250344701, "vf_explained_var": 0.7740911245346069, "kl": 0.023480544652557, "entropy": 1.2297566831111908, "entropy_coeff": 0.0}}, "num_steps_sampled": 836000, "num_steps_trained": 836000}, "done": false, "episodes_total": 246, "training_iteration": 209, "experiment_id": "3b3b9fef8a0f4b9f923151581abc5b19", "date": "2021-05-01_22-23-25", "timestamp": 1619875405, "time_this_iter_s": 15.812373876571655, "time_total_s": 3196.4164555072784, "pid": 9509, "hostname": "Hinton", "node_ip": "143.248.157.211", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 1, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "gamma": 0.99, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env_config": {"agent": {"globalScaling": 1, "acc": 0.3, "max_speed": 1.5, "color": [0, 125, 0, 1]}, "target": {"globalScaling": 2, "acc": 0.2, "max_speed": 2, "color": [0, 0, 125, 1]}, "obstacle": {"globalScaling": 20, "color": [125, 125, 125, 1], "acc": 0.0001, "max_speed": 2}, "num_agents": 1, "num_obstacles": 10, "num_targets": 1, "map_size": 4, "max_timestep": 4000, "curriculum_learning": 1, "observation_range": 2, "cnn_size": 10, "phase": 4}, "env": "FollowTemplateRay", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 5e-05, "monitor": false, "log_level": "WARN", "callbacks": "<function Trainer.merge_trainer_configs.<locals>.make_callbacks at 0x7f73ec6040d0>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": true, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", "Box(-inf, inf, (10, 10), float32)", "Discrete(5)", {}]}, "policy_mapping_fn": "<function <lambda> at 0x7f73f63c41e0>", "policies_to_train": ["pol"], "observation_fn": "<function Observation_CNN.observation_fn_3 at 0x7f73f6ff51e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": true, "_fake_gpus": false, "vf_share_layers": -1}, "time_since_restore": 3196.4164555072784, "timesteps_since_restore": 0, "iterations_since_restore": 209, "perf": {"cpu_util_percent": 18.236363636363635, "ram_util_percent": 58.07272727272727}, "trial_id": "e60dd_00000"}
